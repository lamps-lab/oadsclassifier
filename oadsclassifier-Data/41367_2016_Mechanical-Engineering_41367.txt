EVALUATION OF TELEOPERATION SYSTEM PERFORMANCE OVER 
A CELLULAR NETWORK 

 
 
 
 
 
 
 
 
 
A Thesis  
Presented to 
The Academic Faculty 
 
 
 
 
By 
 
 
 
Reinaldo Sepulveda 
 
 
 
 
In Partial Fulfillment  
Of the Requirements for the Degree 
Master of Science in the  
School of Mechanical Engineering 
 
 
 
 
 
 
 
Georgia Institute of Technology 
December 2016 
 
 
COPYRIGHT © 2016 BY REINALDO SEPULVEDA 

 

 

 

EVALUATION OF TELEOPERATION SYSTEM PERFORMANCE OVER A CELLULAR 
NETWORK 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

Approved by: 

 

Dr. Bert Bras, Advisor  
School of Mechanical Engineering 
Georgia Institute of Technology 
 
Dr. Ghassan Al-Regib  
School of Electrical and Mechanical Engineering 
Georgia Institute of Technology 
 

Dr. Aaron Ames  
School of Mechanical Engineering 
Georgia Institute of Technology 
 

Date Approved: August 23, 2016 

 

 

ACKNOWLEDGMENTS 

I would like to thank Dr. Bras for the incredible opportunity he gave me when I 

joined the Sustainable Design and Manufacturing lab, along with his support and advice 

along this 2 year travesty of completing research and building incredible projects. 

I have a great deal of gratitude towards my committee members, Dr. Al-Regib 

and Dr. Ames, who have taken time to read and improve the work in this thesis. 

To the great people that have come and gone (or still remain) in the SDM lab, I 

would like to express feelings of friendship and happiness. I can’t imagine having been 

grouped with more intelligent and proactive people, while still down to earth and always 

willing to have a good laugh or talk about meaningful events. 

I would like to thank my family, who have always encouraged me to push through 

and overcome obstacles in my road. 

Finally, I would like to thank my one true motivation in life, my wife, who gave up 

2 years of her life to help me accomplish my goals. I can honestly say that none of this 

would be possible without her support, guidance and endurance.  

 

 

 

 

 

 

 

 

iv 

TABLE OF CONTENTS 

 

 

ACKNOWLEDGMENTS ............................................................................................................. iv 

LIST OF TABLES ..................................................................................................................... viii 

LIST OF FIGURES .................................................................................................................... ix 

SUMMARY .............................................................................................................................. xiii 

CHAPTER 1

 INTRODUCTION ................................................................................................... 1 

1.1 Motivation ......................................................................................................................... 1 

1.2 Objectives ......................................................................................................................... 3 

1.3 Thesis Structure ............................................................................................................... 4 

CHAPTER 2

 LITERATURE REVIEW ......................................................................................... 6 

2.1 Teleoperation ................................................................................................................... 6 

2.1.1 Master-Slave .............................................................................................................. 8 

2.1.2 Supervisory – Subordinate ......................................................................................... 9 

2.1.3 Partner – Partner.......................................................................................................10 

2.1.4 Teacher – Learner .....................................................................................................10 

2.1.5 Fully Autonomous .....................................................................................................11 

2.1.6 Current Applications in Teleoperation ........................................................................12 

2.2 Quantifying Teleoperation ................................................................................................14 

2.2.1 Quantification Strategies for Teleoperation................................................................16 

2.2.2 Telepresence ............................................................................................................18 

2.3 Internet Based Time Delays.............................................................................................20 

2.4 Current Applications of 4G LTE in Teleoperation .............................................................25 

2.5 Summary .........................................................................................................................27 

CHAPTER 3

 SYSTEM DESCRIPTION .....................................................................................29 

3.1 General Teleoperations Platform .....................................................................................31 

3.2 Remote Vehicle System ..................................................................................................35 

3.3 Local Operator Station .....................................................................................................41 

3.4 Summary .........................................................................................................................45 

CHAPTER 4

 EXPERIMENT DESIGN AND  STATISTICAL ANALYSIS ....................................46 

4.1 Tasks Selected for Measuring Performance ....................................................................48 

4.1.1 Origins of the Selected Tasks....................................................................................48 

4.1.2 Tasks and Description ...............................................................................................50 

v 

4.2 Telepresence and Camera Position .................................................................................55 

4.2.1 Camera Position Variability .......................................................................................56 

4.3 Variables logged and Data collection ...............................................................................57 

4.3.1 Logged Variables ......................................................................................................57 

4.3.2 Data Logging Methods ..............................................................................................58 

4.4 Variables Post-Processing ...............................................................................................60 

4.4.1 Distance Variable processing ....................................................................................60 

4.4.2 Time Synchronization Algorithm ................................................................................62 

4.5 Statistical Analysis ...........................................................................................................64 

4.6 Summary .........................................................................................................................67 

CHAPTER 5

 RESULTS AND ANALYSIS ..................................................................................69 

5.1 Results ............................................................................................................................70 

5.1.1 Performance Metrics .................................................................................................70 

5.1.2 Results and Statistical Analysis .................................................................................76 

5.1.3 Results Summary ......................................................................................................99 

5.1.4 Questionnaire .......................................................................................................... 100 

5.2 Analysis and Variable Comparisons .............................................................................. 107 

5.2.1 Camera Position Analysis ....................................................................................... 108 

5.2.2 Latency Analysis ..................................................................................................... 112 

5.3 Possible Causes to the Observed System Limitations ................................................... 117 

5.3.1 Latency profiles ....................................................................................................... 117 

5.3.2 Network congestion and Time of Day ...................................................................... 122 

5.4 A Posteriori Analysis ...................................................................................................... 124 

5.5 Summary ....................................................................................................................... 127 

CHAPTER 6

 CONCLUSIONS ................................................................................................. 130 

6.1 Summary ....................................................................................................................... 130 

6.2 Achievements ................................................................................................................ 135 

6.2.1 Motivation and State of Art ...................................................................................... 135 

6.2.2 System Description and Experimental Design ......................................................... 136 

6.2.3 Experiments and Results ........................................................................................ 137 

6.2.4 Analysis of Results .................................................................................................. 139 

6.3 Future work ................................................................................................................... 139 

6.3.1 Predicting Congestion ............................................................................................. 140 

 

vi 

6.3.2 Predicting Loss of Connection ................................................................................. 141 

6.3.3 Parallel Connections or Redundancies .................................................................... 141 

APPENDIX A
 ............................................................................................................................................... 143 

 TELEOPERATION SYSTEM NODE AND INFORMATION FLOW DESCRIPTION

APPENDIX B

 QUESTIONAIRE AND RESULTS ..................................................................... 152 

APPENDIX C

 RESULTS – PERFORMANCE METRICS ......................................................... 161 

APPENDIX D

 RESULTS – STATISTICAL ANALYSIS ............................................................ 175 

REFERENCES ....................................................................................................................... 183 

 

 

 

 

vii 

LIST OF TABLES 

Table 2-1 Wireless Technology Comparison (Meier, 2005); (IEEE, 2009); (Zanchi, 2014); 

(Rysavy Research, 2013) ..............................................................................................24 

Table 5-1 Answers to Question 34) what most hindered my performance was… .................... 107 

Table 5-2 P-Values of the Statistical Test for Camera Position Comparisons, calculated as 

described in CHAPTER 4 (Two Sample T-test or Kruskal-Wallis Test) ........................ 109 

Table 5-3 P-Values of the Statistical Test for Improvement Rations in Camera Position 

Comparisons, calculated as described in CHAPTER 4 (Two Sample T-test) ............... 112 

Table A -1 List of Remote Vehicle Variables ........................................................................... 147 

Table A -2 Equipment Description ........................................................................................... 150 
 
Table C - 1 Correlation between Column and Performance metric .......................................... 161 

Table C - 2 Path Following Camera Inside .............................................................................. 163 

Table C - 3 Path Following Camera Outside ........................................................................... 165 
 
Table D - 1 Correlation between Column and Performance metric .......................................... 175 

Table D - 2 Main Hypothesis Statistical Tests for Straight Trajectory ...................................... 177 

Table D - 3 Main Hypothesis Statistical Test for Reverse Trajectory ....................................... 178 

Table D - 4 Main Hypothesis Statistical Tests for Path Following ............................................ 179 

Table D - 5 Camera Comparison, Statistical Tests for Straight Trajectory ............................... 180 

Table D - 6 Camera Comparison, Statistical Tests for Reverse Trajectory .............................. 181 

Table D - 7 Camera Comparison, Statistical Tests for Path Following ..................................... 182 

 

 

 

 

viii 

LIST OF FIGURES 

Figure 2-1 Master-Slave System (Swanson, 2013) .................................................................... 8 

Figure 2-2 Supervisory-Subordinate System (Swanson, 2013) .................................................. 9 

Figure 2-3 Partner-Partner System (Swanson, 2013) ................................................................10 

Figure 2-4 Teacher-Learner System (Swanson, 2013) ..............................................................11 

Figure 2-5 Fully Autonomous System (Swanson, 2013) ............................................................11 

Figure 2-6Areal View That (Saakes, Choudhary, Sakamoto, Inami, & Igarashi, 2013) Believe 

Improves Teleoperation .................................................................................................17 

Figure 2-7 a) Circuit Switch Network. b) Packet Switch Network ...............................................22 

Figure 2-8 Sample IP Packet (Northrup, 2016)..........................................................................23 

Figure 2-9 TCP and UDP Packet Headers (Microchip Techonology Inc., 2016) ........................23 

Figure 3-1 General Teleoperations Configuration ......................................................................30 

Figure 3-2 Cellular Network Teleoperation Scheme ..................................................................32 

Figure 3-3 Teleoperation System Architecture ..........................................................................34 

Figure 3-4 Remote Vehicle Control Nodes and Information Flow ..............................................36 

Figure 3-5 Remote Vehicle – Golf Cart .....................................................................................38 

Figure 3-6 Remote Vehicle System Break down .......................................................................39 

Figure 3-7 Local Operator Station Control Nodes and Information Flow ....................................41 

Figure 3-8 Gamepad Setup .......................................................................................................43 

Figure 3-9 Graphics Display Setup ............................................................................................43 

Figure 3-10 Visual Example of Prediction Line Overlay .............................................................44 

Figure 4-1 Straight Trajectory Task Overview ...........................................................................52 

Figure 4-2 Reverse Trajectory Task Overview ..........................................................................53 

Figure 4-3 Path Following Task Overview .................................................................................55 

 

ix 

Figure 4-4 Bicycle Model Geometric Model ...............................................................................61 

Figure 4-5 NTP Time Stamp Algorithm .....................................................................................63 

Figure 5-1 Visualization of Trajectory Performance Metrics. Path taken by remote operator 

(blue). Optimal Path (red). Area between paths (light blue). Check points (red circles). .72 

Figure 5-2 Description of Box-Plot Identifiers ............................................................................77 

Figure 5-3 Actual Data Points overlaid on a Box-Plot ................................................................78 

Figure 5-4 Box Plot of Maximum Deviation for Straight Trajectory Tasks ..................................79 

Figure 5-5 Box Plot of Total Time for Straight Trajectory Tasks ................................................80 

Figure 5-6 Box Plot or Area Deviation for Straight Trajectory Tasks ..........................................81 

Figure 5-7 Box Plot of Area Deviation in Function of Time for Straight Trajectory Tasks ...........82 

Figure 5-8 Box Plot of Maximum Speed for Straight Trajectory Tasks .......................................83 

Figure 5-9 Box Plot of Mean Speed for Straight Trajectory Tasks .............................................83 

Figure 5-10 Box Plot of Latency for Straight Trajectory Tasks ...................................................84 

Figure 5-11 Box Plot of Distance Deviation for Reverse Trajectory Tasks .................................85 

Figure 5-12 Box Plot of Total Time for Reverse Trajectory Tasks..............................................86 

Figure 5-13 Box Plot of Area Deviation for Reverse Trajectory Tasks .......................................86 

Figure 5-14 Box Plot of Area Deviation in Function of Time for Reverse Trajectory Tasks ........87 

Figure 5-15 Box Plot of Maximum Speed for Reverse Trajectory Tasks ....................................88 

Figure 5-16 Box Plot of Mean Speed for Reverse Trajectory Tasks ..........................................88 

Figure 5-17 Box Plot of Number of Stops for Reverse Trajectory Tasks ....................................89 

Figure 5-18 Box Plot of Time Stopped for Reverse Trajectory Tasks ........................................90 

Figure 5-19 Reverse Trajectory Stops Plotted over the Ideal Path. In Green are the ideal 

locations for stopping that in-situ drivers achieved consistently. ....................................91 

Figure 5-20 Box Plot of Latency for Reverse Trajectory Tasks ..................................................92 

Figure 5-21 Box Plot if Distance Deviation for Path Following Tasks .........................................93 

Figure 5-22 Box Plot of Total Time for Path Following Tasks ....................................................94 

 

x 

Figure 5-23 Box Plot of Area Deviation for Path Following Tasks ..............................................95 

Figure 5-24 Box Plot of Area Deviation in Function of Time for Path Following Tasks ...............95 

Figure 5-25 Box Plot of Maximum Speed for Path Following Tasks ..........................................96 

Figure 5-26 Box Plot of Mean Speed for Path Following Tasks .................................................96 

Figure 5-27 Box Plot of Number of Stops for Path Following Tasks ..........................................97 

Figure 5-28 Box Plot of Time Stopped for Path Following Tasks ...............................................97 

Figure 5-29 Path following Stops Plotted over the Ideal Path. The green dots shoe optimal stop 

points.............................................................................................................................98 

Figure 5-30 Box Plot of Latency for Path Following Tasks ........................................................99 

Figure 5-31Camera Position- Inside Vehicle ........................................................................... 101 

Figure 5-32 Camera Position – Outside Vehicle ...................................................................... 102 

Figure 5-33 Bar Graph of Questions Relating to Camera Location .......................................... 102 

Figure 5-34 Bar Graph of Questions Related to Video Feedback ............................................ 104 

Figure 5-35 Bar Graph of Questions Regarding System Latency ............................................ 105 

Figure 5-36 Bar Graph of Questions Relating to Overall Performance .................................... 106 

Figure 5-37 Box Plot of Camera Comparison for Maximum Distance Deviation in Straight 

Trajectory Tasks .......................................................................................................... 110 

Figure 5-38 Box Plot of Camera Comparison for Maximum Distance Deviation in Reverse 

Trajectory Tasks .......................................................................................................... 110 

Figure 5-39 Box Plot of Camera Comparison for Maximum Distance Deviation in Reverse 

Trajectory Tasks .......................................................................................................... 111 

Figure 5-40 Logarithmic Plot of the Maximum Distance in Function of Latency. Blue Crosses 

Represent Path following Tasks, Green Crosses Represent Reverse Trajectory Tasks 

and Magenta Crosses Represent Straight Trajectory Tasks. ....................................... 114 

Figure 5-41 Average Latency for Each Task in Function of the Time of Day ........................... 115 

Figure 5-42 Average Latency for Path and Reverse Task in Function of the Time of Day ....... 115 

 

xi 

Figure 5-43 Average Latency for Straight Trajectory Task in Function of the Time of Day ...... 116 

Figure 5-44 Examples of Low Latency Profiles for Each Task ................................................. 118 

Figure 5-45 Latency and Velocity Profiles in Function of Time of Run. Latency Profile is shown 

in Blue, Velocity Profile is shown in Magenta. .............................................................. 119 

Figure 5-46 Latency and Gyroscope Profiles in Function of Time of Run. Latency Profile is 

shown in Blue, Gyroscope Profile is shown in Green. .................................................. 120 

Figure 5-47 Latency, Velocity and Gyroscope Profiles in Function of Time of Run. Latency 

Profile is shown in Blue, Velocity Profile is shown in Magenta, and Gyroscope Profile is 

shown in Green. .......................................................................................................... 121 

Figure 5-48 Normalized Network Congestion in Function of Time of Day in an Urban Setting. 

(Son, 2011) ................................................................................................................. 123 

Figure A-1 Remote Vehicle Control Nodes and Information Flow ............................................ 143 

Figure A-2 Local Operator Station Control Nodes and Information Flow ................................. 149 

 

 

 

xii 

SUMMARY 

The ubiquity of cellular networks has exploded over the last half decade making 

internet access a given when located in an urban settings. On top of this, new 

technologies like 4G LTE provide higher transfer speeds than ever, permitting streaming 

of video and other high bandwidth services. Though cellular networks are not new, few 

studies have leveraged this particular communications method when studying 

teleoperations, due to the significant bandwidth restrictions.  

As a result, this study seeks to understand whether teleoperation could be 

implemented over regular cellular networks where the bandwidth load that each cell 

tower is subject to cannot be controlled by the teleoperation system. For this, a prototype 

system is built using a remote controlled golf cart that hosts a multimedia link between 

the vehicle and a control station which communicate over the internet.  

The system is tested by measuring teleoperation for 3 different tasks of varying 

degrees of complexity. The results reveal that latency can be low enough to optimally 

control a remote vehicle. Nevertheless, the performance greatly depends on the network 

conditions that can vary significantly. The results also indicated that in-situ driving 

outperformed remote operation. 

xiii 

 

 

 

 

 

CHAPTER 1

  

INTRODUCTION 

1.1 Motivation 

Teleoperation has been an ever-evolving field in science and engineering since 

the mid twentieth century. It spans through several fields and depends on collaboration 

of a wide array of disciplines providing benefits to several industries ranging from 

sociology to space exploration. Though it may encompasses a plethora of fields, at its 

roots teleoperation is simply a system that encompasses a master, or operator station; a 

slave, or remote environment; and a communications link that bridges both sides.  

For teleoperations to evolve, advances have to occur on the operator station, the 

remote environment or the communications link. As time has gone by, more complicated 

system have risen and enabled development on the master side due to advances in user 

interfaces, augmented reality or heighten Situational Awareness (SA). Similarly, the 

slave side has evolved allowing for operators to preform microsurgeries, safe operation 

in hazardous locations and remote operation in space. All the while the communications 

link has grown and improved long range control allowing for bilateral control, haptic 

feedback and other latency driven investigations. 

As every facet of teleoperations grows at huge paces, the communications link in 

particular, spurs growth that leverages wireless technology and grants high degrees of 

autonomy. Originally, teleoperation was conducted through wired connections between 

the master and slave systems. As telecommunications evolved into the radio frequency 

 

1 

spectrum, wireless control of the master and slave system allowed them to be 

decoupled. The distance between the systems depended on the extent of the 

communications infrastructure, where longer ranges required more elaborate setups. 

With the advent of internet, a democratization of long range communications came that 

allowed for organizations with reduced infrastructure capabilities to connect over longer 

distances. As communication strategies gradually improved, data transfer rates grew 

and end to end latencies decreased. However, the “last mile” implementation of wireless 

systems still depended on installing hardware that have short range limitations, like Wi-

Fi.  

A sub category that has exploded in the recent years, seeking to reduce or even 

eliminate the “last mile” problem, is cellular technology. Though not new in wireless 

communications, the advent of 4G has significantly improved data transfer speeds and 

latencies, allowing teleoperation to open up new avenues and demographics that were 

previously unattainable due to infrastructure and cost restraints (Ericsson, 2015).  

As will be seen in Chapter 2, some studies have already delved into 

teleoperation via cellular networks, using 3G and 4G protocols successfully. But what is 

understood as a successful implementation of a teleoperated system in some 

investigations does not imply that the technology is capable of reliably and effectively 

controlling a remote system. Hints of this can be inferred when studying relevant 

author’s conclusions, where recommendations to further research connection loss 

protocols or implementing more autonomous algorithms imply difficulties in controlling 

the system with a cellular communications link.  

 

2 

With this in mind, it is intent of this study to further delve into cellular 

teleoperation and determine to what extent the use of cellular networks can be 

leveraged.  

1.2 Objectives 

The main question behind the research conducted herein is whether a cellular 

network offers a reliable connection capable of properly controlling a remote vehicle. 

Many investigations tend to reduce this down to whether or not the system has enough 

bandwidth or a low enough latency. However, this sometimes tends to be subjective and 

limits for latency can range from just a few tens of milliseconds to over five hundred 

milliseconds and a similar situation arises with band width.  

Moreover, just measuring certain aspects of the connection does not guarantee 

that the operator is capable of effectively driving a remote vehicle. In other words, it is 

possible for the system to perform nominally when measuring the through-put in 

megabits per second and time delay in milliseconds, but these parameters speak very 

little about the resolution that the operator observes, how the remote environment is 

being interpreted by the driver or whether other aspects of teleoperation are causing 

strains on operator performance.  

Understanding that there are benefits and limitations to any method that seeks to 

measure performance, this study believes that metrics used to interpret how well an 

operator executed a task may better determine how well the entire system allows for 

effective and reliable control of a teleoperated system. This way, system reliability is 

indirectly measured by assessing the operator’s global performance. 

 

3 

The principle hypothesis of this investigation is to determine whether “a vehicle 

can be controlled over a 4G LTE network, streaming HD video feedback”. Generally 

speaking, two issues have to be successfully complete for the hypothesis to be 

considered valid. The first relates to the quality of the visual feedback that the system 

incorporates. In this case, it is expected that the camera streams captured on the remote 

environment be of the highest quality possible, and for these to be able to be transmitted 

back to the operator. The second relates directly to the performance that the drivers 

show while operating the system. If both issues are achieved successfully, then in can 

be said that the principle hypothesis is accepted as true.  

On top of this, a secondary hypothesis is stated later in this thesis regarding to 

how performance is affected due to camera position. Due to how the teleoperation 

system is built, this investigation has the unique opportunity of comparing operator 

performance in function of the positions of the cameras. This is further explained in 

Chapter 3, but generally speaking, the system can be configured with cameras in 

different locations providing the driver with two points of view while completing each 

task. Because of this, a comparison of performance can be established between 

different points of views and subsequently, if a statistically significant difference exists, 

one point of view can be said to be better than the other. 

1.3 Thesis Structure 

Intent on accomplishing the objective detailed in the previous section, this thesis 

is structured in the following manner. Chapter 2 details relevant information regarding 

teleoperation, research that others have performed regarding teleoperation with cellular 

networks and how others have measured performance. Chapter 3 describes the 

teleoperation system built in this thesis used to determine the validity of the principle 

 

4 

hypothesis, explaining each sub category and how they all tie together. Chapter 4 details 

the experimental design and the statistical tools used to analyze the experiments that 

help determine the validity of the principle hypothesis. Chapter 5 shows the results 

obtained from the experiments and delves in a discussion of the observed results. 

Finally Chapter 6 concludes this investigation by summarizing the works conducted in 

this study and detailing possible future works. 

 

 

5 

CHAPTER 2

  

LITERATURE REVIEW 

Though one could perhaps wright a whole book detailing every step that 

teleoperation has taken and how its offspring’s have shaped current research, this study 

is mainly concerned in providing basic concepts of what teleoperation is so that the 

reader can understand the decisions involved that guide this investigation. With this in 

mind, a brief overview of teleoperation methods and current applications are presented 

in this chapter. Common methods for measuring teleoperation quantitatively and 

qualitatively are also presented and discussed. Time delay issues are detailed while 

current research and experiments related to cellular teleoperation are presented 

highlighting principle advantages and difficulties.  

2.1 Teleoperation 

Teleoperation has existed for quite some time and can be traced back to the mid-

1940s, as was done by (Sheridan, 1995) referencing a publication by Raymond C. 

Goertz who built a master slave device that manipulated radioactive material from a 

shielded distance. Others, who offer broader definitions of teleoperation, state that it can 

even be traced back to prehistoric eras, arguing that poking a fire with a stick is a form 

“manipulation from a distance” (Liciardopol, 2007).  

Gradually, Goertz’s mechanically operated system evolved to an electro 

mechanical servo system with feedback, becoming the first modern electromechanical 

teleoperated system. From here, teleoperation exploded and similar structures have 

 

6 

been developed to explore or control remote environments ranging from underwater to 

space exploration. 

The definition of teleoperation can vary from very specific to practically 

unbounded, but one particular definition resonates with this author is: 

 

‘Teleoperation means "doing work at a distance", although by "work" we mean 

almost anything. What we mean by "distance" is also vague: it can refer to a physical 

distance, where the operator is separated from the robot by a large distance, but it can 

also refer to a change in scale, where for an example a surgeon may use 

micromanipulator technology to conduct surgery on a microscopic level. Teleoperations 

comprise a robot technology where a human operator (master) controls a remote robot 

(slave)….’ (Liciardopol, 2007) 

From here (Liciardopol, 2007) goes on to describe how a teleoperation system is 

composed and provides interesting details into frequent difficulties encountered in 

teleoperation. What is interesting, though, is that even in high level definitions little clarity 

exists when defining this type of technology. This vagueness eventually trickles down 

into even the most common issues studied in teleoperation and drives researchers to 

develop a wide array of possible interpretations to measuring performance. 

Driven by this ambiguity, and depending on the author being reviewed, 

teleoperation can be categorized into different subcategories. Commonly, authors tend 

to classify teleoperation depending on the method of control in the remote environment. 

Though some differ slightly, a good categorization of control methods is provided by 

(Swanson, 2013), who separates the system in to 5 categories: 

 

 

7 

•  Master – Slave 

•  Supervisory – Subordinate  

•  Partner – Partner 

• 

• 

Teacher – Learner 

Fully Autonomous 

These will be explained in the following section. 

2.1.1 Master-Slave 

As described by (Swanson, 2013), basically every teleoperated system is 

composed by two main environments, Operator and Remote, linked together by a 

communications protocol. In Figure 2-1, one can view a general diagram that explains 

how a Master – Slave system is organized.  

Figure 2-1 Master-Slave System (Swanson, 2013) 

 

In essence, the operator inputs command through the physical interface to the 

command processor that transmits the signals to the actuator controller. This in turn 

commands the actuator movement generating a reaction in the remote environment. 

8 

 

 

Simultaneously, the sensory feedback is collected and passed to the sensor processor 

to be sent back to the feedback processor in the operator environment. Subsequently 

these are passed to the operator and a response is triggered starting the cycle again.  

2.1.2 Supervisory – Subordinate  

Another common category used in teleoperation is supervisory control. Here the 

general environments are similar to the Master – Slave system, but the control blocks 

that compose these are changed so as to allow for different levels of autonomy. 

Figure 2-2 Supervisory-Subordinate System (Swanson, 2013) 

 

The remote side is tasked with the majority of the computing power in order to 

allow the algorithm to perform preplanned tasks. Feedback is continually sent to the 

operator environment so as to verify that the system is operating correctly, and in the 

event of corrective measure being need, the operator can send instructions to the task 

algorithm to complete. 

 

9 

 

 

2.1.3 Partner – Partner 

The Partner – Partner configuration is unique due to the change in paradigm, 

where the action takes place in the operator environment instead of the remote 

environment. Here, the remote environment supports the actions taken by the operator 

through sensing and corrective signals transmitted back to the operator environment. 

Figure 2-3 Partner-Partner System (Swanson, 2013) 

 

2.1.4 Teacher – Learner 

The teacher learners system is a mix between supervisory control and master 

slave architecture with the exception that the remote environment includes a control 

block that has a learning algorithm. This algorithm is in charge of progressively taking 

more control of the remote side so as to ease operator strain. 

10 

 

 

Figure 2-4 Teacher-Learner System (Swanson, 2013) 

2.1.5 Fully Autonomous 

Lastly, autonomous remote control of the vehicle allows for the remote system to 

guide itself, being able to complete tasks without any supervision form the operator 

environment. However, feedback is still available to the operator.   

 

 

Figure 2-5 Fully Autonomous System (Swanson, 2013) 

11 

 

 

2.1.6 Current Applications in Teleoperation 

As time has transpired and new methods for remotely controlling robots have 

evolved, ever more uses have been developed for teleoperated system. Most would be 

familiar with larger media displays such as NASA’s moon and mars explores, but several 

industrial applications exist that are essential to productivity. Current applications worth 

mentioning are detail in the following section. 

2.1.6.1 Space Applications   

Space provides a unique environment for teleoperation. Due to the limiting 

circumstances astronauts face while in orbit, or even on earth, remote operation of tools 

and vehicles is fundamental. Key examples are; vehicles sent to other planets, like the 

mars rover, or crane arms used for space repairs or docking procedures. The author 

(Liciardopol, 2007) divides space teleoperation into 3 main categories: 

•  Space exploration robots: robots sent as a first interaction mission for gathering 

initial telemetry. Examples of this are:  

Landing robots (Sojourner (NASA), Rocky I-IV (NASA), Lunakhod I (Russia)) 

- 

- 

- 

Explorer probes: (Voyager (NASA)) 

DEEP Space Observers (Hubble Observatory) 

•  Satellites: robots that provide communication, weather forecasts, GPS, among 

other functions. 

•  Outer-space robot arms: that provides an extension that may execute tasks 

without requiring humans to be exposed to hazardous situations. 

 

12 

2.1.6.2 Military/Defensive Applications 

The military has, for a long time, used teleoperation in several different ways with 

a primary focus of reducing human exposure to dangerous situations. Some of the most 

advertised applications are Unmanned Air Vehicles (or UAV) for reconnaissance and 

long range strike missions; using radio or satellites as a communications medium. 

Another known application is Unmanned Ground Vehicles (or UGV) used for 

reconnaissance, route clearing or land-mine detection. One of the newer models used in 

this application is SARGE (Liciardopol, 2007), that is commonly equipped with state of 

the art stereo vision or auxiliary sensors so that the operator can execute the tasks 

quickly and efficiently.  

2.1.6.3 Toxic environments 

In toxic or radioactive environments, human presence is generally avoided or 

even restricted.  Due to this limitation, an overwhelming amount of tasks specific 

teleoperated machines have been developed for executing tasks that human cannot 

complete, due to the dangers of the remote environment (Cui, Tosunoglu, Roberts, 

Moore, & Repperger, 2003). 

2.1.6.4 Telerobotics in Forestry and Mining Applications 

Due to the unique risks that that forestry and mining operators face, several 

efforts have been made to design and build specialized equipment with teleoperation 

capabilities. An example of this is the Centrauroid robot developed by the Helsinki 

University of technology; whose particular design emulates human maneuverability in 

complex forest terrain (Liciardopol, 2007). Some other applications that may be seen in 

mining are:  

 

13 

•  Heavy machines: such as tunnelers, excavators and crushers that can be remotely 

operated enhancing plant autonomy and reducing human exposer. 

•  Exploratory robots: that allow for inspection of risky mines from secure locations, 

such as the Groundhog developed by the robotics institute at Carnegie Mellon (Morris, 

2005). 

•  Rescue robots: that allow search and rescue operation potentiality unstable mines 

in events of collapse or other unsafe circumstances, such as the cave crawler, also 

developed by Carnegie Mellon. (Baker, 2005). 

2.1.6.5 Telesurgery 

Teleoperation has even been seen in the medical industry allowing physicians to 

perform delicate tasks that were previously unimaginable for humans. As previously 

defined, “remote” can be understood as a large distance between the operator and 

environment or even as a “difference in scales”. Particular examples of these two 

meanings are the studies carried out by NASA (Liciardopol, 2007) and (Korte, et al., 

2013) or by the Da Vinci Surgical system. In the case of NASA, they wanted to 

understand how much time delay was acceptable in a low orbited teleoperated surgery, 

concluding that delays of more than 1,5 seconds could not be accepted. Or the surgical 

system developed by Da Vinci Surgery that allows for physicians to conduct micro 

surgery in patients with minimal incisions. 

2.2 Quantifying Teleoperation 

Having seen the several ways that teleoperation systems can be constructed and 

the plethora of different industries that depend on properly configured systems, it 

becomes apparent that classification of these systems in function of their performance is 

 

14 

required for proper comparison and decision making. However, as may be expected, no 

one method exists when measuring teleoperation performance; where commonly each 

investigation determines a quantification strategy based on their goals and objectives. 

Due to this, a survey of current investigations is completed and a brief description of the 

different methods encountered is described.  

By far, the most common form of quantifying teleoperated systems is by 

analyzing the time domain response of actions on the master side and studying their 

reactions on the slave side, (Swanson, 2013). While other popular method often used in 

unison with the previous, is to analysis the systems in the frequency domain (Tanner & 

Niemeyer, 2005). Though these methods provide good comparison of how the system is 

performing when stimulated with predetermined signals, they don’t always reflect how 

users are conditioned by other factors, such as time delay of the video source, resolution 

of the video feed, variability of the time delay or any other factor not included in their 

study.  

quantifying it. 

Strictly speaking, these factors are not commonly associated with teleoperation 

but rather studied as a part of telepresence. None the less, performance in teleoperated 

system is believed to be directly proportional to telepresence. Due to this, this 

investigation also delves into telepresence and presents different methods for 

When thinking of telepresence, a lot less ambiguity surrounds its definition. An 

overwhelming number of studies define it as “the ability of the remote environment to be 

relayed back to the operator” in a way the he is optimally immersed (Preusche & 

Hirzinger, 2007). At its most basic, telepresence is any feedback that the system 

provides its user. This may range from videos streams sent back, force reflection of the 

 

15 

environment or even audio queues that give the user a sense of where objects may be 

located. Though at first glance these concepts may seem easy to quantify, no one 

method exists when measuring said concepts. Thus, most research that investigate 

these factors tend to focus on indirect metrics or the Situational Awareness (SA) that the 

operators have while manipulating the teleoperated system. Situational Awareness may 

be understood as the perception of the environment over time and space.  

2.2.1 Quantification Strategies for Teleoperation 

Since quantifying performance of a teleoperated system by just analyzing the 

time or frequency domain does not offer a holistic view of performance, this investigation 

has decided to review methods that try to determine global metrics of overall 

performance or telepresence. With this in mind certain studies that apply this type of 

quantification are reviewed.  

An example of the previous can be seen in (Halme, Suomela, & Savela, 1999), 

where the authors compare different camera setups, such as: stereo-vision with head 

tracking, mono-vision and video display on a screen. Their hypothesis is that “the more 

expensive the configuration of a video setup is then the better the operators can perform 

required tasks”. To quantify this, they submit several subject to different tasks and 

monitor how many errors they make and how long it takes them to complete the required 

tasks. Additionally, each participant is then required to complete a personal opinions 

questionnaire of their experience. They determined that while the more sophisticated 

setup did provide better results (less total error deviations and times) they marginally 

outperformed simpler configurations. Furthermore, in some tasks, it did not matter how 

complex the setup was and not benefit was perceived between setups. Nevertheless, 

they conclude that stereo vision and head tracking equipment on the remote vehicle 

does provide better overall control based on user feedback. 

 

16 

Another study that also researches how camera positions influence teleoperation 

has an interesting hypothesis. This Investigation (Saakes, Choudhary, Sakamoto, Inami, 

& Igarashi, 2013)  believes that placing the camera on an unmanned aerial vehicle will 

provide the operator with a larger perspective and thus give the driver a higher sense of 

telepresence. Again, this study indirectly measures telepresence & teleoperation based 

on performance by quantifying the amount of errors an operator makes as he passes 

through a maze and total time to complete the experiment. After completing the 

experiments and tallying the results, the researchers statistically validate their 

hypothesis by comparing the means of the metrics to different camera positions and 

determine that overhead views are better when compared to front facing cameras. 

Figure 2-6Areal View That (Saakes, Choudhary, Sakamoto, Inami, & Igarashi, 2013) Believe 
Improves Teleoperation 

 

An interesting characteristic of this quantification strategy is that it allows for the 

formulation of almost any type of hypothesis testing that relates to performance of 

teleoperation or telepresence. Such is the case of (Vasilijevic, Nad, Miskovic, & Vukic, 

17 

 

 

2014), a study that sets out to see if perhaps a binaural signals can be used to guide a 

teleoperator. Here they focus on setting up a feedback interface that relies solely on 

binaural headphones that emit a pinging signal of an object that they wish the operator 

to follow. Later, when the results are computed, they compare how well the driver was 

able to follow the sound signal based on an optimal path. Their findings are that it is 

possible to follow an object using purely auditory signals and that this may be used to 

augment user perception of the remote environment. 

From the previous examples, a general method can be seen where each study 

selects specific characteristics attributed to operator performance while utilizing the 

system. These characteristics, such as deviation from path, total time of completion or 

errors per task, work as a reference point of off which general system performance 

standard can be established. By doing this, the researchers indirectly determine how 

well the system performs on a global level and then conclude the validity of their initial 

hypothesis. In otherworld’s, if they hypothesize that “trait A is better than B”, then they 

would subsequently need to complete tests that incorporate trait A and measure the 

appropriate metrics. Afterward, they would conduct the same experiments with trait B. 

Later, they would have to compare the results of the metrics and only then would they be 

able to determine if one trait outperformed another. 

2.2.2 Telepresence 

Up to now, we’ve seen that some studies try to quantify teleoperation by linking it 

to operator performance; however more direct links can be established through 

Situational Awareness. This being said, these methods tend to rely on subjective 

parameters such as questionnaires performed during or after the participants complete a 

task. Some commonly used methods that appear in literature are Situation Awareness 

 

18 

Global Assessment Technique (SAGAT), Temple Presence Inventory (TPI) or NASAs 

Task Load Index (TLX).  

Each of these methods tries to quantify how immersed a user is in the 

experience displayed. In the case of SAGAT the researcher must carefully prepare a 

questionnaire that is believed to be able to describe how aware an operator is of events 

currently happening. The questionnaire should be drafted so that it can measure SA in at 

least 3 levels, these being: level 1, perception of data; level 2, comprehension of 

meaning; and level 3, projection of the near future. In (Endsley & Garland, 2000) the 

authors describe an example oriented towards remote operation of an aircraft and tries 

to validate SAGAT  by subjecting operators to different user interface configurations, 

measuring SA for each. 

 Another method found in literature is the Temple Presence Inventory (TPI) 

(Lombard, Ditton, & Weinstein, 2009) though its use is slightly different. Not intended to 

measure SA, it is designed to be used as a measure of the amount of immersion a user 

is capable of achieving while viewing video streams. These researches make a 

difference between 6 dimensions of presence, though they admit that other studies may 

suggest higher dimensions. The authors believe that everything can be summed up into 

just: 1- presence of transportation, 2- presence of realism, 3- presence as immersion, 4- 

presence as social realism, 5- presence as a social actor as a medium and 6- presence 

as medium as social actor. They later explain that one can try and measure these 

dimensions in various ways, such as recording facial expressions of users or developing 

questionnaires. They determine that the simplest and most effective way is via surveying 

users and thus develop TPI. Subsequently, they describe how to develop a 

questionnaire capable of measuring all the dimensions specified and later validate their 

work.  

 

19 

Alternatively, in the late 80’s, NASA developed a Task Load Index (TLX) that sets 

out to quantify how demanding a teleoperation task may be.  This is by far the most 

common metric used when subjectively trying to determine how “hard” a remote 

operation task is. The method states that teleoperation workload can be characterized 

by six dimensions: Mental Demand, Physical Demand, Temporal Demand, Performance 

Effort and Frustration. With this in mind, a questionnaire is handed to the operator after 

completing the required task, and they are instructed to rate each dimension. An 

example of the NASA TLX questionnaire can be seen in APPENDIX B page 1. 

In this thesis a questionnaire is developed with the intent of rescuing the 

operator’s opinion of how demanding the tasks were and how well the system 

responded to their inputs. The NASA task load index is used along with a questionnaire 

designed specifically for this investigation. More information regarding this questionnaire 

is available in APPENDIX B. 

2.3 Internet Based Time Delays 

Heretofore, we’ve explored general definitions of teleoperation and telepresence. 

However, the main difficulty when implementing wireless teleoperations systems 

pertains to how information is sent from the operator side to the remote side. In this 

section a brief description of some communication strategies are discuses and a 

description of complications encountered in internet based teleoperation are detailed. 

(Hokayem & Spong, 2006), a well-known survey in teleoperation, provides a 

helpful recount of teleoperation trends through time and current research focus; by 

skillfully explaining how different technologies and communication mediums have 

shaped modern teleoperation. They argue that the main points of interest in modern 

teleoperation, from a controls perspective, are bilateral control and time delays in 

 

20 

communication; highlighting the fact that the main goals are how to maintain or improve 

system stability and transparency in telepresence. 

At its simplest, the main task of bilateral control is to provide the user with haptic 

feedback in such a way that the operator can physically interact with the remote 

environment while the maintaining system stability. As one can imagine, if time delay in 

the system is significant the user may “feel” and react in accordance to erroneous stimuli 

that ultimately reduces stability in the teleported system. Hence this issue has attracted 

many researchers to propose several methods for handling this type of situations, like: 

wave variable, smith predictors and Supervisory control methods, among others (Cui, 

Tosunoglu, Roberts, Moore, & Repperger, 2003). 

The main cause behind time delay in teleoperation is centered on the inherent 

difficulties of how information is sent through the internet in wireless connections 

(Hokayem & Spong, 2006), i.e. packet switched networks. In essence, packet switching 

is the grouping of data into packets of bytes that are routed through a network so that 

the communication medium is only occupied while transferring the content of the packet. 

This data transfer method is most commonly used when communicating between 

computers over the internet and provides both advantages and disadvantages when 

compared to circuit switched networks. The main advantage is that the communications 

channel is only used while transferring packets, thus freeing it up to be able to connect 

more devices, but its drawback is that the amount of time that a packet may take to 

reach its destination is not known and will vary depending on when the packet is sent 

and the rout that is individually selected for each packet.  

 

21 

 

 

Figure 2-7 a) Circuit Switch Network. b) Packet Switch Network 

 

Packet switching can be classified into two modes of sending information, 1- 

connectionless packet switching and 2- connection-oriented packets.  In connectionless 

packet switching, each packet is addressed according to a selected protocol and 

subsequently sent into the network; this normally leads to each packet following different 

paths in the net and commonly results in out-of-order delivery. This in hand causes 

latency variance and, when applied to teleoperation, can ultimately lead to an unstable 

system. On the flip side, in general, the protocols that utilize this data transmission 

method tend to be much quicker than connection-oriented schemes and thus tend to be 

the preferred method for data transfer in streaming or general data transfer over the 

internet. One of the most common connectionless protocols is User Datagram Protocol 

or UDP, Figure 2-8. 

 

22 

Figure 2-8 Sample IP Packet (Northrup, 2016) 

 

In contrast, connection-oriented packet switching is a method that tries to 

guarantee the delivery and order of the packets sent. It accomplishes this by adding 

extra information to the header that provides a sequence number. This way, it can 

reconstruct the information in the appropriate order once it is received at the addressed 

computer. The extra information attached to each packet added to the reconstruction at 

the client computer adds further delay and, though quality is improved, the overall 

system latency is increased. The most common method for transmitting information like 

this is Transmission Control Protocol or TCP.  

Figure 2-9 TCP and UDP Packet Headers (Microchip Techonology Inc., 2016) 
 

 

23 

 

 

 Descending a few steps closer to the physical layer of the OSI classification of 

computer communications (International Organization for Standardization, 1996), 

different protocols that dictate how information should be parceled and subsequently 

transmitted over the physical layer exist. The physical layer is understood as the 

wireless medium used for connecting two or more users. The most commonly 

encountered technologies are Wi-Fi 802.11n, Bluetooth, 4G LTE and Dedicated Short 

Range Communications (DSRC). Each of the previous has unique advantages or 

disadvantages depending on the goals to be accomplished. For example, DSRC tends 

to have lower data rate throughputs, but significantly lower latencies, longer ranges and 

can be used at higher moving velocities (Harding, et al., 2014), therefore a general 

tendency exists to incorporate this medium into vehicles and hopefully improve safety. 

On the other hand, Bluetooth has lower data rates, but shorter distance and lower power 

consumptions; therefore they tend to be found in consumer mobile devices. Table 2-1 

highlights principle characteristics of these different communications protocols. 

Table 2-1 Wireless Technology Comparison (Meier, 2005); (IEEE, 2009); (Zanchi, 2014); 
(Rysavy Research, 2013) 

Type 

Throughput  Range 

Bandwidth 

Mean Latency 

Bluetooth 

3 [Mbps] 

50 [m] 

2.4 [GHz] 

25 [ms] 

DSRC 

54 [Mbps] 

1000 [m] 

5.9 [GHz] 

2 [ms] 

4G LTE 

70 [Mbps] 

>5000 [m] 

700-2500 [MHz] 

50 [ms] 

Wi-Fi 

600 [Mbps] 

100 [m] 

2.4 & 4.9 [GHz] 

40 [ms] 

In wireless teleoperations, the most commonly used medium is Wi-Fi due to the 

large throughput and versatility it offers (Swanson, 2013) (Hokayem & Spong, 2006). 

Nonetheless, other mediums, like Bluetooth, have still been studied in teleoperation with 

24 

 

 

varying degrees of success, such as (Araque & Guerrero, 2010) and (Alshazly & 

Hassaballah, 2013).  

However, though 4G LTE is not new, little studies exist that leverage this 

communications medium in teleoperation. 

2.4 Current Applications of 4G LTE in Teleoperation 

Cellular telecommunications has existed for several decades, allowing a large 

world to progressively become smaller and more mobile. Up until recently, data transfer 

rates were restrictively low for teleoperation, but as newer communications protocols 

have spawned, i.e. 3G and 4G LTE, a rise in opportunities for teleoperation have 

appeared recently in literature (Ericsson, 2015). Most cellular based investigations 

center their efforts in controlling automobiles in urban environments so as to provide 

support to an incoming wave of autonomous vehicles. This section will briefly detail 

some works that delve into cellular teleoperations and discuss advantages and 

drawbacks of their works. 

One of the first appearances of a cellular teleoperations system, that this 

investigation reviewed, revolved around the control of a small robotic vehicle. Munoz 

(Munoz, Eusse, & Cruz, 2007) discussed the benefits of an eventual explosion in cellular 

connectivity and how this would enable a large boost in infrastructure for cellular 

connected devices. Because of this, they decided to configure a small test bed to 

determine the feasibility of teleoperating a vehicle over a cellular network. Some of their 

main concerns were data transfer rates and time delays in the system and thus centered 

their quantification strategy around gathering network variables that elucidated strains on 

the system. Furthermore, anticipating low data rates, they propose two control 

strategies; one being an autonomous system that resembled the supervisory-

 

25 

subordinate scheme, and a second more data intensive master-slave configuration. After 

constructing their system and conducting experiments to test their system, the authors 

come to the conclusion that though cellular teleoperation is possible, best results were 

achieved when using the supervisory-subordinate configuration due to latency (12.3 [s]) 

and low network transfer rates (1.1 [Kbps]).  

More than 6 years later, (Gnatzig, Chucholowski, Tang, & Lienkamp, 2013) pick 

up where (Munoz, Eusse, & Cruz, 2007) left off by using 3G and 4G cellular networks to 

control a commercial vehicle over the internet. Here, the authors construct an internet 

based teleoperation system that connects through a cellular network. On the vehicle, 

appropriate modifications are made to the steering wheel and input modules so as to be 

able to control the vehicle “by wire”, and special attention is placed on safety by installing 

several redundancies to the brake pedals. Furthermore, the authors recognize that a 

weak link in the system is the video stream throughput and, though they have installed 

approximately 4 640x480 cameras, they implicitly state that they drive the vehicle 

streaming one or two cameras simultaneously at 320x240 resolutions. To test the 

system, they drive the vehicle in what appears to be a relatively straight line for 

approximate 200 [m] in a rural area at a constants speed preset into the cruise control. 

To quantify how well the teleoperator control the vehicle, they measure the offset of the 

drivers respect to an ideal path and how often the drivers tend to steer the wheel, with 

average calculated values of 0.4 [m] and 0.25 [Hz] respectively. In this papers 

discussion, the authors state that they successfully operated a vehicle through a cellular 

connection but imply that network difficulties play an important role in overall system 

performance and believe that autonomous control algorithms should be implemented in 

case connection is lost. 

 

26 

Most recently, (Shen, et al., 2016) also built a teleoperation system around 

different wireless mediums, including 4G cellular networks. Here, the authors retrofit a 

commercial vehicle so that it can to be controlled remotely, all the while using “off the 

shelf” products and implementing stereoscopic vision. In the paper, attention is 

emphasized on achieving low cost teleoperation of commercial automobiles so as to 

support autonomous vehicles in difficult situations in urban locations. In order to 

demonstrate that they can effectively control the vehicle, they make use of a large 

parking lot and have the operator perform slalom maneuvers around cones set on the 

ground. A test is considered successful if the operator is able to complete the course 

without skipping any of the cones. On top of this, they also measure success by 

comparing network variables, such as data transfer rates and latency, to Wi-Fi. This 

study concludes that teleoperation is viable and argue that low cost systems are readily 

available. However, they do warn that certain issues like connectivity, range to a cellular 

tower and speed of the vehicle may influence optimal teleoperations via cellular 

networks. 

2.5 Summary 

The intent of this chapter was to introduce basic concepts of teleoperated 

systems to the reader so that the following chapters can be understood easily. Different 

teleoperation architectures are introduced, like: Master-Slave, Supervisory-Subordinate, 

Partner-Partner, Teacher-Learner and Fully Autonomous. Industrial applications of 

teleoperation are detailed, such as: space applications, military applications, removing 

humans from hazardous environments encountered in mines or forestry and performing 

medical services at a distance like surgery.  

 

27 

The need for measuring teleoperation is discussed and common measuring 

strategies are described, such as time and frequency domain analysis. However, a more 

holistic approach is preferred and some examples are shown of investigations that 

derive how well a teleoperation system operates by analyzing operator performance 

using quantifiable metrics like total time to complete an experiment, the amount of error 

in the executing of a task or deviation from the ideal path. 

Lastly, Inherent difficulties in internet based communications due to packet 

switching are explained and its effects on time delay in teleoperation are detailed. 

Furthermore, studies that delve into cellular based teleoperation are detailed and the 

strengths and weaknesses are described, such as: metrics used to infer performance, 

types of experiments completed and how success is measured.

 

28 

CHAPTER 3

  

SYSTEM DESCRIPTION 

When seeking to implement a teleoperated system, a plethora of options exist 

that depend on what objectives need to be accomplished. This case is no different and 

clear goals must be established in order to optimally design the teleoperation system. 

This studies main hypothesis is “a vehicle can be controlled over a 4G LTE network 

streaming HD video feedback”; all the while trying to maintain flexibility, where flexibility 

is understood as being able to easily use the system in deferent locations without 

requiring high initialization setups, such as installing specialized programs or purchasing 

expensive hardware.  

Other constraints that further guide design efforts are: to use low cost and 

commercially available instruments, reducing the overall cost of implementation of any 

future teleoperation system; the main source of feedback must be video, eliminating the 

use of SLAM, LIDAR point cloud reconstructions on the operator environment or optical 

flow analysis of the video stream that might reduce the overall data stream of video 

feedback.  Furthermore, the cameras must also be commercially available and 

compatible with real-time streaming. The Modems that connect to the cell towers must 

be commercially available 4G LTE modems along with commercially available data 

plans from any cellular network provider, and any data plan that is purchased cannot 

have preferential treatment when connecting to the cellular network or being assigned 

bandwidth. 

 

29 

Also, due to the inherit dangers of remotely operating a large vehicle (Swanson, 

2013) it was decided a full sized automobile would not be used. However, with the intent 

of replicating the interactions present while driving, a golf cart is selected as the remote 

vehicle, thus simplifying safety management.  

Figure 3-1 General Teleoperations Configuration 

 

 

detailed.  

Understanding the primary objective and vehicle size constraint established, a 

brief summary of system alternatives will be discussed and the actual system will be 

Several configurations exist when designing a teleoperation system, all linked by 

a general design that requires an Operator – Remote Environment connected through a 

communications medium, as seen in Figure 3-1. This studies primary objective is to use 

a 4G LTE communications protocol to relay information between each actor in the 

system, but this type of communications protocol inherently introduces complications 

that must be addressed with proper design methods and considerations. Therefore, as 

seen in CHAPTER 2, the teleoperation system will be implemented following the Master-

Slave configuration while incorporating safety protocols from the Supervisory-

Subordinate system. 

 

30 

The following chapter is divided in to three sub sections that analyze the system 

and better detail how it all integrates together. The subsections are divided into: 

• 

• 

• 

The General Teleoperations Platform section, which determined the systems 

architecture and what programs are used in order to achieve teleoperation.  

The section Remote Vehicle System, describes the control architecture and 

provides further insight into how the remote system in built. 

The section Local Operator Station, details how information is captured and what 

the operator will be exposed to while driving the teleoperation system. 

3.1 General Teleoperations Platform 

Several alternatives to building a teleoperations system exist. Most cases 

determine which system is to be used based on the investigations overall objectives. In 

one example, as seen in (Marin, Sanz, & Sanches, 2002), the researcher’s main interest 

is to propose a control system that can manipulate a robotic arm in a web based 

environment; thus the authors decide to build their system on a Java, Java3D and Cobra 

platform. (Vozar & Tilbury, 2014), seek to emulate latency filled teleoperation, for this 

they used Java programing language along with robotics specific libraries such as April 

Robotics Toolkit (APRIL) and Lightweight Communications and Marshaling (LCM) in 

order to simulate a remote environment and control time delays in the artificial 

communications link. Yet another system, and arguably one of the more popular 

alternatives, as described by (Swanson, 2013), is using Robot Operating System (ROS). 

This program is based off of Linux and has a large community that continually writes 

new libraries on diverse robotics subjects while simultaneously troubleshooting common 

issues.  

 

31 

Though all these options provide unique advantages when compared amongst 

each other, it is important to factor in the particular difficulties of teleoperation when the 

communications link is based on cellular networks. Taking this into consideration, a 

platform should be selected that minimizes these risks while complying with this studies 

main objectives.  

At its most basic, the teleoperation system could be illustrated as in Figure 3-2.  

Figure 3-2 Cellular Network Teleoperation Scheme 

 

The image shows how the information travels through the network crossing 

different nodes, be it cell towers or internet service provider nodes, and ultimately arrives 

at the operator station. Specifically, information captured on the remote vehicle is sent 

via the communications link to the nearest cellular tower. The tower in turn, transfers the 

information through the internet to the destination computer that, in this case, is located 

on the Georgia Tech Network. Despite only 4 nodes being illustrated: remote 

environment, cell tower, ISP nodes, and operator environment, these are not necessarily 

the total amount of nodes that the data will be relayed through, where the actual number 

may be much greater. 

32 

 

 

 Furthermore, here the main obstacle is not the amount of nodes, but rather if the 

information passes through nodes that belong to different networks. This is important, 

because as the information approaches its destination, it may pass through firewalls. If 

so, special permissions may be needed or different interconnection strategies required. 

And, as expected, when entering the Georgia Tech network, the information must pass 

through a firewall. 

Fortunately there are methods that allow for incoming information to pass the 

firewall, but these require certain considerations to be in place when designing the 

overall system. Without delving deeper into this specifics of the issue, a common method 

for sidestepping firewalls is to use “Session Traversal Utilities for NAT” (STUN) or 

“Transversal Using Relay around NAT” (TURN) servers, (Dutton, 2013). Here one 

makes use of a server that resides out of the destination network that allows for relaying 

information through firewalls. 

Several methods exist that can achieve this, but luckily a few companies already 

exist that facilitate access to STUN/TURN server. One of these companies is Tokbox, an 

enterprise that is built around webRTC, an open source real time communications API, 

which enables browser to browser communications using video chat and messaging 

sessions, without the need of specialized software.  

Given the fact that the primary goal is to be able to transmit information through a 

4G LTE network that requires the use of STUN/TURN servers, and the company Tokbox 

that provides this service that incidentally is built around open source video conferencing 

software. This group decided to take advantage of the overlap, and build the system as 

a web app that uses web browsers as a platform. 

 

33 

Furthermore, the secondary objective of facilitating flexibility is achieved by 

building the system based on a browser environment, which is possible due to the fact 

that the TokBox is built around webRTC. Thus, by using web apps the platform 

leverages system flexibility, because virtually all computer that have internet access use 

web browsers, maintaining prerequisites for the system as low as possible.  

On top of this, it was decided to keep to one programing language as much as 

possible. With this in mind, and since system would be web based, JavaScript was 

chosen as the primary reference language. Consequently, node JS, a JavaScript 

interpreter, is used to host a server and control interactions on the remote vehicle. 

Having elaborated on the causes for selecting this teleoperation system 

architecture, Figure 3-3 details the resulting configuration of the system. Here, one can 

distinguish the categories previously described and how they interconnect given the 

current constraints. 

Figure 3-3 Teleoperation System Architecture 

 

 

 

34 

The Remote Environment and the Operator Environment represent the nodes 

that this study can directly control. Where the other nodes, cell towers and internet are 

considered black boxes and no influence exists over them. The operator environment 

represents the main interface of the system with the driver, and is where all the control 

signals are generated. While the remote environment is the actual vehicle to be 

controlled and where the feedback signals are generated and sent back to the operator 

station. 

session and, 

provided.  

Generally speaking, two actions must occur for the system to be activated and 

allow teleoperation of the remote vehicle:  

1. 

The remote vehicle must launch a server which initiates the communications 

2. 

The operator must start the user interface and open the operator web page 

establishing contact with the communications session on the vehicle.  

In the continuing sections further detail as to what each subsystem does, shall be 

3.2 Remote Vehicle System 

Using Figure 3-3 as a guide, the teleoperations system is initialized on the 

remote side by prompting node JS to create a server. This server in turn establishes a 

communications link between the remote vehicle and the operator station; and 

simultaneously monitors the vehicles microcontroller. The main objective of establishing 

a communications link is to relay control information from the operator station to the 

vehicle and at the same time transmit feedback to the driver so that he/she can control 

the automobile in real-time. 

 

35 

To better understand how the remote vehicle is controlled, it helps to visualize 

how information flows through the system, as seen in Figure 3-4. Here, the incoming 

information is every signal that the operator sends and that generates change in the 

remote vehicle, while all the outgoing signals represent the feedback that the driver 

requires to be able to reconstruct the remote environment and take appropriate action. 

Though the following representation of the system is slightly different to how it has been 

shown previously, this illustration allows for better identification of information flows and 

control nodes in the system.  

 

Figure 3-4 Remote Vehicle Control Nodes and Information Flow 

 

Using the previous figure as a guide, more detail is provided as to what 

information is present in each stream line. A brief description regarding what data is 

being transmitted and why, as well as data transformations in the program blocks are 

detailed herein. Further description of the system is available in APPENDIX A. 

•  Remote vehicle information flow: 

- 

Incoming Signals, line 1: This line represents all the information that is 

captured on the remote vehicle coming from the operator station. It contains 

36 

 

 

all the data necessary to maneuver the steering wheel while providing more 

or less thrust and ancillary control signals for triggering camera views or other 

supplementary functions. 

- 

NodeJS-cart, lines 3 & 4: Once the information is received and processed in 

the main program, this is in turn parsed and sent to the microcontroller on the 

vehicle or motor drive, so as to manipulate the remote environment. 

- 

Cart-NodeJS, lines 5, 6, 7 & 9: As the cart is being feed control information 

from the main program, it too is sending information back regarding how the 

environment is changing. In particular, the vehicle is equipment with cameras, 

a LIDAR and other sensors that help the operator understand what changes 

are taking place on the remote vehicle. 

-  Outgoing, line 10: Finally, all the information is sent back to the operating 

station so that the operator can decipher the information and take appropriate 

steps to guarantee smooth and safe control of the vehicle. 

•  Remote Vehicle Control Nodes: 

- 

Node JS: the nodeJS interpreter contains the main program and the 

index.html file. The Index.html file acts as the interface to all of the incoming 

and outgoing signals that the cart receives. The main program is tasked with 

interpreting, scaling and transferring the signals to the microcontroller through 

the corresponding physical ports on the computer. On top of this, the main 

program aggregates external sensor information and implements safety 

measure as required. 

-  Microcontroller: the microcontroller receives the translated control signals 

form the main program and converts them in to signals that the different 

elements within the system understand.  

 

37 

- 

Cart: the cart in the main body that is being controlled. It responds to the 

control signals sent from the microcontroller and simultaneously provides 

feedback to the main program by means of the various sensors that it 

houses. The sensor that are available on the cart are, a hall effect sensor for 

measuring wheel displacement, LIDAR for detecting objects in close 

proximity, a gyroscope and HD video cameras. 

An important component of the remote system is the actual vehicle to be 

controlled. The golf cart houses all of the importation components that permit the system 

to relay information from and to the operator. Figure 3-6 details that specific location 

where the components are placed and a brief description is provided of each 

component. 

Figure 3-5 Remote Vehicle – Golf Cart 

 

 

 

38 

4a 

3 

2 

4b 

1 

 

Figure 3-6 Remote Vehicle System Break down 

1.  Computer, item 1: The computer is the main interface to all systems onboard the 

remote vehicle. I connects all sensors cameras that provide video feedback (4a and 

4b). It communicates with the microcontroller that translates all signals to and from the 

vehicle. And provides the communications link to a local cellular tower through a 4G 

LTE modem. Furthermore, it also runs the programs and control logics previously 

described. 

2.  Controller, item 2: The Controller is composed of 2 main sub categories: the first 

a micro controller that translates signals sent form the Computer and the second the 

vehicle specific controller. In this case, this project uses the microcontroller to emulate 

voltages between the acceleration and brake encoders and the vehicle controller. By 

means of a pulse width modulation (PWM) signal, the controller is made to think that 

the encoders are being actioned and consequently it takes action by signaling the carts 

39 

 

 

main engine. The microcontroller also translates signals from the computer to the 

stepper motor drive. It receives the required angle position from the computer, 

calculates the steps the steering motor needs to reach said position and signals the 

drive to take the appropriate action. Furthermore, the microcontroller relays information 

from auxiliary sensors to the main program in the computer. The sensors that are 

captured are the Hall Effect sensor for measuring wheel displacement, LIDAR for 

detecting objects in close proximity and a gyroscope for detecting the vehicles angular 

velocity for post processing. 

3.  Steering motor and drive, item 3: The Steering motor and Drive act over the golf 

carts steering wheel. As described, the required steering wheel position is sent from 

the microcontroller to the drive. Here, the stepper motor powered from the vehicles 

power source (48 VDC), gyrates the wheel until it reaches the desired positon. 

4.  Camera and Feedback, items 4a-4b: Finally, camera feedback is provide through 

4 cameras located in the areas shown by items 4a and 4b. Two possible locations are 

used for video feedback, these being the front and back positions. An overwhelming 

amount of studies that test teleoperation system performance tend to position the 

cameras in the front of the vehicle where a clear field of view is provided. However, 

when driving a vehicle the operator is commonly located inside of the cart with visual 

feedback of onboard displays and current steering wheel position.  In prior tests, this 

study found it helpful to position the camera on the inside of the vehicle due to the fact 

that one could also see where the wheel position was during driving test. Because of 

this, this study proposes a secondary hypothesis that the “camera position significantly 

influences teleoperator performance” which is tested and analyzed in Section 5.2.1 of 

CHAPTER 5. 

 

40 

3.3 Local Operator Station 

As previously stated, the second step that must be completed to initialize the 

system is to open the operator page and establishes a communications link between the 

remote vehicle and the operator station. This station generates every control signal 

needed to properly control the remote vehicle and is setup to resemble a typical 

automobile cockpit including: a steering wheel, gas and brake pedals, a stick shift to 

signal forward and revers, along with three screens that provide a wide as possible field 

of view.  

Using the same illustration method, one can visualize the incoming and outgoing 

information form the operator page. However, in Figure 3-7 the incoming information 

corresponds to the outgoing from the remote system, and analogously, the outgoing 

from the operator station is the incoming to the remote vehicle. 

Figure 3-7 Local Operator Station Control Nodes and Information Flow 

 

 

 

 

41 

Though at first glance this system seems less intricate than the remote system, it 

is anything but that. The Operator Station combines several critical tasks into just three 

main nodes: operator station, gamepad and Graphics display. Moreover, it is tasked with 

relaying large amounts of information; all the control signals as well as all the video and 

auxiliary feedback. More detail as to of how the information is captured from the driver 

and subsequently displayed are described as well as the overall layout of the operator 

station. For further detail view APPENDIX A. 

•  Operator Station information Flow: 

- 

Incoming, line 1: The incoming information is mainly composed of the video 

stream session held by webRTC, and auxiliary feedback such as GPS 

position or LIDAR point cloud. 

-  Outgoing, line 4: The outgoing data stream on the Operator side is the same 

as the incoming stream on the remote side. 

•  Operator Station Nodes: 

-  Operator station: This principle node is manually started by the driver by 

accessing the operator web page through a browser and contains two 

processing programs: the Gamepad Node and the Graphics Display.  

-  Gamepad Node: This node represents the direct interaction that the driver 

has with the operator station. Here, the user physically manipulates the 

gamepad which detects the control signals and sends them over the data 

session previously initiated. Figure 3-8 shows the setup used. 

 

 

42 

Figure 3-8 Gamepad Setup 

 

-  Graphics display node: The graphics display is show to the driver via three 

windows each on one of the three screens that the operator has. Each 

window controls one camera in the remote vehicle providing left, right, front 

and rear camera position views. The layout can be seen in Figure 3-9. 

Figure 3-9 Graphics Display Setup 

43 

 

 

 

 

 

 

• 

• 

3-10.  

On top of providing the user with three screens for video feedback, he is also fed 

supplementary sensor feedback so as to enhance his situational awareness. The 

additional information is shown in terms of a prediction line, speedometer, a 2D LIDAR 

and a GPS map, as seen in Figure 3-9 and Figure 3-10. 

The prediction line is a visual overlay of the possible path that the vehicle will 

follow if the current settings are maintained. An example of this can be seen in Figure 

The speedometer and 2D LIDAR are shown in the bottom center of the front view 

and provide the user two important control parameters that help the operator during 

task execution. While the main function of the speedometer is clearly detail the current 

speed of the vehicle, the 2D LIDAR’s main object is to quantify the vehicles immediate 

surrounding taking the burden of guessing relative distances from a 2D image from the 

video stream. An example of this can be seen in Figure 3-9. 

Figure 3-10 Visual Example of Prediction Line Overlay 

 

44 

3.4 Summary 

Recapping this chapter, the general platform for teleoperations is presented. A 

comparison between common teleoperations systems is discussed and a browser based 

platform is chosen to be implemented; by weighing the benefits it provides over other 

system, i.e. network address translation though STUN/TURN. The general system 

architecture is presented and further detail is shown for both remote and operator 

stations. In the remote station different control nodes are detailed, explaining the 

fundamental roles each node completes. Likewise, in the operator station, control nodes 

are detailed and special considerations elaborated.  

 

 

45 

CHAPTER 4

  

EXPERIMENT DESIGN AND  

STATISTICAL ANALYSIS 

In order to properly confirm or reject any hypothesis, one must first devise a 

method of quantifying said statement and subsequently subject it to statistical analysis 

so as to determine its validity. 

As discussed in previous chapters, several studies attempt to quantify 

teleoperation by controlling time delay and measuring its effect on the driving ability of 

the remote operator (Halme, Suomela, & Savela, 1999); while others try and model how 

an operator will react to local stimuli and determine what effects these have over system 

stability and control (Vozar & Tilbury, 2014) & (Swanson, 2013). Though these factors 

are important, they are not the focus of this work, whose intent is to determine whether 

“a vehicle can be controlled over a 4G LTE network streaming HD video feedback”.  

With this in mind, this study attempts to indirectly asses the initial hypothesis’s 

validity by measuring operator performance while using the teleoperation system, and 

comparing it to performance commonly experienced while driving a vehicle locally. If the 

performance metrics are comparable, i.e. they share similar mean values, then it can be 

said that remote operators perform as well as in-situ drivers and consequently, the 

system allows for a vehicle to be controlled over the cellular network while streaming HD 

video feedback. Otherwise, two options exist: 1) the remote operator is able to perform 

 

46 

better than expected or, 2) the teleoperator cannot control the vehicle to the proficiency 

levels required.  

Herein, the reasoning behind how this study selects tasks that may capture the 

full particulars of driving are briefly discussed. Afterwards, a detailed description of the 

selected tasks and specific objectives for each are presented. Three main tasks are to 

be used for measuring performance, these being: 1) Straight Trajectory Tasks, 2) 

Reverse Trajectory Tasks, and 3) Path Following Tasks. Additionally, and as seen in 

CHAPTER 3, the camera position in the vehicle is not fixed and thus can be changed in 

between task. With this in mind, this study briefly describes how this may affect driver 

performance and details how this is varied in between tests. 

Regarding data collection, a detailed list of variables to be acquired is presented 

along with the data logging strategy. Two different data acquisition methods are 

implemented in this study. The first leverages the asynchronous nature off of which the 

system is built and gathers information as an event is triggered. The second polls all 

relevant variables at a constant time interval and simultaneously logs them. Further 

detail is provided in Section 4.3 .  

Certain variables, like vehicle position or time synchronization, require post-

processing before being able to calculate the corresponding performance metric. The 

theoretical background and post-process algorithm are detailed in Section 4.4 . 

Lastly, the statistical analysis plan used for determining the validity of the initial 

hypothesis is described. The actual analysis and interpretation of the results are 

presented in CHAPTER 5. Three main statistical tests are used for establishing whether 

the comparisons of the performance metrics are statistically significant. The test are: 1) 

the Kolmogorov-Smirnov Goodness of Fit test for determining normality, 2) depending 

 

47 

on the previous, an F-test or Levene’s test is used for comparing sample variances to 

the ground truths, and 3) a Two Sample T-test or a Kruskal-Wallis test is used for 

comparing the performance metrics mean to ground truths. 

4.1 Tasks Selected for Measuring Performance 

No unanimous consent exists regarding a metric that effectively reflects whether 

a remote driver is correctly performing the required tasks. Examples of this are shown in 

CHAPTER 2, where some studies performed tasks based on the author’s discretion. 

Furthermore, objectives could vary wildly; where a subject would be required to cross an 

obstacle course, trace a figure 8 or simply follow a circular line.  

With this in mind, this study looks at established entities whose objective is to 

quantify the ability of drivers and see if any parallels exist between them and this study 

that may be used for quantitatively measuring performance. From here, driving tasks are 

selected and specific completion criteria are described along with secondary objectives. 

4.1.1 Origins of the Selected Tasks  

In an attempt to use a standardized guide for measuring the operator’s ability to 

teleoperate the system, and due to the intentional similarities that the system has with 

automobiles, this study uses a standard driver’s license test as a guide for determining 

how well an operator can steer a vehicle.  Though the Department of Motored Vehicles 

(DMV) tests vary depending on the state in which they are partaken, there are general 

guidelines that all test makers try to guarantee; as seen in the following list: 

Minimum required skills for obtaining a driver’s license (Georgia DDS, 2015). 

1.  Parallel Parking: Park midway between two standards so that your car is not 

more than 18 inches from the curb. 

 

48 

2.  Quick Stops: Drive at a speed of 20 miles per hour and make a quick, safe stop 

when the examiner instructs you. 

3.  Backing: Back your car for a distance of about 50 feet, at a slow rate of speed, 

and as straight and as smoothly as possible. Turn your head and look back at all times 

while backing. 

4.  Stopping for Signs or Traffic Signals: Give the proper hand or brake signal; 

approach in the proper lane; stop before reaching a pedestrian crosswalk; and remain 

stopped until you can move safely through. 

5.  Turnabout: Turn your car in a narrow space using two-, three- or five- point turns. 

6.  Use of Clutch: If your car has a standard transmission, you must shift smoothly 

and correctly. 

7.  Approaching Corners: You must be in proper lane and look in both directions. 

8.  Yielding Right-of-Way: Always yield right-of-way to pedestrians, motor vehicles, 

bicyclists or anyone else who moves into the intersection before you. 

9.  Turning: Get into the proper lane and give signal an adequate distance before 

10.  Passing: Always look ahead and behind to make sure you can safely pass without 

reaching the turn. 

interfering with other traffic. 

11.  Following: Do not drive too closely behind other cars. Watch the car ahead of 

you; when it passes some reference point, such as a telephone pole, and then count 

"one-thousand-one, one-thousand-two." If you pass the same spot before you are 

through counting, you are following too closely. 

12.  Posture: Keep both hands on the steering wheel. Do not rest your elbow on the 

window and do not attempt to carry on a conversation with the Examiner because they 

will be busy giving instructions and recording your score. 

 

49 

Of the dozen of objectives previously listed, this research has chosen to focus on 

points, 2- Quick Stop, 3- Backing and 5- Turnabout; due to this studies ability to 

quantitatively measure the effectiveness of the driver’s execution of the task. In other 

words, even though driver’s license test administrators rely on personal opinion in 

determining whether a candidate has successfully preformed the given objective, the 

performance of the selected tasks are quantifiable and the logging of appropriate 

variables is readily available in the system.  

Due to the fact that the objectives of this study do not completely match those 

described by DDS , the names of each of the selected tasks are changed. Furthermore, 

the new labels are used throughout the rest of this work. The updated tasks are named: 

•  Straight trajectory Task: formerly known as task 2- Quick stop. 

•  Reverse trajectory Task: formerly known as task 3- Backing. 

•  Path Following Task: formerly known as task 5- Turnabout. 

4.1.2 Tasks and Description 

Every task detailed herein rescues certain aspects that the DOT tries to 

qualitatively measure when testing prospective drivers. Many factors are involved in 

order for an operator to be able to accomplish each and every one of these objectives, 

such as understand how the environment is changing, perceive the vehicles relative 

velocity, estimate how much inertia the vehicle has and accurately measure depth 

perception, among others. Some of these tasks are already difficult for in-situ drivers, 

and the difficulty of these is compounded when taking into account how a teleoperation 

system degrades presence. This is why, though the tasks are based off of DOT metrics, 

certain parameters are modified in order to more accurately capture possible limitations 

 

50 

the system has when acting as an intermediary between the operator and the remote 

Considering all of this, specific details regrinding how the task will be completed, 

what path the operator must follow and secondary objects are described in the rest of 

location. 

this section. 

4.1.2.1 Straight Trajectory tasks 

The Straight Trajectory Task consists of driving the vehicle in a straight line and 

stopping on a checkpoint at the end of the run. Before beginning the test, the vehicle is 

properly positioned on the initial spot making sure that it is correctly directed towards the 

final location. Figure 4-1 shows the initial location that the vehicle will be positioned in, 

along with the ideal path the vehicle will be compared against for calculating 

performance. 

In order to assure that each participant tries to accomplish the task under the 

same conditions, task specific constraints are detailed and conveyed to the operators. The 

objectives for the Straight Trajectory Tasks are: 

•  Drive as fast as comfortably possible. 

•  Maintain a speed as constant as possible throughout the whole task. 

• 

Try to deviate a minimum from the path. 

•  Attempt to stop as close as possible, hopefully on top of, the checkpoint. 

 

 

51 

Figure 4-1 Straight Trajectory Task Overview 

 

 

4.1.2.2 Reverse Trajectory Tasks 

The second task that the participants will have to overcome is the Reverse 

Trajectory Task. This test offers a substantially larger degree of complexity due to the 

fact that the operators must control the vehicle while it is moving in reverse. Initially, the 

vehicle will be positioned on top of the starting checkpoint and oriented in the correct 

direction. From here, the operator will have to toggle the reverse position and drive the 

vehicle toward the first check point located in a delineated area half way through the 

whole course. When approaching the delineated area, the operator will have to 

maneuver so as to park the vehicle with the back end towards the sidewalk. Once the 

parking maneuver is completed, the operator will have to toggle the forward direction, 

pull out of the delineated area and head in the direction of the final check point. Lastly, 

the operator is asked, once more, to stop as close as possible to, or on top of, the 

checkpoint. Figure 4-2 shows where the task was completed and overlays the ideal path 

to which each run will be compared. 

 

52 

In an attempt to maintain clear task objectives and therefore reduce participant 

variabilities, task specific goals are again detailed and conveyed to the operators. The 

objectives for the Reverse Trajectory Tasks are: 

•  Maintain a speed as constant as possible. 

•  Maintain a speed that the operator feels comfortable with (not necessarily as fast 

as possible). 

• 

• 

Try to deviate a minimum from the path. 

Try and complete the task with the least amount of stops. 

•  Attempt to stop as close as possible, hopefully on top of, each checkpoint. 

 

 

Figure 4-2 Reverse Trajectory Task Overview 

 

4.1.2.3 Path Following Tasks 

The final task that the operators have to complete is the Path Following Task. 

Again, this task presents significantly higher degree of complexity when compared to the 

 

53 

previous task due to the fact that the operator has to steer the vehicle in 180 degree 

curves along with forward and reverse parking.  

Before starting the task, the vehicle is prepositioned in the correct location and 

orientation. Once the participants are ready, they must first toggle the forward direction 

in the vehicle and subsequently start the test. Here they have to follow a straight path 

until they pass over the first checkpoint, after which they must immediately turn to the 

left. After completing a 180 degree turn to the left while passing over the second 

checkpoint, the participant must count 4 parking spots and stop his vehicle in the 

designated parking area. After this, they must toggle reverse and back out in a straight 

line so as to park in the parking area immediately behind their previous location. After 

completing the second parking maneuver, they must again toggle forward and pull out of 

the parking area while simultaneously turning to the left, in the direction of travel, so as 

to back track their previous path and go over the aforementioned checkpoints to 

ultimately stop on top of the final position. An illustration of the checkpoints and the 

maneuvers that the operator must complete is shown in Figure 4-3 along with the ideal 

path that they must follow. 

Again, specific task objectives are detailed and conveyed to the operator so as to 

reduce unnecessary variances. The goals for the Path following task are: 

•  Maintain a speed as constant as possible. 

•  Maintain a speed that the operator feels comfortable with (not necessarily as fast 

as possible). 

• 

• 

Try to deviate a minimum from the path. 

Try and complete the task with the least amount of stops. 

•  Attempt to stop as close as possible, hopefully on top of each checkpoint. 

 

54 

Figure 4-3 Path Following Task Overview 

4.2 Telepresence and Camera Position 

 

Measuring telepresence is difficult and authors tend to rely on subjective surveys 

performed during or after experiments, where the subjects Situational Awareness is 

measured in lieu of telepresence, by having each operator answer a questionnaire of 

carefully crafted questions. Moreover, even if one could determine a non-subjective way 

of measuring telepresence, it would be difficult to generalize the index, all this because 

telepresence is a function of several factors that try to understand how humans interpret 

remote environments.  

Though an ideal outcome of further research in this area would be to develop a 

single index capable of quantifying how well the remote environment is being relayed to 

the user in function of telepresence parameters, it is not the current objective of this 

study. Nevertheless, this investigation has allowed for flexibility regarding perhaps the 

most important factor in telepresence, the camera position. Here, the system is built in 

55 

 

 

such a way that it allows for the operators point of view to be modified so that his 

perspective can be placed inside the cockpit or on the outside. With this in mind, this 

section describes how said parameter is modified and what is expected when altering 

the point of view. 

Furthermore, this study has developed a questionnaire that will be filled out by 

each participant after the completion of every task. Its intent is to provide broader 

perspectives when understanding the individual complication that that the users 

experience, thus providing an extra dimension to the analysis. For more detail regarding 

the questions that form part of the questionnaire, please refer to APPDENDIX B. 

4.2.1 Camera Position Variability 

As described in CHAPTER 3, the remote vehicle counts with 2 camera mounting 

locations: one in the front of the windshield pillars under the roof, and one behind the 

driver’s seat close to the head level, as seen in Figure 3-6. These locations are chosen 

for two specific reasons: 

1.  An overwhelming amount of studies tend to position cameras in front of the vehicle 

or somewhere that the driver is not normally located. This forces the interface to shown 

a view that the drivers don’t normally experience, which this study believes may force 

the operator to present reduced operational performance.  

2.  Secondly, this study believes that by placing the cameras in a location where the 

drivers head would normally be situated, will give the remote operator a more “natural” 

sense of the actual surroundings. Consequently, improving the operator’s situational 

awareness and providing visual feedback of both the steering wheel reacting to the 

sent control signals and better depth perception between the vehicle and external 

interferences. 

 

56 

During the experiments, the operators will be subject to completing each of the 

aforementioned tasks under both camera position settings. That is, they will be required 

to complete each task with the cameras mounted in one of the previous configurations, 

and after having completed all the objectives, they will then be required to repeat each 

task with the cameras located in the alternative location. After collecting all the required 

information, the two tasks will be compared amongst each other in hopes of determining 

if there is any difference between the camera positions. With this, a secondary 

hypothesis is formulated, stating that “the camera positions have a significant effect on 

performance when teleoperating a vehicle”. In order to validate said hypothesis, this 

study uses the same statistical analysis that is used for the principle hypothesis, as 

detailed in Section 0. 

4.3 Variables logged and Data collection  

In order to properly quantify performance and subsequently validate the primary 

hypothesis, relevant information has to be extracted from each of the previous tasks. 

Due to how our system is configured, several variables can be acquired during the 

executing of the tests using two different data logging methods. Herein, the variables to 

be collated are detailed and the acquisition strategies described. 

4.3.1 Logged Variables 

Each one of the previous tasks will be conducted under a controlled environment 

with the intent of logging several variables that can later be used to determine how well 

the system performed while being teleoperated. Due to how our system is configured, 

this study is capable of registering the following variables: 

•  Vehicle steering wheel position 

•  Vehicle gas pedal position 

 

57 

Analogously, this study also logs the following operator side variables: 

•  Vehicle brake pedal position 

•  Distance traveled (position sensor on the wheel) 

•  Direction of travel (forward, reverse or neutral) 

• 

Z-axis gyroscope 

•  Current camera angle position 

•  Steering wheel position 

•  Gas pedal position 

•  Brake pedal position 

•  Direction of travel (forward, reverse or neutral) 

•  Current camera angle position 

4.3.2 Data Logging Methods 

Regrinding data acquisition, several different methods exist for logging and 

storing relevant information. Though it would seem better to individually register each 

action on operators station PC, two main factors steer this research into developing a 

different logging approach, these being; software system restrictions and event time 

synchronization. An Important reason for not logging actions on local computers is that 

the software off of which the system is built does not easily permit the host server to run 

scripts that modify the file system on the client machine. In other words, since the 

system is based on nodeJS and each client connects to the host server through a 

browser, writing to the clients file system is difficult and can lead to errors while logging 

events or afterwards when trying to collect and process the registered data.  

The second, and arguably more important issue, is time synchronization. Since 

events are triggered on different computers and time stamps are calculated accessing 

 

58 

the local computers reference clock, no assurance exists that both clocks are properly 

synchronized. Due to this, a recurrent function is periodically executed with the intention 

of logging the offset between clocks in both computers. For this, an NTP protocol was 

studied and implemented using assumptions commonly accepted for calculating network 

timing (Mills, 2014). More on how this protocol assesses the time difference is shown in 

Section 4.4.2 of this chapter. 

With the previous limitations in mind, this study now explains how data is 

registered and the logging philosophy implemented. The current system uses two 

approaches towards logging, one being event driven and the other being time based. 

The fundamental reason for using two approaches are; event based logging provides 

more fluid representation of what is changing as it happens, while the time based 

method enables us to register every variables value periodically throughout the whole 

experiment. 

4.3.2.1 Event Driven Data Logging 

For the event driven data collection, the system leverages nodeJS’s 

asynchronous properties to better determine the time at which an action takes place. 

Here an event listener is established, which continually checks to see if an action occurs. 

Once the event listener detects new information, it executes a specific program 

associated to the particular event. It is in this instance that the system is forced to record 

the information and keep track of when the event was triggered. Generally speaking, 

each variable used to control the remote vehicle will be modified and a small script of 

code will be inserted in order to allow for the logging of said variable.  

 

59 

4.3.2.2 Constant Time Interval Data logging 

For the time based data acquisition method, the logging process is straight 

forward. This study simply adds a function to the general code that is executed at a 

constant rate, registering the global values of each variable and storing them in a file 

along with their corresponding time stamp. In other words, each variable is assigned a 

global memory slot that reaches across the whole program. As the program runs and 

different events are triggered, the local variable copies its value to the global variable 

and thus provides a registry of the last available value. When a predetermined time 

passes, the logging function is executed and consequently each global variable is read 

and copied to the data storage file.  

4.4 Variables Post-Processing  

Though most variables collected during the execution of the tasks are ready for 

being interpreted as a performance metric, some require some processing before useful 

information can be extracted. The specific performance metrics that depend on post 

processing are the distance deviated from the path and the time delay in between 

sending and receiving control signals. The first metric depends on being able to 

determine the correct path that the vehicle completed over the task. While the second 

depends on properly synchronizing the two computer clocks and subsequently 

determining the moment when one signal is sent and hen the same signal is received. 

4.4.1 Distance Variable processing 

For determining the position of the vehicle a simplified bicycle model is 

developed using input variables collected in this study. In literature one typically 

encounters a dynamic bicycle model that determines the acceleration and yaw rate of 

the vehicle in function of lateral velocity and current yaw that the vehicle has, all this 

 

60 

after having gathered vehicle specific constants. Unfortunately, due to the limited 

precision of the accelerometer used in this study and large vibrations present in the 

vehicle when starting, the following bicycle model is used to calculate the vehicle 

position (Sharma, 2014) . From Figure 4-4 and geometric correlations, equation 4-2 

determines the vehicle’s yaw rate in function of the steering angle and linear differential 

distance, captured from the steering motor encoder and position sensor on the vehicles 

wheel respectively. Similar to other commonly used bicycle models (Jazar, 2014) 

(Swanson, 2013), this model assumes that the steering angles are small and that the 

effect of slippage between tires and roads is negligible. 

Figure 4-4 Bicycle Model Geometric Model 

tan (cid:4) =

(cid:6)
(cid:7)

 

(cid:8) =

=

tan (cid:4) 

(cid:9)
(cid:7)

(cid:9)
(cid:6)

 

eq.  4-1 

eq.  4-2 

 

 

 

 

 

 

 

61 

On top of determining the yaw through the geometric bicycle model, the 

gyroscope provides the current instantaneous yaw rate that can be used to calculate a 

second yaw angle, as seen in equation 4-3. 

(cid:8) = (cid:10) ∙(cid:12) (cid:13)(cid:14) 

eq.  4-3 

Both of these values are filtered together using a Kalman filter (Welch, 2016) for 

a single variable and then used as inputs to the general equation of motion of the 

cos((cid:10)(cid:22) + (cid:8)) − sin((cid:10)(cid:22) + (cid:8))

sin((cid:10)(cid:22) + (cid:8))

    cos((cid:10)(cid:22) + (cid:8))

                    

                     

0

          

               

0

cos((cid:10)(cid:22) + (cid:8))

0          

               0

sin((cid:10)(cid:22) + (cid:8))

 0

0

0

1

(cid:9)(cid:22)

(cid:6)

0

(cid:30)
(cid:29)
(cid:29)
(cid:29)
(cid:29)
(cid:29)
(cid:29)
(cid:29)
(cid:8) (cid:28)

(cid:9)(cid:22)

(cid:18)
(cid:17)
(cid:17)
(cid:17)
(cid:17)
(cid:17)
(cid:17)
(cid:17)
(cid:16)

∗

(cid:30)
(cid:29)
(cid:29)
(cid:29)
(cid:29)
(cid:29)
(cid:29)
(cid:29)
(cid:28)

0

0

0

0

               0

eq.  4-4 

 

 

vehicle. 

(cid:19)(cid:27)((cid:22)(cid:23)(cid:24))

=

(cid:19)(cid:20)((cid:22)(cid:23)(cid:24))

(cid:26)(cid:20)((cid:22)(cid:23)(cid:24))

(cid:30)
(cid:29)
(cid:29)
(cid:29)
(cid:29)
(cid:29)
(cid:29)
(cid:29)
(cid:29)
(cid:10)(cid:22)(cid:23)(cid:24) (cid:28)

(cid:26)(cid:27)((cid:22)(cid:23)(cid:24))

(cid:18)
(cid:17)
(cid:17)
(cid:17)
(cid:17)
(cid:17)
(cid:17)
(cid:17)
(cid:17)
(cid:16)

(cid:18)
(cid:17)
(cid:17)
(cid:17)
(cid:17)
(cid:17)
(cid:17)
(cid:17)
(cid:16)

0          
(cid:19)(cid:27)((cid:22))

(cid:18)
(cid:17)
(cid:17)
(cid:17)
(cid:17)
(cid:17)
(cid:17)
(cid:17)
(cid:17)
(cid:16)

(cid:26)(cid:27)((cid:22))

(cid:30)
(cid:29)
(cid:29)
(cid:29)
(cid:29)
(cid:29)
(cid:29)
(cid:29)
(cid:29)
(cid:10)(cid:22) (cid:28)

(cid:26)(cid:27)((cid:22))

+

(cid:19)(cid:27)((cid:22))

 

 

 

4.4.2 Time Synchronization Algorithm 

Regarding time synchronization of the computer clocks, an NTP algorithm is 

studied and incorporated in the system (Mills, 2014). Here, once the teleoperation 

system is initialized a recurring function sends out a signal to the operator station with a 

timestamp S1. When this event is received at the operator station, the time is logged 

62 

with time stamp R1 and subsequently sent back to the remote vehicle with the sent 

timestamp S2. Finally, when it is received at the remote vehicle, timestamp R2 is logged 

and stored in the system memory. An illustration of the process is shown in Figure 4-5. 

Figure 4-5 NTP Time Stamp Algorithm 

After the tasks are completed and once processing of the information is started, 

time offset θ and round trip time δ metrics are calculated using equations 4-5 and4-6 

respectively. 

 

 

 

(cid:10) =

((cid:7)(cid:24) − ((cid:24)) + (() − (cid:7)))
 
2

+ = ((cid:7)) − ((cid:24)) − (() − (cid:7)(cid:24)) 

 

eq.  4-5 

eq.  4-6 

 

It is important to highlight that in this study latency is understood as the 

difference of time between when an input signal is captured by the operator station and 

when it is received on the remote environment. Some studies tend to define latency as 

the round trip time cause by an event, however this type of accounting of latency is very 

63 

 

 

difficult due to the need of identifying when a stimulus is triggered on the remote 

environment and reliably capturing an associated timestamp (sometimes embedded in 

an image in the video stream). Later, one must then determine when the operator reacts 

to this stimulus and consequently manipulates the gamepad, which captures his 

response, accounting for “human latency”. Lastly, the input signal is then sent through 

the network where the remote system must actuate the environment accounting for the 

roundtrip latency of an event. Reiterating, this type of accounting of latency is not logged 

in this study. 

4.5 Statistical Analysis 

The previous work of: selecting appropriate tasks; determining how system 

variables are collected; and post processing, is done in order to be able to calculate 

performance metrics for the teleoperated system. However, this work is pointless unless 

some sort of comparison can be established that helps determine the validity of the initial 

hypothesis. To achieve this, ground truth test that establishes a point of comparison to 

each of the performance metrics are completed. These ground runs are completed 

taking into account the same objectives of each task, with the distinct difference that the 

driver is located in the vehicle as opposed to remotely. Once local driving performance is 

established and teleoperation performance metrics for each task are calculated, one can 

then compare the metrics via statistical analysis in order to determine whether or not 

they share similar means, and thus conclude the validity of the hypothesis.  

The following statistical tests are selected in order to validate or reject the 

hypothesis “A vehicle can be controlled over a 4G LTE network streaming HD video 

feedback”. The significance level α of each test is set at 0.05 and the type II error β to 

0.2. This entails that for the following analysis, the tests are able to reject the hypothesis 

 

64 

for different means with a confidence interval of 95%. Furthermore, using a power of 

80% (type II error of β equal to 0.2) and a mean differences effect size of 0.6 (Cohen, 

1992), the sample size is calculated to be at least 20 for each performance metric. Thus, 

if the mean comparison statistical test rejects its null hypothesis then the validity of the 

studies initial hypothesis would be rejected. A three stage statistical test is design and 

detailed herein: 

• 

Stage 1 - Kolmogorov-Smirnov test (KS-test). This nonparametric test 

determines if a sample comes from a normal distribution. The test is 

implemented by using the function “kstest” in Matlab to each metric in an attempt 

to determine whether they can be considered to have a normal distribution at a 

significance level of α equal to 5%. The test rejects the null hypothesis with a p-

value under the significance level (α equal to 0.05).  

Because of the limited sample size used in this study and the difficulty of 

complying with a principle assumption of the Chi-Square test, the Kolmogorov-

Smirnov test is preferred. 

This test sets a precedent for the following statistical tests. Based on whether the 

studied distribution is deemed normal or not, the following stages will select the 

more appropriate statistical tests. In other words, if the KS-test deems that the 

distribution is normal, then it is preferred to use a parametric test which, tend to 

be more robust and deliver better predictions when used with known 

distributions. On the other hand, if the KS test cannot determine normality, then a 

less sensitive to non-normality or non-parametric test is preferred, delivering 

more robustness and better predictions for unspecified distributions. 

• 

Stage 2 - Variance comparison. The second stage is used to determine whether 

the variances of the samples are similar at a significance level of 5%. Two 

 

65 

methods are used in measuring variance similarities: the first is the F-test and the 

second is the Levene test. 

The F-test is implemented by calling “vartest2” function in Matlab. This test uses 

the F-distribution to determine the validity of the null hypothesis that “both 

samples come from normal distributions with the same variance”. If the p-value 

falls under 0.05 then the hypothesis is rejected. This test is used if the null 

hypothesis in the first statistical test is not rejected, i.e. the performance metric 

follows a normal distribution. Thus a parametric test is preferred. 

In the case that the performance metric does not follow a normal distribution, this 

study uses the Levene-test, a test less sensitive to non-normality, to check for 

similar variances. Here, the null hypothesis is similar to the F-test, but it is not as 

sensitive to samples that do not follow normal distribution. The null hypothesis is 

rejected with p-values under 0.05. It is implemented using the function “vartestn” 

in Matlab and setting the testing option to “LeveneAbsolute”. 

• 

Stage 3 - Mean comparison.  After having completed the previous tests, each 

individual performance metrics can be compared to the ground truth and its 

validity determined. Here, this study uses one of two statistical tests, these being 

a Two Sample T-test or Kruskal-Wallis test. The Two sample T-test performs 

better for normally distributed samples whereas the Kruskal-Wallis is not as 

sensitive as the T-test to distributions that are not normal. Both share the 

hypothesis that “the samples come from independent distributions with equal 

means” and is rejected with p-values under 0.05. The same principle for 

parametric tests applies in this stage too. That is, the two-sample T-test, a 

parametric test, provides better predictions for data that follows a normal 

distribution, whereas the Kruskal-Wallis test, a non-parametric test, performs 

better under unspecified distributions. 

66 

 

4.6 Summary 

In summary, three tasks are selected from a list of tests commonly used to 

measure driver qualification (Georgia DDS, 2015). The selected tasks are:  

• 

• 

• 

Straight Trajectory Tasks, 

Reverse Trajectory Tasks, & 

Path Following Tasks. 

On top of detailing the tasks that will be used for measuring operator 

performance in the teleoperated system, data logging methods and variables are 

detailed. Essentially, two methods will be used simultaneously for collecting data: event 

driven logging and time constant logging. Event driven logging takes advantage of 

nodeJS’s asynchronous nature and provides precise time stamps for each event 

triggered in the system. While Time constant logging surveys each variable during each 

time step and simultaneously logs them. 

Some performance metrics require more involved calculations before they are 

ready to measure performance. With this in mind, the theoretical background for the 

calculation of path based and time based metrics are described. Regarding the path 

based metrics; a simple bicycle model is used to determine the position of the vehicle in 

each time step. While for the time based metrics, a time synchronization scheme is 

implemented based on NTP. 

of the principle hypotheses:  

Lastly a three stage statistical test is described used for determining the validity 

• 

The first stage determines the normality of the logged performance metrics by 

the use of a nonparametric KS-test.  

 

67 

• 

• 

The second stage compares the performance metrics variance to that of the 

ground truths by either using an F-test, parametric, or a Levene test, a test less 

to non-normality. If in the first stage, the metric is deemed to be normal, then an 

F-test is used; otherwise a Levene test is used. 

The third stage compares the performance metrics mean to the ground truth 

mean. This is done using either a two sample T-Test, parametric, or a Kruskal-

Wallis test, non-parametric test. Again, if in the first stage the metric is deemed to 

be normal, then a two sample T-test is used; otherwise a Kruskal-Wallis test is 

conducted. 

 

 

 

68 

CHAPTER 5

  

RESULTS AND ANALYSIS 

Herein the results of the data collection and processing are shown with the intent 

of determining the validity of the initial hypothesis; “A vehicle can be controlled over a 4G 

LTE network streaming HD video feedback”. Though this statement may seem open-

ended, its validity can be inferred by the results of well bounded metrics that seek to 

quantify the performance of remote drivers. As seen in CHAPTER 2, little consensus 

exists as to what metric best predicts performance, thus several parameters were 

captured during experimentation, and resultant of this, various performance metrics are 

calculated and used as comparison, providing a more holistic view of how the operator 

performed. On top of this, ground truth runs that were previously logged are used as a 

frame of reference to help determine overall performance of the teleoperation system.  

This chapter is divided into two main sections: results and analysis. In the first, 

the calculated metrics are listed and described so as to introduce the reader to the 

criteria that is used to measure performance. Subsequently, highlighted results are 

detailed and the statistical analysis shown in CHAPTER 4 is applied to the results in 

order to determine how the teleoperation system allowed the operators to perform. After, 

the questionnaire results are presented and discussed, providing qualitative insight to 

what the participants experienced and what they believe hindered their performance. 

The second section delves into understanding the possible reasons for the 

performance seen. Initially, the camera location is studied by comparing the 

performance metrics and their means through the statistical analysis. Since it is 

 

69 

determined that this factor does not likely cause systems difficulties, a deeper look into 

how latency varies is carry out.  

Two main comparisons are studied regarding latency. In the first, latency is 

compared to several performance metrics in order to see if any patterns emerge that 

may warrant further research. Secondly, the latency profiles are compared to the vehicle 

parameters collected during each experiment by overlaying them in function of time. 

From these analysis, possible causes for the systems underperformance are 

hypothesizes for future work. 

5.1 Results 

5.1.1 Performance Metrics 

During the data collection stage, 20 participants completed the tasks described in 

CHAPTER 4. Before teleoperation, each subject was driven through each test in the 

exact location that they would later remotely drive the vehicle. Furthermore, before 

starting the tests, they were allotted 5 minutes of free drive time to get accustomed to 

the latency and feel of system. Subsequently, they were instructed to complete each test 

to the best of their abilities. During each task, a team member was permanently 

stationed on the vehicle, capturing the data and ensuring safety. The “copilot” could halt 

the task at any given moment if he foresaw possible unsafe conditions. In total, a little 

under 5 hours of drive time were logged and the emergency stop was activated 6 times. 

Though the stop was activated, the option of finishing the task was given to each 

subject, to which every driver accepted and ultimately completed the test. 

From the variables collected during teleoperation three main category of 

performance metrics are established: trajectory performance, control signal performance 

and system variables performance. Each of these categories has parameters that are 

 

70 

calculated from different sources attempting to characterize how the subject drove 

during the test.  

5.1.1.1 Trajectory Performance Metrics 

The first category, trajectory performance, uses the logged data to calculate the 

trajectory that the vehicle follows and determines performance metrics by comparing the 

subject’s trajectory to an ideal path. A visual representation of the computed metrics can 

be seen in Figure 5-1. The computed metrics are: 

• 

The Maximum Deviation from Path [m], measures how far the center of the 

vehicle diverged from the ideal path over which it should be on. This metric 

provides an extremes comparison to performance since it only returns the largest 

distance that the vehicle deviated by. It is obtained by calculating the 

perpendicular distance from the vehicle onto the ideal path. (this is shown as dark 

red in Figure 5-1) 

• 

• 

• 

The Distance from Checkpoints [m] metric is the same as the previous, the 

difference being that it only takes into account a specific point on the ideal path. 

(Distance from the path (blue line) to the red circles). 

The Length of Run [m] metric details the total distance traveled by the vehicle. It 

provides longitudinal perspective on how closely the vehicle was able to stick to 

the track. It is calculated by summing the differential displacement of each point. 

The Area of Deviation [m^2] in function of Position, commonly referred to in this 

work as just Area, takes into account the total distance deviation over the whole 

task. This metric provides an extra dimension of information of how the task was 

executed. It is calculated by determining the perpendicular distance of each point 

 

71 

• 

• 

to the ideal path and multiplying it by the differential distance taken in each 

corresponding step. (this is represented by the light blue area in Figure 5-1) 

The Area of Deviation in function of Time [-] provides yet another degree of 

information to the area deviation metric. This metric not only calculates the area 

that the vehicle deviates from the ideal path but additionally weights the 

differential area with the time that the vehicle was away from its path. 

The Ratio Area Deviated over Distance Traveled [-] normalizes the Area metric in 

function of the Length of the Run so that the performance metric can be compared 

to other tasks within the same category, i.e. reverse trajectory to reverse 

trajectory. 

Figure 5-1 Visualization of Trajectory Performance Metrics. Path taken by remote operator 
(blue). Optimal Path (red). Area between paths (light blue). Check points (red circles). 

 

 

72 

5.1.1.2 Control Signals Performance Metrics 

The second category, control signals performance, identifies the subject’s 

response to the remote environment by assessing what control variables are being sent 

and how the vehicle responds to them. The Control Signals Performance metrics are: 

• 

Corrections metrics calculate how many corrections are made by the operator 

during the execution of the task. This metric tries to describe how difficult a task is 

to the operator when compared to ground truth information. The metric is 

calculated by considering a correction to be when the parameter in hand is 

moved, i.e. when derivative of the value goes from zero to an amount and back to 

zero. Correction metrics are obtained from the operator station for: 

1.  Steering signals [-]. 

2.  Acceleration signals [-]. 

3.  Brake signals [-]. 

• 

Velocity metrics provide information pertaining to how fluid the vehicle moved 

during the task. The following metrics are calculated from the distance parameter 

collected during the task execution. A difference is made between “Mean Speed” 

and “Moving Mean Speed”. The mean speed is calculated by the general formula 

total distance over time. While the “Moving Mean Speed” is the average of the 

speed while the vehicle is in motion. The Velocity metrics obtained are: 

1.  Maximum Speed [m/s]. 

2.  Mean Speed [m/s]. 

3.  Moving Mean Speed [m/s]. 

4.  Moving Standard Deviation Speed [m/s]. 

• 

Time performance metrics reveal how much time the operator required to perform 

the given task. The time is categories in to three categories, these being: moving 

 

73 

time, stopped time and initialization time. Initialization is the time required by the 

operator to start the system so as to be able to drive the vehicle. The moving and 

stopped time quantify how much the driver spent moving or stopped, respectively. 

The initialization time is calculated by counting the time since the system is setup 

on the remote side until the operator starts moving. The stopped time is calculated 

by count all the time that the vehicle had a speed of 0 [m/s] and the moving time is 

counted by all the time the vehicle hat a velocity larger the 0[m/s]. The Time 

Performance metrics are: 

1.  Total Time Moving [s]. 

2.  Total Time Stopped [s]. 

3.  Number of Stops [-]. 

4.  Initialization Time [s]. 

5.  Total Time [s]. 

6.  Stop/Moving Ratio [-]. 

7.  Stop/Total Ration [-]. 

8.  Moving/Total Ratio [-]. 

5.1.1.3 System Variables Performance Metrics 

The third category, system variables performance, goes through every control 

signal capturing their sent and received times and, through the means of synchronized 

clocks, calculates the time difference so as to have a latency value of each signal. The 

computed metrics are: 

• 

The Latency performance metrics detail the time delay between when the signal 

was captured in the operator station and when said signal arrived on the remote 

vehicle. They do not account for roundtrip latency as explained in CHAPTER 4. 

 

74 

For each task, a latency profiles is calculated by mapping each time delay to a 

corresponding sent time. These metrics help understand how the system is being 

influenced by the 4G LTE network and guides troubleshooting in Section 5.3 . the 

calculated metrics are: 

1.  Latency Profile [-]. 

2.  Control Signals Mean latency [ms], details the average latency that each 

task had, allowing for a point of comparison between tasks. 

3.  Control Signals Latency Standard Deviation [ms], similar to the average 

latency, this metric provides an idea of how spread-out each signal time 

delay is during each task. 

Every one of these metrics is calculated for each of the tasks completed by each 

operator so as to have a clear idea of how they are performing when using the 

teleoperation system. However, as one can imagine, some metrics provide more 

information than others when predicting performance in each tasks. What’s more, a 

metric that provides a clear description in a particular task may supply less information 

when used in another task. As an example, “stops” or “time stopped” when used in the 

straight trajectory tasks provide little to no information, but when compared in path 

following tasks it illustrates how difficult the task may be. For this reason, though this 

study calculates all of the above metrics, only select metrics are detailed with the intent 

of highlighting performance features. The selected metrics are chosen because: 1- they 

help illustrate difficulties within a particular task, 2- they help show contrast between 

tasks, and 3- they highlight system limitations. For a detailed breakdown of the values of 

all the performance metrics please refer to APPENDIX C. The metrics that will be 

highlighted for each task are: 

•  Maximum Distance Deviation 

 

75 

Total time of execution 

Area Deviation 

Area Dev. In function of Time 

•  Maximum Speed 

•  Moving Mean Speed 

• 

• 

• 

• 

• 

• 

• 

Number of Stops (not used in the straight trajectory task) 

Total time Stopped (not used in the straight trajectory task) 

Latency Mean 

Latency Standard Deviation 

5.1.2 Results and Statistical Analysis  

The three teleoperation tasks; 1- straight trajectory, 2- reverse trajectory and 3- 

path following, will be subject to the statistical analysis on each of the highlighted 

performance metrics. Each metric is first tested with a Kolmogorov-Smirnov test to 

determine the normality of the error metric. The metric variance is later tested with the F-

test or a Levene test in order to determine whether the variances match the ground 

truths. Lastly, the T-test or Kruskal-Wallis test is used to determine whether the 

performance metrics share a common mean with the ground truth within a specific 

interval. If they do share a common mean, then the system can be said to be 

comparable to in-situ driving. Otherwise, if the last test rejects its null hypothesis, the 

system does not operate similar to local driving behavior. Statistical tests values for all 

metrics are detailed in APPENDIX D. 

In order to further help visualize the results, the distribution of the metrics are 

shown in box-plots alongside the ground truth values for the corresponding performance 

metric. Recapping, ground truths are tasks completed with the driver situated in the 

vehicle, thus providing a point of comparison for remote operators. 

 

76 

Box-Plots provide a unique form of representing data in a simple graph that 

condenses relevant information. This allows the reader to extract key elements from 

data without relying heavily on numeral information and simultaneously visually 

recognizing important features within the data. Another useful feature is that boxplots 

help summarize information from different type of distribution, be it normal distributions 

or any other, due to how information is condensed and presented. Figure 5-2 shows how 

a box-plot is organized and what key point’s represent. The center red line is the 

median; the upper and lower blue lines of the box are quartile 3 (Q3) and quartile 1 (Q1) 

respectively; the inter quartile range (IQR) is the space limited between Q3 and Q1 

(IQR=Q3-Q1); the upper and lower whiskers are the highest and lowest data points 

within 1.5xIQR from Q3 and Q1; and the outliers are all points out of the ranges limited 

by the whiskers. 

Figure 5-2 Description of Box-Plot Identifiers 

 

77 

 

 

As a mode of example actual data points are overlaid in a box-plot that 

summarizes the information in Figure 5-3. 

Figure 5-3 Actual Data Points overlaid on a Box-Plot 

 

5.1.2.1 Straight trajectory task 

To determine whether the system allows operators to complete tasks in a 

manner that may be considered “as well” as in-situ drivers, the performance metrics 

previously listed are subjected to the statistical tests. If the performance metrics are able 

pass the final T-Test or Kruskal-Wallis Test, then remote operation is considered to be 

feasible and the teleoperator performed comparable to a local driver.  

In this case, the first performance metrics studied are the most typical metrics 

encountered in similar studies, these being the maximum deviation from path and the 

total time of the run, shown in Figure 5-4 and Figure 5-5. Here, both metrics reject the 

Kolmogorov-Smirnov test, implying that they do not follow a normal distribution at a 

significance level of α of 5%. Furthermore, the Levene Test is rejected at the same 

78 

 

 

significance level, therefore their variances are not comparable to the ground truths. 

With this information, the Kruskal-Wallis test is applied and subsequently rejected with a 

significance level of α equal to 5% and with p-values of 1.01e-03 and 3.04e-04 

respectively.  

Figure 5-4 Box Plot of Maximum Deviation for Straight Trajectory Tasks 

 

Though the maximum deviation from the path is on average 0.91 [m], the ground 

runs averaged .22 [m], far less than remote operation. On top of this when viewing the 

total time of the run, one observes large variances within the metric, which is then 

compounded to the fact that the remote operation median is roughly twice that of the 

ground truth. 

]

m

[
 
e
c
n
a
t
s
D

i

 

 

79 

]
s
[
 
e
m
T

i

Figure 5-5 Box Plot of Total Time for Straight Trajectory Tasks 

 

Continuing the statistical analysis, the Area Deviation and Area Deviation in 

Function of Time, shown in Figure 5-6 and Figure 5-7, are subjected to the previous 

tests. Again, both metrics fail the KS-test and the Levene test at an α of 5%. They also 

reject the Kruskal-Wallis null hypothesis with p-values of 1.68e-04 and 3.50e-04 

respectively.  

 

 

80 

]
2
^
m

[
 
a
e
r
A

Figure 5-6 Box Plot or Area Deviation for Straight Trajectory Tasks 

 

Once again, the teleoperation system did not allow equal performance when 

compared to ground truths for both metrics, further establishing that some type of 

limitation exists. However, it should be noted that even though the great majority of the 

operators did not achieve expected results, some participants were able to perform as 

well as in-situ drivers, falling within both the 1st and 3rd interquartile bounds of the 

ground truth runs. 

 

 

81 

]
2
^
m

[
 
a
e
r
A

Figure 5-7 Box Plot of Area Deviation in Function of Time for Straight Trajectory Tasks 

 

Remembering that one of the objectives in this task was for the operator to 

achieve the highest speed possible and maintain it throughout the run, the Maximum 

Speed and Mean Speed metrics are analyzed. Contrary to previous examples, both 

metrics fail to reject the KS-test and F-test at an α of 5% implying that they resemble a 

normal distribution and both have similar variances to those of the ground runs. The 

corresponding boxplots are shown in Figure 5-8 and Figure 5-9. However, both two-

sample T-test reject the null hypothesis, which indicates that neither mean is comparable 

to those of the ground truths.  

Lastly, the average and standard deviation of latency are shown in Figure 5-10. 

It’s important to highlight that the mean is well within the acceptable limits when 

compared to other studies. Even though the latencies are within expected ranges, they 

do not follow a normal distribution as would be expected, due to the fact that the average 

latency KS-test rejects the null hypothesis at a p-value of 0.0139. 

82 

 

 

]
s
/
m

[
 
d
e
e
p
S

]
s
/
m

[
 
d
e
e
p
S

 

 

 

 

 

Figure 5-8 Box Plot of Maximum Speed for Straight Trajectory Tasks 

Figure 5-9 Box Plot of Mean Speed for Straight Trajectory Tasks 

83 

]
s
m

[
 
y
c
n
e
t
a
L

Figure 5-10 Box Plot of Latency for Straight Trajectory Tasks 

 

Summarizing the straight trajectory task results, one can see that the majority of 

the T-tests or Kruskal-Wallis tests reject the null hypothesis that the means belong to the 

same distribution. This indicates that none of the performance metrics were able to 

establish that their means are statically similar to those of the ground truths. Therefore, 

based on just these results, it would seem that the system does not allow for 

performance similar to that of in-situ drive. However, some operators were able to 

achieve performance metrics that fell within the interquartile range Q1 and Q3 of the 

ground truths. This suggests that, even though most drivers could not perform as 

expected, perhaps a more experienced driver could perform on par to in-situ drivers. 

5.1.2.2 Reverse Trajectory task 

The next task that will be subjected to statistical analysis is the reverse trajectory 

task. Again, attention is directed to metrics that detail the Maximum Deviation from the 

Path and the Total Time it took the participants to complete the given task. In this case, 

84 

 

 

both metrics fail to reject the Kolmogorov-Smirnov test with a significance level of α 

equal to 5%, establishing that the metrics follow a normal distribution. However, they 

both reject the F-test at the same α. Furthermore, they also reject the two-ample T-test 

with p-values of 1.204e-07 and 7.542e-11 respectively. 

]

m

[
 
e
c
n
a
t
s
D

i

 

 

 
Figure 5-11 Box Plot of Distance Deviation for Reverse Trajectory Tasks 

Visually inspecting the box-plots in Figure 5-11 and Figure 5-12, one can see that 

a great amount of variance exists in both metrics. On top of this, both show a large 

presence of outliers, hinting that the task at hand may represent a higher degree of 

difficulty when compared to straight trajectory tasks. Nevertheless, some operators were 

still able to outperform in-situ drivers, suggesting once more that optimal performance is 

possible.  

85 

]
s
[
 
e
m
T

i

]
2
^
m

[
 
a
e
r
A

 

 

 

Figure 5-12 Box Plot of Total Time for Reverse Trajectory Tasks 

 

 

Figure 5-13 Box Plot of Area Deviation for Reverse Trajectory Tasks 

 

86 

Continuing the analysis, the metrics Area Deviation and the Area Deviation in 

Function of Time are inspected and illustrate in Figure 5-13 and Figure 5-14. The KS-

test reveals that the former fails to reject the null hypothesis while the latter rejects it, 

both with at a significance level set to α at 5%. But once more the F-test and Levene 

tests are rejected. Using this information in the two-sample T-test and Kruskal-Wallis 

test, it again rejects the hypothesis with p-values of 7.88e-06 and 7.83e-04. These 

results further cement the tendencies that have been seen until now.  

]
-
[
 
a
e
r
A

Figure 5-14 Box Plot of Area Deviation in Function of Time for Reverse Trajectory Tasks 

 

When reviewing the Maximum Speed metric, shown in Figure 5-15, intuitively 

one can see that it might share the same mean as the ground truth. Applying the 

statistical analysis, the KS-test does not reject the null hypothesis while the F-test does. 

However, in this particular case the two-sample T-test does not reject the null hypothesis 

with a p-value of 0.9214, implying that it shares a common mean. Unfortunately, when 

the Moving Mean Speed, shown in Figure 5-16, is submitted to the same statistical test it 

87 

 

 

rejects the Kruskal-Wallis test, showing once again that performance cannot be said to 

be comparable to local operation. 

]
s
/
m

[
 
d
e
e
p
S

]
s
/
m

[
 
d
e
e
p
S

 

 

 

Figure 5-15 Box Plot of Maximum Speed for Reverse Trajectory Tasks 

Figure 5-16 Box Plot of Mean Speed for Reverse Trajectory Tasks 

88 

 

 

The results seen in the previous metric show unexpected behavior concerning 

speed. More specifically, it would seem that the operators are trying to accelerate more 

than necessary, but fail to maintain a high average speed. Due to this, the Total Stops 

and Total Time Stopped metrics are scrutinized in an attempt to see if relevant 

information can be extracted from these. The box-plots for these metrics are illustrated in 

Figure 5-17 and Figure 5-18. 

]
-
[
 
s
p
o
t
S

 
Figure 5-17 Box Plot of Number of Stops for Reverse Trajectory Tasks 

Here a new tendency, not seen in the prior task, arises. By visual inspection, the 

metrics show a significant increase in the degree of complexity. More precisely, this task 

requires only 2 stops, one when the vehicle is first parked and a second when it stops at 

the final check point. This is explicit when studying the ground truth metric that shows 

only two stops are needed to complete the test. However, the teleoperator performance 

metric shows that the drivers stop more times than expected. This tendency is further 

amplified when studying the Total Time Stopped metric, which also shows that a 

89 

 

 

substantial amount of time is spent with the vehicle stopped. Furthermore, and not 

surprisingly, both two-sample T-tests and Kruskal-Wallis test reject the null hypothesis of 

a common mean with p-values of 6.22e-09 and 3.04e-04 respectively. 

]
s
[
 
e
m
T

i

Figure 5-18 Box Plot of Time Stopped for Reverse Trajectory Tasks 

 

Taking it a step further and trying to determine whether there are any patterns 

regarding where operators stopped their vehicles, the unexpected stops are plotted over 

the ideal path in Figure 5-19. At first glance, one notices that a great majority of the 

interruptions are concentrated at the end of the first segment, while the drivers are 

backing up to the parking area, and at the beginning of second segment while the 

vehicles are pulling out of the parking area. Several reasons may exist as to why there is 

an apparent concentration of detentions in these areas, but the predominant reason that 

is further explored in Section 5.3 pertains to possible latency issues. 

 

90 

 

 

]

m

[
 
n
o
i
t
i
s
o
P
Y

 

Figure 5-19 Reverse Trajectory Stops Plotted over the Ideal Path. In Green are the ideal 
locations for stopping that in-situ drivers achieved consistently. 

 

To end with the reverse trajectory statistical analysis, the average and standard 

deviation of the latency are shown in Figure 5-20. In this occasion, though the mean 

latency is within acceptable ranges, the overall spread of the average and variance are 

evidently larger than in the previous task, and in some instances surpass 1000 [ms]. 

This abnormally high standard deviation hints at the fact that, though some tasks are 

completed with relatively stable time delays, others present highly variables time delays 

which is believed to significantly hinder operator performance .Additionally, the average 

latency rejects the KS-test with a p-value of 0.0149, implying that it does not follow a 

normal distribution, contrary to what would be expected. 

91 

 

 

]
s
m

[
 
y
c
n
e
t
a
L

 

 

Figure 5-20 Box Plot of Latency for Reverse Trajectory Tasks 

 

Summarizing the reverse trajectory task results, the statistical analysis shows 

that almost all of the performance metrics do not share a common mean with those of 

the ground truths. What’s more, when a metric does not share the same average, the 

metrics greatly underperforms the corresponding ground truth. 

Up to this point the results do not seem promising, additionally the metrics are 

starting to show signs that they systematically fail to achieve expected outcomes. This is 

further cemented by the unexpected concentration of vehicles stops in certain locations. 

These issues shall be further analyzed in Section 5.3 when trying to determine the 

underlying causes for systems limitations.  

92 

5.1.2.3 Path Following Task 

Following similar logic as in the previous cases, box plots of the highlighted 

metrics are shown in Figure 5-21 and Figure 5-22, along with the statistical analysis that 

attempts to determine whether the system allows acceptable performance. 

Contrary to the prior tasks, the Maximum Deviation and the Total Time indictors 

both fail to reject the Kolmogorov-Smirnov null hypothesis, i.e. their distribution is normal 

at a significance of α equal 5%, and their variance do not follow that of the ground truth 

at the same α, as shown by the F-test.  

With this, the means of the max deviation and total time are compared and again 

the two-sample T-test rejects the null hypothesis with a p-value of 1.01e-3 and 9.40e-12 

respectively. Both metrics show a large deviance from the expected results, diverging by 

more than 4 [m] from the ideal path and taking more than twice the required time to 

complete the path following task.  

]

m

[
 
e
c
n
a
t
s
D

i

Figure 5-21 Box Plot if Distance Deviation for Path Following Tasks 

 

 

93 

 

 

 

]
s
[
 
e
m
T

i

Figure 5-22 Box Plot of Total Time for Path Following Tasks 

 

Not content with only comparing these two metrics, focus is placed on the other 

calculated metrics in order to widen the analysis and substantiate the final results. 

Taking into account the Area Deviation and Area Deviation in function of Time metrics, 

these also fail to reject the KS- test null hypothesis at α 5% significance, but reject the F-

test hypothesis of equal variance. Subsequently we compare the means with the two-

sample T-test test and determine that they reject the null hypothesis with a p-value of 

4.18e-10 and 5.01e-11 respectively. This further drives the idea that system operators 

are underperforming when compared to in-situ drivers by approximately 3 to 12 times 

depending on the performance metric, as seen in Figure 5-23 and Figure 5-24.  

 

94 

]
2
^
m

[
 
a
e
r
A

]
-
[
 
a
e
r
A

 

 

 

Figure 5-23 Box Plot of Area Deviation for Path Following Tasks 

 

 

Figure 5-24 Box Plot of Area Deviation in Function of Time for Path Following Tasks 

Comparing the Maximum Speed and Moving Mean Speed plotted in Figure 5-25 

and Figure 5-26, a different outcome to that witnessed in the reverse trajectory task is 

95 

observed. That is, the speeds are not as close to the anticipated ground values and the 

two-sample T-test test rejects the null hypothesis (they do not share the same mean) at 

a p-value of 2.96e-12 and 4.65e-18 respectively. 

]
s
/
m

[
 
d
e
e
p
S

]
s
/
m

[
 
d
e
e
p
S

Figure 5-25 Box Plot of Maximum Speed for Path Following Tasks 

 

 

Figure 5-26 Box Plot of Mean Speed for Path Following Tasks 

 

 

96 

]
-
[
 
s
p
o
t
S

]
s
[
 
e
m
T

i

 

 

 

 

 

Figure 5-27 Box Plot of Number of Stops for Path Following Tasks 

Figure 5-28 Box Plot of Time Stopped for Path Following Tasks 

97 

 

 

Nevertheless, checking the same stop metrics as in the reverse trajectory task, 

the Number of Stops in the run and Time Stopped are examined in Figure 5-27 and 

Figure 5-28, and the same hesitant behavior is observed as in the reverse trajectory 

task. Here, the null hypotheses rejections and non-rejections are the same as in the 

previous task with even lower p-values and the vehicle stops are plotted over the ideal 

path to see if there are any patterns, illustrated in Figure 5-29. Though the pattern 

doesn’t exactly follow that of the reverse trajectory, a concentration of stops is seen 

entering and during curves in the path following task. 

]

m

[
 
n
o
i
t
i
s
o
P
Y

 

Figure 5-29 Path following Stops Plotted over the Ideal Path. The green dots shoe optimal 
stop points. 

 

Lastly, the average latency and standard deviation are displayed in Figure 5-30, 

so as to have somewhat of a quantitative understanding of these parameters in the 

98 

 

 

given task. Here the average latency fails the KS-test null hypothesis at a p-value of 

0.0171. The significance of this, similar to the previous task, is that though we would 

anticipate that the average of the latency to follow a normal distribution it unfortunately is 

does not adhering to what’s expected,  highlighting an underling presence of error that 

we will further be analyzed in Section 5.3 5.3 . 

]
s
m

[
 
y
c
n
e
t
a
L

Figure 5-30 Box Plot of Latency for Path Following Tasks 

 

5.1.3 Results Summary 

Reviewing the results of the completed statistical tests, it can be seen that the 

performance metric for each operator and task generally do not compare significantly to 

the ground truths previously measured. Moreover, when comparing the metrics to ideal 

values, these grossly underperform, implying that the remote operators are not capable 

of achieving in-situ performance through the teleoperation system.  

More concretely, Straight trajectory tasks fail to provide significant statistical 

similarity to ground truths in 13 of the 20 metrics measured. Though this is not 

99 

 

 

overwhelmingly skewed to the rejection of the hypothesis, when analyzing Reverse 

Trajectory Tasks and Path Following Tasks, the difference is much larger.  

In Reverse Trajectory Tasks, the mean comparison statistical test is rejected 17 

out of 20 times. Concurrently, the Path Following Task rejects statistical similarities 

between the means 18 out of 20 times.  

With these results, this works confidently rejects the principle hypothesis that “A 

vehicle can be controlled over a 4G LTE network streaming HD video feedback” due to 

important system limitations.  

5.1.4 Questionnaire 

In this section, the results to the questionnaire that each participate completed 

are detailed. After completing every tasks, the subjects were asked fill a questionnaire 

that sought to obtain qualitative metrics regarding the teleoperation system. As seen in 

the questionnaire in APPENDIX B, the questions span across various features that help 

narrow down possible causes for reduced performance experienced during teleoperation 

by explicitly listing them and petitioning the driver to rate how said factor influence his 

performance. Each person is asked to rate the individual compare the degree of 

influence between certain factors.  

After compiling and analyzing the results, this study has chosen to detail 4 main 

classifications that offer an improved grasp of what the participants believe. On top of 

this, the insight that these categories provide will help guide the analysis presented in 

the subsequent sections. The categories are: 

• 

• 

• 

Camera Location Comparison 

Video Feedback 

System Latency Levels 

 

100 

•  Overall Perceived Performance 

5.1.4.1 Camera Location Comparison 

When analyzing the participant’s perception of the camera position, the relevant 

questions to review are: 

•  Q16: I preferred driving the vehicle with the cameras positioned… 

•  Q17: With the camera positioned outside, my spatial awareness was…(view seen 

•  Q18: With the camera positioned inside, my spatial awareness was…(view seen in 

in Figure 5-32) 

Figure 5-31) 

Figure 5-31Camera Position- Inside Vehicle 

 

The results to each of these questions are shown in Figure 5-33. From the 

image, one can see that participants overwhelmingly preferred the camera positioned on 

the inside of the cart, seen by the answers to Q16. And when asked how they believed 

that they performed with the camera on the inside of the cockpit, Q18, the majority 

believed they performed close to excellent. Though mixed signals are expressed when 

101 

 

 

answering Q17, where the distribution is almost uniformly distributed form poor to 

excellent performance. 

Figure 5-32 Camera Position – Outside Vehicle 

 

Figure 5-33 Bar Graph of Questions Relating to Camera Location 

 

102 

 

 

 

5.1.4.2 Video Feedback Questionnaire 

When quantifying the significances that video feedback played on the individual’s 

performance, the subjects had to answer:  

•  Q1: Did you experience video quality problems? 

•  Q2: Of the issues related to video quality, how good was the resolution? 

•  Q3: Of the issues related to video quality, how good was the frame rate? 

•  Q4: How did the video quality affect your performance? 

•  Q5: Which parameter, if improved, would most affect your performance? 

 

From Figure 5-34, one can see that operators either experienced “a lot of 

problems” or “no problems” when driving the remote vehicle, from Q1, and small 

percentages experienced performance in between said extremes. Furthermore, from Q4, 

most participants believed that video quality heavily affected their performance. 

Additionally, when directed to choose between which parameter of video quality would 

most affect their performance if improved, the great majority chose to improve the 

frames per second of the video stream.  

 

 

103 

Figure 5-34 Bar Graph of Questions Related to Video Feedback 

 

5.1.4.3 System Latency Questionnaire 

When asked to answer questions regarding the systems time delay perceived by 

the participants, they were asked: 

104 

 

 

•  Q25: How much time delay in controls did you experience? 

•  Q26: Rate the variation of the time delay. 

•  Q27: The time delay I was exposed to affected my performance… (Significantly-

Very Little) 

Figure 5-35 Bar Graph of Questions Regarding System Latency 

 

From Figure 5-35, a clear tendency regarding user opinion to system latency is 

not observable. In question Q25, approximately 30% of the users believe that they did 

not experience significant time delay in control signals, but 50% believe that they did 

experience some degree of latency. Furthermore, when asked if time delay affected their 

performance, the results again bring back mixed feelings, not being able to concretely 

determine whether latency did or did not affect individual performance. 

105 

 

 

5.1.4.4 Overall Perceived Performance 

Finally, when asked to evaluate the individual performance that each participant 

had, the relevant questions asked were: 

•  Q28: My performance was… (Inadequate-Adequate) 

•  Q34: What most hindered my performance was...(Answers shown in Table 5-1) 

Figure 5-36 Bar Graph of Questions Relating to Overall Performance 

 

From Figure 5-36, one can clearly see that the great majority of the participants 

believed that they completed the driving tasks at least adequately. An interesting fact, 

when compared to the statistical results analyzed in the previous section. 

Additionally, even though question Q34 is open ended the participants answers 

were able to be categorized into 5 categories. These categories are order and shown in 

Table 5-1.  

 

106 

 

 

Table 5-1 Answers to Question 34) what most hindered my performance was… 

Main Feature that Hinders Performance 

Relative Frequency 

Video Quality - Resolution 

Video Quality – Frames Per Second 

Time Delay of Control Signals 

No Force Feedback  

Camera Position – Field of View 

 

0.10 

0.25 

0.45 

0.10 

0.10 

Reviewing the collected data and the statistical results obtained, it is clear that 

the initial hypothesis is rejected. That is, the teleoperation system does not allow for “a 

vehicle to be controlled over a 4G LTE network streaming HD video Feedback” 

equivalent to a regular driver, as defined in this study. Though the hypothesis has been 

rejected, this study has still not determined whether the camera position significantly 

influences teleoperation, nor has it determined possible causes for the system 

underperformance. 

The rest of this chapter focuses on taking a more in-depth look at the variables 

collected and determining possible causes for the calculated results. 

5.2 Analysis and Variable Comparisons 

Having determined that teleoperators underperform when compared to local 

drivers, we now seek to understand possible reasons for the shortcomings experienced 

during the given tasks. In order to gain further clarity, the acquired variables are 

compare amongst each other in a post-hoc analysis.  

 

107 

The first variable to be studied is one related to a secondary hypothesis that tried 

to determine whether or not the camera position influences performance in the 

teleoperated system. To accomplish this, the performance metrics are analyzed using 

the previous statistical analysis. Each metric is associated to the camera position that 

the task was executed and subsequently scrutinized via the two-sample T-test or a 

Kruskal-Wallis test. 

Secondly, system variables, such as the average latency and its variance, are 

compared to other parameters with the intent of noticing any patterns. Trends relating to 

the time of day are devised and interpreted as a likely source for network congestion 

which may contribute to decreased performance. Additionally, and due to the observed 

patterns, a correlation between the stops that the operators had and characteristics of 

the latency profile during task execution is further scrutinized and streaming video 

feedback as well as sending control signals is hypothesized as a cause for system 

strain. 

5.2.1 Camera Position Analysis 

As seen in CHAPTER 2, telepresence factors can, on occasion, drive operator 

performance within a remote control system. Based on this affirmation, the remote 

vehicle had two video feedback configurations; one with the camera located in front and 

the other with the camera positioned in the vehicle, where the drivers head would be. As 

a result of having two setups, a comparison between the arrangements is studied with 

the intent of determining whether one configuration is significantly better than the other. 

To accomplish the previous, a similar approach to that used in determining the 

validity of the principle hypothesis is computed. That is, we first check to see whether the 

metrics resemble a normal distribution by means of the Kolmogorov-Smirnov test, then 

 

108 

the variance of each sample is compared using the F-test or Levene and finally the 

means are compared by use of the two sample T-test or Kruskal-Wallis. If the third 

statistical test is rejected then the means are considered to be significantly different. This 

in turn would imply that one camera position helps the operator perform significantly 

better than the other with α at 5%. 

Table 5-2 P-Values of the Statistical Test for Camera Position Comparisons, calculated as 
described in CHAPTER 4 (Two Sample T-test or Kruskal-Wallis Test) 

Straight Trajectory 

Reverse Trajectory 

Path following 

0.6652 

0.8181 

0.8924 

0.7868 

0.8560 

0.6949 

0.3562 

Max. Dist. 

Total Time 

Area 

Area(Time) 

Max. Speed 

Mean Speed 

 Stops 

 

Time Stopped 

0.2289 

0.9803 

0.3548 

0.9106 

0.5162 

0.0631 

0.2183 

0.6696 

0.2674 

0.3577 

0.2342 

0.9389 

0.0768 

0.3564 

0.4334 

0.2488 

0.1771 

Table 5-2 shows the results of the third statistical test for the metrics highlighted 

in the previous section, every statistical test can be seen in APPENDIX D. In the table, 

the first column lists the highlighted performance metric and the subsequent columns 

detail the p-value for the T-test, where the null hypothesis is rejected with a value lower 

than 0.05. It is abundantly clear that none of the statistical tests are rejected, thus 

implying that the means are at least significantly similar.  

 

109 

As a mode of example, the comparison between the camera positions for the 

Maximum Deviation metric for each task is shown in Figure 5-37, Figure 5-38 and Figure 

5-39 in the form of boxplots, visually showing no significant difference. 

Figure 5-37 Box Plot of Camera Comparison for Maximum Distance Deviation in Straight 
Trajectory Tasks 

]

m

[
 
e
c
n
a

t
s
D

i

]

m

[
 
e
c
n
a
t
s
D

i

 

 

Figure 5-38 Box Plot of Camera Comparison for Maximum Distance Deviation in Reverse 
Trajectory Tasks 

110 

 

 

 

 

]

m

[
 
e
c
n
a
t
s
D

i

Figure 5-39 Box Plot of Camera Comparison for Maximum Distance Deviation in Reverse 
Trajectory Tasks 

 

Even though there are no statistical differences in the overall metrics between 

one camera position and the other, individual operator improved performance is 

calculated and their means are tested via the previous statistical method. That is, a ratio 

between each metric is calculated as in eq.  5-1, where each specific performance 

metric ,-. is calculated with the camera located inside the cockpit and the 

corresponding performance metric ,-/ is calculated with the camera outside the 

vehicle. This represents how well a task was executed respect to the camera positions, 

and subsequently this ratio’s mean is compared to that of a normal distribution using the 

T-test, at a significance of α equal to 5%.  

 

 

 

0 =

,-.
,-/

 

111 

eq.  5-1 

Once more, from Table 5-3, the majority of the performance metrics for a given 

task fail to reject the null hypothesis implying no significant difference between the 

means. This in turn suggests that there is no improvement between a tasks executed 

with a camera positioned in front when compared to the same task with a camera 

positioned inside the vehicle, as previously seen in the direct comparison (Figure 5-37, 

Figure 5-38 and Figure 5-39). 

Table 5-3 P-Values of the Statistical Test for Improvement Rations in Camera Position 
Comparisons, calculated as described in CHAPTER 4 (Two Sample T-test) 

Straight Trajectory  Reverse Trajectory  Path following 

Max. Dist. 

Total Time 

Area 

0.4642 

0.8468 

0.1395 

Area(Time) 

0.2798 

Max. Speed 

0.5961 

Mean Speed 

0.6549 

 Stops 

0.7481 

Time Stopped 

NaN 

 

5.2.2 Latency Analysis 

0.2530 

0.5093 

0.1633 

0.8831 

0.0119 

0.0723 

0.5078 

0.7876 

0.0609 

0.0370 

0.2166 

0.5805 

0.2849 

0.2637 

0.0710 

0.0138 

Another factor that is commonly associated with performance in a teleoperated 

system is latency. As previously stated, this parameter was compared to several 

performance metrics with the intent of determining if it swayed operator tasks. After 

comparing several metrics, two in particular present noteworthy assessments, these 

being the dependency of performance versus the latency and how the latency varied in 

function of the time of day. 

 

112 

A closer look at how latency compares to performance is graphically shown in 

Figure 5-40. Here, the information is plotted on a log-log graph in order to amplify the 

effect of latency over the performance metric. Though it is tempting to determine that 

performance is deteriorated as the latency mean increase, it is difficult to justify said 

assumption based off of the information presented in the figures.  

Fortunately, certain conclusions can still be made from observing the scattered 

points. The logarithmic plots, Figure 5-39, shows each task in different colors where the 

straight trajectory task is shown in magenta, the reverse trajectory task is in green and 

the path following task is shown in blue. By visually inspecting the graph, groups of 

horizontal small stripe regions are recognized. This implies that particular performance 

metrics may be bounded to a specific area. On top of this, straight trajectory metrics are 

tightly grouped in the lower left side of the graph. Whereas, both reverse trajectory and 

path following tasks present wider bands on both latency average and variance. These 

two facts hint at the possibility that they are somehow forcing the system to experience 

higher average latencies. 

 

113 

]

m

[
 
e
c
n
a
t
s
D

i

Figure 5-40 Logarithmic Plot of the Maximum Distance in Function of Latency. Blue 
Crosses Represent Path following Tasks, Green Crosses Represent Reverse Trajectory 
Tasks and Magenta Crosses Represent Straight Trajectory Tasks. 

 

Intent on better understanding the causes for the observed latency 

characteristics, the study also compared the average value of latency to the time of day 

that each task was completed. Figure 5-41 shows the relationship that exists between 

these two factors using the same color scheme as illustrated in Figure 5-40.  

Once more, no clear tendency is present when viewing the points scattered in 

one image. But when the reverse trajectory and path following tasks are plotted 

separately to that of the straight trajectory task, an interesting pattern arises. In Figure 

5-42, the green and blue crosses which represent reverse ad path following tasks 

respectively, show that between 19:00 and 21:00 [h] latency tends to concentrate under 

the 500  [ms] mark and before 19:00 [h] the latency varies wildly, reaching values of up 

to 2500 [ms] averages. However, this tendency is not observed in the straight trajectory 

task, where latencies consistently fall under the 500 [ms] mark, as seen in Figure 5-43. 

114 

 

 

]
s
m

[
 
y
c
n
e
t
a
L

]
s
m

[
 
y
c
n
e
t
a
L

 

 

Figure 5-41 Average Latency for Each Task in Function of the Time of Day 

 

 

Figure 5-42 Average Latency for Path and Reverse Task in Function of the Time of Day 

115 

]
s
m

[
 
y
c
n
e
t
a
L

Figure 5-43 Average Latency for Straight Trajectory Task in Function of the Time of Day 

 

Though it is not statistically proven, there seems to be a hidden relationship 

between latency and performance. By just comparing average latency to performance 

metrics, one can notice that the system reacts differently depending on the task that is 

being completed. For straight trajectory tasks, latencies tend to concentrate below 500 

[ms] and in general have better performance metrics. On the other hand, both the 

reverse trajectory and the path following tasks display a higher range of latency while 

displaying decreased performance metrics. 

Furthermore, when comparing latency to the time of day, straight trajectory tasks 

show less variability. However, this is not the true for both reverse trajectory and path 

following tasks that vary largely before 19:00 [h]. 

116 

 

 

5.3 Possible Causes to the Observed System Limitations 

Up to this point, an intuitive relationship between latency, performance and time 

of day has been established, but no underlining causes has been resolved. When 

focusing on the comparison between latency and performance, it was observed that 

straight trajectory tasks behaved differently to reverse and path following tasks. Due to 

this, the system latency profiles are studied in order to determine possible causes to this 

diverging behavior. Additionally, the latency and time of day tendencies are further 

analyzed and compared to network congestion statistics.  

5.3.1 Latency profiles 

Latency profiles for each test are computed by plotting the time delay of each 

control signal in function of the time the signal was sent in the corresponding run. These 

profiles illustrate how the time delay in the system fluctuates as the task is executed. 

Examples of low latency runs for each task are shown in Figure 5-44. 

Though each profile provides interesting information regarding time delay in the 

system, its relevance becomes apparent only when other variables are overlaid and 

contrasted. Many of the vehicle specific parameters collected during the runs were 

compared to each latency profile in an attempt to recognize patterns that could help 

understand root causes of the variances in the system. Of all the parameters examined, 

two are highlighted in this study due to the implications that they provide, these being: 

the vehicles velocity profile and the gyroscope readings.  

 

 

117 

Figure 5-44 Examples of Low Latency Profiles for Each Task  

 

In Figure 5-45 and Figure 5-46 each parameter is overlaid on the latency profile 

separately at first and then all together in Figure 5-47. Since the parameters being 

compared share no physical dimension, the y axis is set to show the value of latency 

and the parameters that are overlaid are scaled to an adequate size to facilitate visual 

inspection. The following analyses is exemplified on a reverse trajectory task for brevity, 

but is holds true for path following tasks as well. Just as a reminder, the reverse 

trajectory task consisted in driving the vehicle in reverse for approximately 20 [m] and 

118 

 

 

parking. Immediately after parking the vehicle had to pull out to the left and follow a 

straight line for less than 20 [m] and stop on a marker.  

Figure 5-45 Latency and Velocity Profiles in Function of Time of Run. Latency Profile is 
shown in Blue, Velocity Profile is shown in Magenta. 

 

From Figure 5-45, where the latency is compared to the velocity profile, one can 

infer that initially the vehicle is stopped and consequently the latency profile is relatively 

stable. However, when the vehicle starts to backup, small fluctuations in latency appear 

and slowly start to gain prevalence. Before the car’s first stop, at around the 80 second 

mark, we notice a small spike in the latency but it subside quickly after the vehicle 

comes to a halt. During the period that the vehicle is stopped, between the 80 and 120 

second marks, the latency profile appears to stay stable. But as soon as the cart starts 

to move again, almost immediately the system latency starts to spike to levels that are 

unsustainable for teleoperation. Therefore the operator stops the vehicle and lets the 

system stabilize, close to the 140 second mark. Once the latency appears to be stable 

again, the vehicle starts and ultimately concludes the reverse trajectory task at the 160 

second mark. 

119 

 

 

Figure 5-46 Latency and Gyroscope Profiles in Function of Time of Run. Latency Profile is 
shown in Blue, Gyroscope Profile is shown in Green. 

 

Turning our attention to the gyroscope readings, the values are overlaid on the 

latency profile as shown in Figure 5-46. In this case, one can notice that at the beginning 

of the run, the gyro is at rest and analogously the latency reading remain stable. Soon 

after, at around the 40 second mark, the latency starts to display small perturbations but 

nothing significant until the gyroscope detects that the vehicle starts to turn, close to the 

70 second mark, and almost immediately there is a spike in latency. After the vehicle 

stops turning, latency values return to normal and remain there until the sensor detects 

rotations again, displaying this characteristic latency behavior all the way until the end of 

By combining both variables over the latency profile, as seen in Figure 5-47, one 

starts to notice that variances in latency loosely follow the velocity and gyroscope 

profiles. Better understanding what these parameters measure we see that the first 

metric, velocity, quantifies the linear speed that the vehicle is subjects to. Similarly, the 

gyro parameter quantifies the angular velocity that the vehicle has.  

the run.  

 

120 

 

 

Figure 5-47 Latency, Velocity and Gyroscope Profiles in Function of Time of Run. Latency 
Profile is shown in Blue, Velocity Profile is shown in Magenta, and Gyroscope Profile is 
shown in Green. 

 

But the question still remains, why is latency affected by these velocity metrics? It 

is here that this study believes that the underlining cause of variance in the system is not 

cause by actual velocity, but rather what happens when the vehicle is in movement. 

Going back to the basics, the teleoperation system is setup so that control signals flow 

from the operator station to the vehicle and simultaneously, the vehicle is streaming 

video feedback to the control station. When the vehicle is idle, the cameras are 

streaming a constant image that, due to encoder algorithms, is compressed significantly 

resulting in low bandwidth utilization. As the vehicle starts to pick up speed, the cameras 

start to process scenery changes which in turn force the compression algorithm to start 

to send more information over the internet connection. However, as seen in the latency 

profile when the vehicle moves in a straight line, though the scenery is changing, the 

majority remains the same and no significant strain is placed on the cellular network. It is 

only when the cart starts to turn and significant changes to the scenery take place along 

with a jump in control signal being sent, that large variances to the latency profiles 

become apparent. Therefore, this study believes that the underlying cause to variability 

121 

 

 

in the latency may be consequence of limitations in the bandwidth due to spikes in video 

streaming and control signals being sent through the network. 

Though rapid changes in scenery look like a probable candidate to system 

complications, one would expect to observe these effects throughout every test, 

independent of the time of day the tasks is executed. Nevertheless, this is not the case, 

and the system is capable of performing on par under certain circumstances, as seen in 

Figure 5-42 that compares latency to the time of day that the task was completed. 

Therefore another cause must exist that in conjunction with video and data stream 

strains, cause the system to underperform. 

5.3.2 Network congestion and Time of Day 

A previous image, Figure 5-43, illustrated an interesting correlation between 

latency and the time of day. Here, one could identify that straight trajectory tasks 

displayed little dependence to the time of day. According to the previous assumptions, a 

probable cause for the low variability behavior now exists. That is, since the straight 

trajectory tasks presents little change in the scenery and almost no significant control 

signal requirements, then video and data streams exerts little strain on the system.  

Nevertheless, if this hypothesis were the only cause for this behavior, then it 

would also be present in Figure 5-42. In other words, one would expect to see large 

latency variability independent of the time. However, a clear tendency of reduced latency 

is detected after 19:00 [h].This leads this study to believe that intrinsic challenges related 

to load on the network also affect system latency.  

Investigating typical loads on cellular networks, (Son, 2011) collected and 

normalized demand on a cell tower located in an urban setting. Figure 5-48 shows how 

demand swings widely from high network demand during the day to minimal demand 

 

122 

during the night. Critical points in time are after 18:00 [h] in the morning when network 

activity picks up and after 18:00 [h] at night when activity starts to subside. Comparing 

this information to the conclusions extracted form Figure 5-41, a reasonable inference 

can be made that when high network demand is present in the system then larger 

variances may be expected. Similarly, if the cell tower is under less demand, commonly 

present after 19:00 [h], then the system will behave in a more stable manner.   

Figure 5-48 Normalized Network Congestion in Function of Time of Day in an Urban 
Setting. (Son, 2011)1 

 

 

 

Taking the previous assumption into account and contrasting them to the 

hypothesis that the video and data streams affects system performance, this 

investigation believes that all these factor have a compounding detrimental effect over 

the teleoperation system. To better explain this, consider the following analogy of water 

flowing through a pipe. In this case, water represents the amount of information being 

sent by the video and data streams to the control station, and the diameter of the pipe is 

analogous to the bandwidth of the network. Hence, the amount of water that needs to be 

sent over the pipe will vary depending on the amount of information that is being sent 

over the network. If the vehicle needs to turn the then data stream starts to utilize more 

                                                            
1 This data was obtained from experiments conducted by the University of Southern California’s Autonomous 
Networks Research Group, http://anrg.usc.edu. 

123 

bandwidth as will the rapid changes in scenery, analogously more water needs to be 

sent through the pipe. If the pipe is large enough, then it doesn’t matter if the water flow 

is large or small, because the pipe can handle the flow. But if the pipe diameter is not 

large enough, which might be due to network congestion, then the flow through the pipe 

will reach a maximum and water will start to accumulate at the entrance. This 

accumulation of water at the entrance can in turn be understood as latency.  

5.4 A Posteriori Analysis 

Though this study believes that the main cause of underperformance in the 

system is attributed to network congestion and variability in data streams, which 

ultimately result in variable latencies; it is hard to quantify the individual effects that each 

subsystem has on the overall performance of the participant. A comparative study 

between the camera positions was shown in section 5.2.1; showing that even though 

participants overwhelmingly believed that the camera position affected their 

performance, when reviewing the statistical comparison, no significant difference could 

be seen. Though, it’s not to say that it didn’t actually hinder their individual performance 

in other ways than accounted for in this work.  

The teleoperated system has many interlinking subsystems that can affect user 

performance differently. And if properly accounted for, insight into these could ultimately 

provide clearer paths to improving cellular teleoperation, without having to alter the 

underlying constraints discussed in CHAPTER 3. Subsystems that can influence 

performance are: the Graphical User Interface (GUI) that shows the operator the remote 

environment and allow them to visually interpret how events are transpiring; the 

supplementary information that is displayed to the operator (like current speed, LIDAR or 

GPS), where on top of aiding the decision process, the information also utilizes 

 

124 

bandwidth and can ultimately cause more difficulties that what it helps; the amount of 

cameras simultaneously streaming and the incremental information they provide the 

user; where they ultimately use more bandwidth but provide a wider camera angle, the 

question here might be to develop a trade-off between the field of view versus bandwidth 

utilization; or even the human element and variability to latency introduced by 

experience and reaction time. All these elements, and more, play a vital role in improving 

operator performance but were not duly collected so as to be able to objectively infer 

conclusions from them. However, some comments can be provided based on 

experience collected throughout several of the experiments conducted.  

 An interesting subsystem that proved to introduce more variability than expected 

was the rear camera view. The effects that spawned from this were twofold: 1- where the 

actual display seemed to block the front view camera and 2- the view provided cause 

some operators to turn in the wrong direction. When displaying the rear camera view, it 

was overlaid in the bottom right corner of the front camera view and some participants 

commented that this seemed to distract them when driving and believed that it could 

either be placed on another screen that was used less than the front view or appear only 

when it was needed. Furthermore roughly 50% of the operators were disoriented when 

driving the vehicle in reverse and believed that the image should be flipped vertically, 

representing more of a mirror image similar to when looking in a rear view mirror.  

The initialization time when switching between cameras sometimes took several 

seconds. Though this does not directly affect many performance metrics, it did prolong 

the amount of time the operators were stopped and sometimes provided uncertainty as 

to whether the camera stream would actually appear. However, when discussing this 

issue, many drivers did not seem to mind the length of time to initialize the camera and 

some welcomed it, because it left them time to rest before starting to drive again.  

 

125 

One point that the majority of the participants commented on was that they 

preferred having the camera positioned inside the vehicle as opposed to having it 

outside. When asked to further explain their preference, several participants stated that it 

was because they could better estimate the amount of latency in the system by 

measuring when they moved the steering wheel and estimate the amount of time that 

lapsed before they saw a response on the remote environment. Though no statistically 

significant difference was measured in performance due to camera positions, this could 

eventually improve performance due to an increased confidence in predicting how the 

system will react to any input they provide. 

An interesting revelation was made apparent, after all the experiments were 

concluded, while trying to determine the bandwidth used by different factors in the 

system. It was seen that under certain circumstances, video streams could use 

anywhere between 0.5 [Mbps] and 3 [Mbps] depending on the quality and variability in 

scenery. Furthermore, it was expected that the control stream would use under 0.5 

[Mbps]. However, when measuring the through put of the control signals, it was 

observed that they used approximately 1 [Mbps], significantly more than expected. This 

further suggested that the strains in the system could be due too much information trying 

to be sent over the network.  

Finally, an interesting study that may ensue in future works would have been to 

be able to determine the incremental amount of information that was relayed to the 

operator due to specific auxiliary feedback. In other words, it would be interesting to see 

if one could quantify how much information is being captured and used by the operator 

based on the amount of data that these factors use in the available bandwidth. For 

example, does the amount of information used by relaying the current speed that the 

vehicle has improve the overall performance of the operator compared to the strain it 

 

126 

has on the network,  furthermore are their other factors that could be included to improve 

the users awareness that do not impose a significant strain on the network. 

Unfortunately, the methodology implemented in this work didn’t account for individual 

testing of these parameters and thus cannot be objectively quantified. However, it is the 

belief of the author that they did not influence the operator due to the heavy fluctuations 

in latency and video quality the drivers experienced. 

5.5 Summary 

Recapping, before the results and statistical analyzes were presented, a 

description of every performance metric was thoroughly detailed, grouping them into 3 

main categories: 1- Trajectory Performance Metrics, 2- Control Signals Performance 

Metrics, and 3- System Variables Performance Metrics. In total, 20 metrics form the 

basis off of which the validity of the principle hypothesis is tested. Though 20 metrics are 

detailed, only 10 are highlighted in the results and statistical analysis section since they 

help provide a clearer image of how the operator performs. 

Concluding the preamble of the performance metrics, the thick of this work is 

presented in the results and statistical analysis section. Performance metrics for each of 

the three tasks are shown by means of boxplots and compared to its corresponding 

ground truth. Each of the performance metrics are submitted to a three stage statistical 

analysis and the results are detailed along with a brief description of their significance. It 

was seen that for all three tasks, the performance of the operators did not meet 

expectations. Specifically, in the straight trajectory tasks 13 of the 20 performance 

metrics rejected the statistical tests; in the Reverse Trajectory Tasks 17 of the 20 metrics 

rejected the statistical tests; and in the Path Following Tasks 19 of 20 metrics rejected 

the statistical tests. On top of determining that operator performance underperformed 

 

127 

and thus the validity of the principle hypothesis was rejected, certain factors hint at 

underlying difficulties, like high number of stops and oddity in the average and standard 

deviation of latency, that are further explored later in this chapter. Nonetheless, some 

more experienced drivers were able to perform just as well as in-situ drivers hinting that 

if system conditions are nominal, then optimal performance is achievable. 

Subsequently, results to the questionnaire are detailed and categorized into four 

groups: Camera Location Comparison, Video Feedback, System Latency Levels and 

Overall Perceived Performance. Regarding the Camera Location Comparison, it was 

seen that user overwhelmingly prefered the camera positioned inside the vehicle even 

though it was statistically proven that camera position had little effect on overall 

performance. For Video Feedback it appears that users experience more quality related 

issues, nevertheless the overwhelming majority believed that improving frames per 

second would be most helpful. In the System Latency Levels the operators no clear 

tendency was shown, however when reviewing latency profiles it is clear that latency is 

present in the runs. And for Overall Perceived Performance, it was interesting seeing 

that most users believe that they performed relatively well, and that they believed that 

what most hindered performance was time delay. 

Though it was shown that the principle hypothesis was rejected, this study delves 

into possible causes for the calculated results. Variance sources due to camera 

positioning and latency are studied. Analyzing performance in function of the camera 

position, it was seen that no statistical difference existed between the metrics. 

Furthermore, no improvement was perceived due to changes in camera position. On the 

other hand, significant variation can be attributed to latency, like stratification in 

performance metrics. On top of this, certain patterns emerge regarding time of day that 

are later shown to affect latency and consequently overall performance. 

 

128 

Lastly, latency profiles and network congestion are hypothesized as the principle 

bottles necks to the teleoperated system. The latency profiles are compared to several 

system variables, and an interesting relationship is found to involve velocity parameters. 

Also, network congestion is found to be cyclical and coincide with variability of the 

average latency values when compared to the time of day. Taking both of these factors 

into account, latency profiles and network congestion, this work believes that they 

conduce to “blockage” in the channels and ultimately reduce available bandwidth 

availability to operations involving high use of video and data streams.  

 

 

 

129 

CHAPTER 6

  

CONCLUSIONS 

In this work, a cellular teleoperated system was built and tested. Its main 

objective was to determine the validity of the hypothesis “A vehicle can be controlled 

over a 4G LTE network streaming HD video feedback” through means of statistical 

analysis. After several tests, the hypothesis was overwhelmingly rejected and insight into 

what and why the system presented issues were discussed.  

In what is left of this thesis, a summary of the information detailed heretofore will 

be reviewed along with relevant conclusions pertain to the completed experiments. 

Finally, future works related to this investigation and how cellular teleoperation may be 

improved are discussed. 

6.1 Summary 

Clearly teleoperation has grown at huge steps spanning across many disciplines 

and science fields. On top of this, each field has seemingly unbounded space to 

continue growing. One field that is of particular interest to this study is the 

communications medium that the teleoperated system uses, that is, cellular networks. 

For decades, cellular communication has consistently increased data transfer rates and 

mobile access while decreasing latencies. This has happened to such an extent that it is 

now possible to stream large amounts of data which in turn allows for exploring new 

uses such as teleoperation (Ericsson, 2015).  

 

130 

Due to this new found ability to stream enough feedback to the operator and 

have him control a remote environment, this study found it necessary to test the actual 

capabilities of commercial cellular networks and determine if they offer reliable services 

to the extent that they allow for “a vehicle to be controlled over a 4G LTE network 

streaming HD video feedback”, this works principle hypothesis. 

In an attempt to determine the validity of the hypothesis, a review of what 

teleoperation is and current industry uses are described. It was seen that teleoperation 

can be grouped into 5 categories; 1- Master-Slave, 2- Supervisory-Subordinate, 3- 

Partner-Partner, 4- Teacher-Learner and 5- Fully Autonomous. Furthermore, uses for it 

span across a plethora of industries, like; space exploration, military or defense, 

removing humans from toxic of hazardous environment, or even medicine where long 

distance and micro surgeries are made possible.  

Current research standards for quantifying the performance of a teleoperation 

system are elaborated on. Time and frequency domain analysis dominate control 

systems quantification strategies, while other more holistic approaches measure user 

performance of overall task completion, such as deviation from path or total time of task 

execution.  

To better understand the main limitations present in cellular based teleoperation, 

internet based time delay is explained. Packet switched networks are presented as 

sources of latency and benefits and disadvantages of UDP and TCP protocols are 

detailed. Also, different wireless communication methods, i.e. Bluetooth, Wi-Fi, etc., are 

compared side by side, highlighting different characteristics.  

On top of this, current investigations that delve into cellular based teleoperations 

are described, highlighting strengths and weaknesses encountered in both methods and 

 

131 

results. The earliest investigation to delve into cellular teleoperation (Gnatzig, 

Chucholowski, Tang, & Lienkamp, 2013) constructs a simple system that controls a 

small robotic vehicle. Their main concerns are data rates and latencies and thus base 

their success on achieving comparable results in transfer rates and time delays. They 

ultimately conclude that while cellular teleoperation is possible, it comes with difficulties. 

Subsequently, (Munoz, Eusse, & Cruz, 2007) and (Shen, et al., 2016) both 

implement cellular teleoperation on commercial vehicles and test the systems by 

measuring transfer rates and latencies and determine that cellular teleoperation is 

possible. However, most of their final remarks highlight that properties inherent to 

cellular networks should be studied to allow for improved teleoperation. 

Presenting the preamble and getting acquainted with current research, this thesis 

proceeds to describe how this investigations teleoperation system is setup and highlights 

relevant characteristics. This works teleoperation architecture is a master-slave 

configuration with minimal autonomous algorithms incorporated on the remote side for 

safety reasons. Both operator station and remote environment are programed in a web 

browser environment due to the advantages of using webRTC in conjunction with 

STUN/TURN servers. Lastly, both operator and remote environments are detailed and 

key characteristics, such as camera configurations and instruments, are described. 

Following the system description, the experimental design and statistical analysis 

principles are presented. A detailed explanation is given of why this investigation chose 

3 principle tasks to be conducted during the experimentation phase. Along with 

objectives that each operator needs to achieve in order to successfully complete each 

task. Insight is given into how the required variables used in the posterior analysis are 

collected and calculated, and the statistical tests and criteria are presented.  

 

132 

Ultimately, the statistical tests try to determine the validity of the principal 

hypothesis. To accomplish this, the variables collected and calculated from the 

experiments are subject to a three stage statistical test whose final goal is to compare 

the average value of teleoperation performance to ground truths. If the statistical tests do 

not reject the null hypothesis, then it can be said that the means are significantly similar 

and thus the teleoperation system performance can be said to be comparable to a local 

driver present in the vehicle. Otherwise, if the tests reject the null hypothesis, then the 

means are not similar and the teleoperation system performance is not similar to in-situ 

driving. 

The three stage statistical test checks for normality in the first stage by 

performing a Kolmogorov-Smirnov test. Depending on the results of the first test, the 

second stage compares the variance of the experimental data to the ground truths using 

either an F-test or Levene test. In the third stage, the means of the experimental data 

are compared to ground truths via a two-sample T-test or a Kruskal-Wallis test and, 

aggregating the information of all test, the principle hypothesis validity is determine. 

Understanding how the system is built, how this investigation plans to measure 

performance and what statistical tests will be used to complete the analysis, the 

experiments are conducted and results detailed. In the experimentation phase, 20 

participants complete each of the 3 tasks 2 times with different camera positions in each 

iteration. From the previous, several variables are collected, calculated and performance 

metrics are determined. After this, the results are compiled and shown in Chapter 5. The 

statistical results to each task are detailed separately so as to better understand how 

performance varies according to each task. Briefly, each task: straight trajectory tasks, 

reverse trajectory tasks and path following tasks, overwhelmingly show that remote 

operator performance is significantly different to in-situ drivers and generally 

 

133 

underperforms. However, in some cases, more experienced drivers were able to perform 

on par with in-situ drivers. 

In an attempt to recognize possible causes to the results obtained, a comparison 

between camera location and user performance is completed. The same statistical 

procedures used to determine the initial hypothesis is performed on a secondary 

hypothesis that postulates “the camera positions have a significant effect on 

performance when teleoperating a vehicle”. The results to this analysis show no 

significant difference between the means and thus lead this investigation to conclude 

camera position does not influence operator performance. Hence other sources of 

variance are studied in hopes of identifying bottlenecks in the system. From this, two 

main factors are thought to contribute to reduced performance: network congestion and 

variability of bandwidth utilization. 

By the end of Chapter 5 an attempt to explain what this investigation believes is 

that principle cause of reduced performance is made via an analogy of water flowing 

through a pipe. Water represents the amount of information being sent by the video and 

data streams to the control station, and the diameter of the pipe is analogous to the 

bandwidth of the network. Hence, the amount of water that needs to be sent over the 

pipe will vary depending on the amount of information that is being sent over the 

network. If the vehicle needs to turn the then data stream starts to utilize more 

bandwidth as will the rapid changes in scenery, analogously more water needs to be 

sent through the pipe. If the pipe is large enough, then it doesn’t matter if the water flow 

is large or small, because the pipe can handle the flow. But if the pipe diameter is not 

large enough, which might be due to network congestion, then the flow through the pipe 

will reach a maximum and water will start to accumulate at the entrance. This 

accumulation of water at the entrance can in turn be understood as latency. 

 

134 

Ultimately, this investigation works through the nuances of explaining the state of 

art of cellular teleoperation. It details the configuration of the system used and the 

method to statistically validate the principle hypothesis. Experimentation is completed in 

order to determine if the cellular teleoperated system is on par with in-situ driving. After 

processing the collected information and computing results, and though some operators 

were able to perform optimally, the main hypothesis “A vehicle can be controlled over a 

4G LTE network streaming HD video feedback” is rejected and possible complications 

are explored. 

6.2 Achievements 

Having summarized the work accomplished in this investigation, a list of 

achievements is given. The achievements are grouped into 4 subdivisions: 1) motivation 

and state of art, 2) system description and experimental design, 3) experiments and 

results, and 4) analysis of results. 

6.2.1 Motivation and State of Art 

In the subdivision, achievements that highlight why this investigation takes place 

and what has already been done are given. 

•  A need for measuring the efficacy of cellular teleoperated systems is established 

due to the breakthroughs in cellular transfer rates and ubiquity of coverage areas. 

• 

The state of art of cellular teleoperation is investigated and common methods for 

measuring system performance are outlined. Even though the common method of 

performance quantification is to measure system level variables, such as time delay 

and throughput, this research uses an alternative method to quantify performance in a 

more holistic point of view. 

 

135 

6.2.2 System Description and Experimental Design 

Specific achievements that highlight accomplishments relating to how the system 

is built and how this work designed the experiments to validate the principle hypothesis, 

“a vehicle can be controlled over a 4G LTE network streaming HD video feedback”, are 

given.  

•  A master-slave internet based teleoperated system is built, implementing minimal 

autonomous algorithms on the remote environment for safety reasons. 

•  Network address translation (NAT) is achieved using commercially available 

products that conveniently allow the use of web based API’s, such as webRTC.  

• 

Tasks that reflect real world difficulties while driving are established and data 

acquisition methods are implemented. The tasks are: 

-  Straight trajectory tasks: drive the vehicle in a straight line as fast as 

possible and stop on a given physical checkpoint. 

-  Reverse trajectory tasks: drive the vehicle in reverse and park in 

reverse. Subsequently the driver must pull out of the parking spot to the 

left and drive to the final checkpoint. 

-  Path following tasks: the driver must drive along a given path that 

requires him to pass over 2 checkpoints while turning to the left and 

park the vehicle in a parking spot. The driver must then pull out in 

reverse and park in reverse. Finally, the driver must pass over two more 

checkpoints and stop on the last checkpoint.  

•  A three stage statistical test method is detailed and used for determining the 

validity of this works principle hypothesis. The stages of the test are: 

-  Determining normality: first, the normality of the performance metrics are 

determined. This is done so that the proper test can be selected in the 

 

136 

subsequent stages, i.e. parametric or non-parametric statistical testing. 

A Kolmogorov-Smirnov test is used for testing Normality. 

-  Comparing variance of the performance metrics to ground truths: A 

comparison of variance between teleoperation and in-situ driving is 

performed. Depending on whether the performance metrics was 

deemed to be normal or not, an F-test (parametric) or a Levene test 

(less sensitive) is performed. 

-  Comparing means of the performance metrics to the ground truths: A 

comparison of the means between teleoperation and in-situ driving is 

performed. Depending on whether the performance metrics was 

deemed to be normal or not, a tow sample T-test (parametric) or a 

Kruskal-Wallis test (non-parametric) is performed. 

6.2.3 Experiments and Results 

The core of the work performed in this thesis is shown in the results section. 

Important achievements highlighted from the compiled results are listed herein. 

•  Over 5 hours of continuous teleoperation are logged by 20 participants completing 

a total of 120 runs. 

•  Results of the statistical testing of the Straight trajectory Tasks: 

- 

- 

The principle hypothesis is rejected, where 13 of a total of 20 metrics fail to 

meet statistically significant similarity to ground truth values. 

Nevertheless, in some cases high performing drivers did approximate values 

seen in ground truths. 

•  Results of the statistical testing of the Reverse Trajectory Tasks: 

- 

The principle hypothesis is rejected by 17 of a total of 20 metrics. 

 

137 

- 

- 

- 

- 

- 

As in the Straight Trajectory Tasks, some high performing operators are able 

to emulate in-situ driving characteristics. 

Contrary to the previous task, an abnormally high number of stops are 

observed. This is further studied and is a contributing factor in assuming that 

the video stream may cause reduced teleoperation performance. 

•  Results of the statistical testing of the Path Following tasks: 

The principle hypothesis is rejected by 19 of a total of 20 metrics. 

As in the Reverse Trajectory Tasks, some high performing operators are able 

to emulate in-situ driving characteristics. 

Similar to the previous task, an abnormally high number of stops are 

•  Specific insight gained by analyzing the response that the operators provided in 

observed. 

the questionnaire are listed herein: 

- 

It was seen that users overwhelmingly preferred driving with the camera 

positioned on the inside due to the feedback of current cockpit conditions that 

it relayed to the operators. 

- 

A majority of the users believe that they experienced video quality issues that 

heavily affected their performance, and of the issues they proclaimed that the 

low frame rate most affected their experience. 

- 

Pertaining to perceived time delay, a majority of the operators believed that a 

high time delay existed and affected their performance. On the other hand, to 

a lesser degree, some operator seemed to not experience a time daily that 

they believed affected their driving ability. 

- 

Finally, regarding overall performance, the majority believed they performed 

close to adequate, while the principle issue that they believed most affected 

their performance was time delay. 

138 

 

6.2.4 Analysis of Results 

As important as computing results and rejecting the principle hypothesis, finding 

possible root causes to why the given performance was witnessed, is paramount. The 

analysis of the results is presented in the second half of chapter 5 and important 

achievements extracted from this chapter are highlighted here. 

• 

• 

• 

• 

• 

Tring to elucidate probable causes for the reduced performance encountered in 

this investigation, performance metrics categorized by the camera position were 

analyzed. It was found that no statistical difference in the performance metrics between 

camera positions exists. Thus ruling out variance due to camera position. 

It was seen that the time of day played a significant factor in average latency for 

the more complicated tasks, Reverse Trajectory and Path following. 

Though not statistically proven, more complex tasks displayed higher average 

latencies. That is, Path Following tasks had a higher average latency than Reverse 

Trajectory Tasks. And analogously, Reverse Trajectory Tasks showed higher latencies 

that Straight Trajectory Tasks. 

Latency profiles for each task are studied and a correlation between scenery 

changes and latency spikes is hypothesized, but not statistically proven. 

It is believed that the main cause of the reduced performance observed in the 

teleoperations system is due to a mix of network congestion coupled with the variability 

of video and data strain on the cellular communications backbone. 

6.3 Future work 

In a way, statistically showing that the cellular teleoperated system is not up to 

par with in–situ drivers shows that there is only room for improvement. This is good on 

several more levels because it allows for new methods and ideas to flourish, ultimately 

 

139 

pushing researchers to investigate new ways of achieving tasks previously unthought-of. 

In an attempt to guide future works that may seek to implement a cellular teleoperated 

system, possible research avenues are listed. 

As seen in this research, several fronts of investigation are open to further 

development. Among the most important, according to this authors view, are 3 

fundamental areas of study: predicting network congestion, predicting loss of connection 

and allowing parallel connections or implementing connection redundancies.  

6.3.1 Predicting Congestion 

By the end of chapter five, it has become increasingly clear that the quality of 

video streaming and overall system latency depend on how congested the cellular 

network is. Unfortunately, the teleoperated system has no control over the amount of 

people connecting to the cellular network. Notwithstanding, it is the belief of this 

research that if one could know actual bandwidth restrictions, then preventive measure 

could be taken so as to reduce strain on the system by limiting bandwidth.  

By limiting the maximum bandwidth used, it is expected that the latency in the 

system would tend to decrease. By decreasing the time delay in the system, then the 

users should feel that the remote environment is more responsive to their stimuli and 

thus improve user performance metrics. 

This line of investigation brings forth two fundamental issues so as to properly 

implement; 1- how to effectively predict network congestion and 2- what signal should be 

throttled to minimize bandwidth use while maximizing user performance.  

Both lines of research pose significant difficulties due to the nature of what is 

being investigated. However, if successfully implemented, they may allow for enhanced 

performance for longer periods of time over any cellular network. 

 

140 

6.3.2 Predicting Loss of Connection 

While congestion is an important issue that should be addressed to improve 

operator performance. A more significant threat to systems stability is a loss of 

connection with the remote environment. Though this condition rarely happens when 

teleoperating over a cellular network, and in this investigations tests it did not occur, it is 

a matter that poses important consequences. Predicting real-time connection loss is a 

difficult task and, to the knowledge of this author, no particular algorithm exists capable 

of such feat. However approximations do exist.  

This topic, too, has two central points that must be studied in order to achieve 

proper implementation; 1- predicting actual connection loss and 2- autonomous control 

algorithm that handle the vehicle after loss of connection is detected. 

Regarding the connection loss research area, real time implementation of this is 

relative to what is understood as real time. In other words how fast does the algorithm 

have to detect that the operator station is no longer receiving or sending information. 

This is a difficult question and determining any valuable metric may be even harder, due 

to the variable nature of an internet connection. However it is vital for safe 

implementation of any teleoperation system. 

Secondly, what should be done when connection loss is detected? This may not 

be as complex as the previous obstacle due to recent advances in autonomous vehicles. 

Nevertheless, questions regarding the nature and extent of autonomous algorithm 

implementation should be studied. 

6.3.3 Parallel Connections or Redundancies 

Finally, one of the last lines of research that can be investigated in hopes of 

improving the cellular teleoperated system is how to maintain a parallel or redundant 

 

141 

connection. Thought these two concepts are shown together, they are far from it and 

both can be implemented simultaneously or separately having different effects on overall 

system performance.  

Implementing redundancies in the system would be aimed at trying to reduce 

connection losses by having a backup system on standby. Though this may seem like a 

straight forward implementation, in practice it is much more complicated to achieve 

optimal implementations due to the significant initialization time for the system to come 

back online. Work in this area would be focused on understanding when a connection 

loss is possible and how to reduce the initialization time of the standby system so that 

minimal control loss is experienced. 

On the other hand, parallel connections aim to virtually decrease bandwidth 

constraint on the system by adding a second pipeline for data to flow through. Here, data 

and video channels could be separated and routed through different cellular modems. 

This would effectively reduce the amount of information being streamed through the 

each pipeline in the system during high bandwidth consumptions, like steering the 

vehicle and fast scenery changes, ultimately improving driver performance of the 

teleoperated system.

 

142 

APPENDIX A

  

TELEOPERATION SYSTEM 

NODE AND INFORMATION FLOW 

DESCRIPTION 

The teleoperation system, as described in CHAPTER 3, is made up of several 

nodes and information flows. These are described in Section 3.2 of CHAPTER 3, but 

shall be further detailed here. In other words, this appendix further details the content of 

the information in each flow line in Figure A-1 along with providing descriptions of each 

control node. Furthermore, a list of all variables available in each flow line is shown in 

Table A-1. Lastly, Table A-2 details the make and model of all relevant hardware 

included in the project. 

Figure A-1 Remote Vehicle Control Nodes and Information Flow 

 

 

 

143 

•  Remote Vehicle Information flow: 

- 

Incoming, line 1: The incoming signals are all those necessary to control the 

vehicle. These signals come into the server in an asynchronous fashion and 

are executed in the order they arrive. Each incoming variables is formatted as 

an object type that carries a command value and a time stamp. The Value is 

generated in the operator station and carried through the system eventually 

being interpreted by the microcontroller. The Time stamp represents the 

moment at which the signal was generated in the operator stations and is 

used for posterior statistical analysis.  

- 

Index to Main Program, line 2: The same variables that are sent to the 

index node are then relayed to the main program in the control logic node. 

-  Main Program to Microcontroller, line 3: The information present in this 

data stream is sent to the microcontroller through a serial communications 

link at the highest baud rate commonly used for these microcontrollers. 

-  Microcontroller to Cart, line 4: The control signals sent to the vehicle are 

formatted as a PWM that is interpreted by the vehicles controller as a RMS 

voltage that ranges from 0 to 5 volts. The microcontroller also governs a drive 

for the stepper motor that directs the vehicle’s steering wheel, by sending it 

the number of steps required for the motor to be in the correct spot. 

- 

Cart to Microcontroller, line 5: Part of the information that is relayed back to 

the user is captured in the vehicle and sent to the micro controller for 

processing so that it can be formatted correctly. In this stream, information is 

sent back as a pulse or data stream depending on the sensor data being 

acquired. 

-  Microcontroller to Main Program, line 6: The information is sent back to 

the main program in the same manner that it was delivered originally to the 

 

144 

microcontroller so that it can either be formatted for sending to the operator 

page as feedback or for local data acquisition. 

- 

Cart to Main Program, line 7: Signals not sent to the microcontroller are 

sent directly to the main program. These are sent as serial communication 

streams. 

-  Main Program to Index, line 8: Specific vehicle feedback acquired and 

formatted in the main program is sent to the Index page. 

The feedback signals that are used for augmenting the video streams are 

parsed, formatted and sent to the index page as internal memory data 

streams at a periodic rate so as to not saturate communication. 

- 

Cart to Index, line 9: The video feedback captured on the cart is sent directly 

to the index page. 

-  Outgoing, line 10: All of the vehicle feedback and camera streams are 

lumped together and sent back to the operator page in the same fashion that 

they are received. In other words, data that is used for the GUI is formatted 

as an object type that carries a value (no time stamp this time) and sent back 

asynchronously, while video feedback is simultaneously streamed to the 

user. 

•  Remote Vehicle Control / Nodes: 

- 

Node JS: The node JS Server is the initial step towards starting the whole 

system. This server contains the main program that handles the relaying of 

information to and from the operator (specified in the Index file) and the main 

program, which computes proper formatting for the control signals and 

monitors variables that insure system safety. 

- 

Index: This node is programed in HTML and JavaScript. Its main goal is to 

establish a connection with Opentok, using webRTC, to stream video 

 

145 

feedback and exchange data between the client (operator station) and server 

(on the remote vehicle). It is the main gateway for incoming and outgoing 

information and distributes the data accordingly by relaying all control signals 

to the main program and consolidating video and data feedback for the 

operator station. 

-  Main program: The main program receives control information from the 

index module, processes it and relays it back to the vehicle. Specifically, this 

program scales the information into ranges that the microcontroller can 

handle, while also monitoring key parameters, such as connectivity and 

proximity sensors, with the intent of taking emergency actions in case any 

value passes a predefined safety threshold.  

Simultaneously, it captures feedback of vehicle statistics, like current velocity 

or direction heading and compiles this into a format that can be transmitted 

back to the operator station. 

-  Microcontroller: The microcontroller’s main function is to relay information to 

the vehicle in a way that the automobile can interpret the signals and produce 

an action. In other words, it interprets the serial communication stream 

coming from the main program and converts the information into a PWM 

signal that is interpreted as a DC volt signal ranging from 0 to 5 volts in the 

vehicle controller. It also controls a stepper motor driver by sending the 

amount of steps that the motor should move in order to reach its required 

position. 

At the same time, it registers incoming information from several different 

sensors placed on the vehicle and relays this back to the main program so 

that it may be formatted and sent back to the operator station. 

 

146 

- 

Cart: Finally the cart is the system which will be controlled. All signals sent 

through the microcontroller are sensed by the vehicles controller that 

commands an AC electric motor. On top of this, a stepper motor and drive 

govern the steering wheel. All these equipment are calibrated so as to allow 

the lowest possible delay between a received pulse and the execution of an 

action. 

In addition to controlling the vehicle, sensors are placed in strategic locations 

that allow for the driver to receive additional information about situations that 

may not be easily extracted by just looking at the visual feedback provided. 

These sensors are a GPS device, a 2D LIDAR that scans the mediate 

proximity in front and a Hall Effect speed sensor that calculates the current 

velocity. As explained, some sensors are routed to the microcontroller while 

other go directly to the main program. 

 

 

 

Variable  

Description 

L1  L2  L3  L4  L5  L6  L7  L8  L9  L10 

Table A-1 List of Remote Vehicle Variables 

Steering 

Steering 

Steering wheel angle signal 
from operator: value range 
from -1 to +1. 

Steering wheel angle signal 
from main program: value 
range from -450 to +450. 

Steering 
Feedback 

Steering wheel feedback 
from encoder: Values range 
from -7000 to +7000. 

Acceleration 

Acceleration signal from 
operator: Values range from 
-1 to +1. 

 

 

 

 

X  X 

X  X 

 

 

 

 

 

 

X  X 

 

 

 

 

X  X 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

147 

Variable  

Description 

L1  L2  L3  L4  L5  L6  L7  L8  L9  L10 

Table A-1 Continued 

Acceleration  

Acceleration signal from 
main program: value range 
from -250 to +250. 

 

 

X  X 

Brake signal from operator: 
Values range from -1 to +1. 

X  X 

 

 

Brake signal from main 
program: value range from -
250 to +250. 

Ignition / Direction signal 
from operator: Values range 
from -1 to +1. 

Ignition / Direction signal 
from main program: value 
range from -250 to +250. 

LIDAR feedback: values are 
distance and angle and 
range from 0 to 6 [m] and 
270 to 90 degrees. 

Pulse detection – wheel 
counter: values are logical 0 
or 1 

Distance and Velocity 
calculation: values are larger 
than 0.  

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

X 

X 

 

X  X 

X 

X 

X  X 

X 

X  X 

X  X 

 

 

X 

X 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

X  X 

X  X 

 

 

X  X 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

GPS 

GPS coordinates 

Gyroscope 

Z-axis of gyroscope reading. 

Camera 
Stream 

Data stream from cameras 

148 

Brake 

Brake 

Ignition / 
Direction 

Ignition / 
Direction 

LIDAR 

Hall Effect 

Hall Effect 

 

 

Figure A-2 Local Operator Station Control Nodes and Information Flow 

 

Using Figure A-2, a description of the principle flows and nodes is detailed. 

•  Operator Station information Flow: 

- 

Incoming: The incoming information is mainly composed of the video stream 

session held by webRTC, and supplementary info such as GPS position or 

LIDAR point cloud. 

-  Outgoing: The outgoing data stream on the Operator side is the same as the 

incoming stream on the remote side and is detailed in the previous section, 

as is analogously explained the incoming stream. 

•  Operator Station Nodes 

-  Operator station: This main node, which contains the two processing 

programs, is manually started by the driver by accessing the Operator web 

page through a web browser. Once started, it connects to the remote server 

and immediately starts poling the gamepad for control signals while 

requesting permission to receive incoming video streams and supplementary 

data.  

149 

 

 

-  Gamepad Node: This node represents the direct interaction that the driver 

has with the operator station with the intent of controlling the remote vehicle. 

Here, the user must physically manipulate the different elements, i.e. steering 

wheel, gas pedals, etc. which are logged and compiled into data packets that 

are sent as quickly as possible to the remote server. Ideally one would like to 

poll the input devices as fast as possible, unfortunately high data acquisition 

frequencies may saturate the communications link, thus a balance must be 

found between provide sufficient polling for smooth control while not posing a 

significant threat to the stability of the communications link.  

-  Graphics display node: As the main operator page is initialized, three 

windows are opened and available to the operator to be resized and fit to 

each screen so as to provide him with the most comfortable setup allowable. 

Each window is labeled with the camera view that it will display and has a 

button that, when toggled, enables the particular video stream commence in 

said window. Furthermore, the front view window also incorporates in it the 

rear view in the bottom right side, allowing for more information to be shown 

more densely. 

 

Table A-2 Equipment Description 

Equipment Name 

Make/Model 

Laptop 

4G LTE Modem 

Lenovo ThinkPad, intel I5, 
2x2.53 GHz, 4 GB RAM, 
64-bit windows 7. 

AT&T Modem; Netgear 
Aircard 770S. 

 

 

150 

Table A-2 Continued 

Equipment Name 

Make/Model 

Microcontroller 

Vehicle Controller 

Arduino Mega 2560 
(ATmega2560) 

ACD4805-G5 Controller 
for EZGO RXV 

LIDAR 

Robo Peak RPLidar 360 

Hall Effect Sensor 

Gyroscope 

Stepper Motor 

Video Camera  

Operator Station CPU 

Game Pad 

Hall Effect Sensor - 
US1881 

ITG-3200 - triple-axis 
digital-output gyroscope 

Kolmorgen P70530 step 
motor and drive. 

Panasonic Action Camera 
HX-A1MD 

Intel core I7, 2x2.8 GHz, 6 
GB RAM, 64-bit windows 
7. 

Logitech Racing Wheel 
G27 

 

 

 

 

151 

APPENDIX B

  

QUESTIONAIRE AND RESULTS 

 

152 

 

153 

 

For the following questions, please rate on a scale of 1 to 6. In some cases, you 

will be asked to choose between one option and the other, and a binary scale will be 

1)  Did you experience video quality problem? Understand problems as reduced resolution or low 

shown. 

REGARDING FEEDBACK 

Visual feedback: 

frame rate.  

1 

2 

3 

4 

5 

6 

1- A lot of Problems 

6- No problems 

2)  Of the issues related to video quality, how good was the resolution? 

1 

2 

3 

4 

5 

6 

1- very bad 

6- very good 

3)  Of the issues related to video quality, how good was the frame rate? 

1 

2 

3 

4 

5 

6 

1- very bad 

6- very good 

4)  How did the video quality affect your performance? 

1 

2 

3 

4 

5 

6 

1-barely affected 

6-heavily affected 

5)  Which parameter, if improved, would most affect your performance? 

1 

2 

1- resolution 

2- frames per 
second 

 

 

 

 

 

154 

Camera display and swivel camera: 

6)  I found that the Graphics User Interface was… 

1 

2 

3 

4 

5 

6 

1-Counter intuitive 

6-Intuitive 

7)  I felt that changing between camera views or toggling them on and off was… 

1 

2 

3 

4 

5 

6 

1-Difficult 

6-Simple 

8)  When turning a camera stream on or off, I felt… 

1 

2 

3 

4 

5 

6 

1- It took too long 

6-It was Quick 

9)  I felt that using the swivel cam was… 

1 

2 

3 

4 

5 

6 

1-Difficult 

6-Simple 

10) The time it took to switch viewing angles with the swivel cam was… 

1 

2 

3 

4 

5 

6 

1-Too long 

6-Quick 

11) Comparing more camera views directly to one camera that swivels, I prefer… 

1 

2 

3 

4 

5 

6 

1- Only swivel cam 

6- More camera views 

12) Having the choice between more cameras and lower quality or less cameras and higher quality I 

prefer… 

1 

2 

3 

4 

5 

6 

1-less cameras 

6-More cameras 

 
 
 

 

155 

13) Taking into account video quality, I believe my performance would be enhanced with… 

1 

2 

3 

4 

5 

6 

1- Only swivel cam 

6- More camera views 

14) Hypothetically, if there were no limitations on the amount of cameras that could correctly stream 

video and taking into account the time it takes to turn on or switch camera views, I prefer 

1 

2 

3 

4 

5 

6 

1- Only swivel cam 

6- More camera views 

15) The rear camera setup was… 

1 

2 

3 

4 

5 

6 

1-Counter intuitive  

6- Intuitive 

16) I preferred driving the vehicle with the cameras positioned… 

 

 

Regarding Camera positioning: 

1 

2 

1- Outside 

2- Inside 

17) With the camera positioned outside, my spatial awareness was… 

 

1 

2 

3 

4 

5 

6 

1- Poor 

6- Excellent 

18) With the camera positioned inside, my spatial awareness was… 

 

1 

2 

3 

4 

5 

6 

1- Poor 

6- Excellent 

Regarding Additional Feedback Sensors: 

19) If Audio feedback was present, how do you believe it would affect your performance?   

1 

2 

3 

4 

5 

6 

1- Hinder 

6- Improve 

 

156 

20) If Force feedback was present, how do you believe it would affect your performance?   

1 

2 

3 

4 

5 

6 

1- Hinder 

6- Improve 

REGARDING AUXILARY FEEDBACK 

Regarding the Prediction line (green and red lines on the front camera view) 

21) Was the prediction line useful?   

1 

2 

3 

4 

5 

6 

1- Not Helpful 

6-Very helpful 

22) The prediction line was useful in establishing where the vehicle would be in the near future. 

 

1 

2 

3 

4 

5 

6 

1- Disagree 

6- Agree completely 

23) The prediction line was useful because I had visual feedback as to the inputs that I was sending 

to the cart. 

 

1 

2 

3 

4 

5 

6 

1- Disagree 

6- Agree completely 

24) If the prediction line was not present my performance would… 

1 

2 

3 

4 

5 

6 

1- Diminish 

6- Improve 

REGARDING TIME DELAY IN CONTROLS 

Regarding time delay 

25) How much time delay in controls did you experience?   

1 

2 

3 

4 

5 

6 

1- Insignificant 

6- Significant 

 

157 

 

 

26) Independent of whether the time delay in controls was significant or not, rate the variation of the 
time delay, i.e. a high variability in the time delay implies that time delay varied several times 
from high lag to low lag. 

 

1 

2 

3 

4 

5 

6 

1- Very variable 

6- Very stable 

27) Not considering visual quality issues, the time delay I was exposed to affected my performance...

   

1 

2 

3 

4 

5 

6 

1- Significantly 

6- Very little  

REGARDING THEOVERALL SYSTEM 

28) My performance was 

 

1 

2 

3 

4 

5 

6 

1- Inadequate 

6- Adequate 

29) If the time delay in the controls was reduced, my performance would… 

1 

2 

3 

4 

5 

6 

30) If the resolution of the video was improved, my performance would… 

1 

2 

3 

4 

5 

6 

31) If the frame rate was increased, my performance would… 

1 

2 

3 

4 

5 

6 

1- Be hindered 

1- Be hindered 

1- Be hindered 

6- Improve 
significantly 

6- Improve 
significantly 

6- Improve 
significantly 

 
 
 
 

 

158 

32) If I had more camera views on continually, my performance would… 

1 

2 

3 

4 

5 

6 

1- Be hindered 

6- Improve 
significantly 

33) To what extent did the User Interface affect my performance 

1 

2 

3 

4 

5 

6 

1- Slightly 

6- Significantly 

34) What most hindered my performance was… 

_______________________ 

35) Please add any additional comments that you believe are pertinent to this survey and were not 

fully addressed. 

_______________________ 

 

NASA TLX Results: 

The Results to the questionnaire are detailed herein as a frequency distribution. 

Scale 
Q1 
Q2 
Q3 
Q4 
Q5 
Q6 

2 

6 

5 

3 

4 

8 

7 

1 

10 
0.00  0.00  0.00  0.05  0.00  0.10  0.05  0.00  0.05  0.00 
0.30  0.05  0.10  0.05  0.05  0.00  0.05  0.00  0.05  0.05 
0.15  0.05  0.05  0.00  0.05  0.10  0.05  0.00  0.05  0.05 
0.00  0.00  0.05  0.00  0.05  0.10  0.10  0.05  0.10  0.10 
0.00  0.00  0.00  0.05  0.00  0.00  0.00  0.10  0.05  0.10 
0.00  0.05  0.05  0.05  0.05  0.05  0.10  0.05  0.00  0.00 

9 

12 

13 

11 

16 

19 

14 

18 

15 

17 

20 
0.20  0.00  0.05  0.05  0.15  0.05  0.25  0.00  0.00  0.00 
0.20  0.05  0.05  0.00  0.00  0.00  0.00  0.00  0.00  0.00 
0.15  0.10  0.05  0.15  0.00  0.00  0.00  0.00  0.00  0.00 
0.05  0.10  0.10  0.05  0.00  0.15  0.00  0.00  0.00  0.00 
0.15  0.00  0.05  0.05  0.05  0.15  0.10  0.10  0.05  0.00 
0.15  0.05  0.05  0.05  0.10  0.20  0.00  0.00  0.00  0.00 

Scale 
Q1 
Q2 
Q3 
Q4 
Q5 
Q6 

 

 

159 

Questionnaire Results: 

Scale 
Q1 
Q2 
Q3 
Q4 
Q5 
Q6 
Q7 
Q8 
Q9 
Q10 
Q11 
Q12 
Q13 
Q14 
Q15 
Q16 
Q17 
Q18 
Q19 
Q20 
Q21 
Q22 
Q23 
Q24 
Q25 
Q26 
Q27 
Q28 
Q29 
Q30 
Q31 
Q32 
Q33 

1 

2 

3 

5 

4 

6 
0.00  0.00  0.00  0.05  0.00  0.95 
0.30  0.05  0.10  0.05  0.05  0.45 
0.15  0.05  0.05  0.00  0.05  0.70 
0.00  0.00  0.05  0.00  0.05  0.90 
0.00  0.00  0.00  0.05  0.00  0.95 
0.00  0.05  0.05  0.05  0.05  0.80 
0.10  0.30  0.15  0.10  0.05  0.30 
0.05  0.10  0.40  0.15  0.15  0.15 
0.15  0.15  0.20  0.25  0.15  0.10 
0.10  0.05  0.20  0.10  0.40  0.15 
0.20  0.80  0.00  0.00  0.00  0.00 
0.00  0.00  0.00  0.25  0.40  0.35 
0.00  0.00  0.05  0.10  0.20  0.65 
0.05  0.05  0.10  0.35  0.25  0.20 
0.00  0.00  0.05  0.05  0.15  0.75 
0.00  0.05  0.00  0.05  0.40  0.50 
0.10  0.20  0.20  0.15  0.05  0.30 
0.20  0.40  0.05  0.20  0.15  0.00 
0.10  0.30  0.20  0.25  0.10  0.05 
0.00  0.10  0.10  0.15  0.30  0.35 
0.05  0.05  0.05  0.20  0.35  0.30 
0.20  0.80  0.00  0.00  0.00  0.00 
0.15  0.20  0.10  0.25  0.25  0.05 
0.00  0.05  0.05  0.30  0.35  0.25 
0.00  0.00  0.00  0.45  0.25  0.30 
0.00  0.00  0.15  0.10  0.40  0.35 
0.00  0.00  0.10  0.05  0.45  0.40 
0.00  0.00  0.10  0.20  0.30  0.40 
0.00  0.00  0.00  0.20  0.40  0.40 
0.30  0.45  0.25  0.00  0.00  0.00 
0.10  0.30  0.10  0.15  0.20  0.15 
0.15  0.15  0.15  0.15  0.30  0.10 
0.05  0.25  0.10  0.30  0.20  0.10 

 

160 

APPENDIX C

  

RESULTS – PERFORMANCE METRICS 

This Appendix details the calculated values of the performance metrics for every 

task executed by the subjects. Each row in the main table represents a different subject 

and the columns represent the performance metric value to the corresponding task. 

Table C-1 correlates the column identification label with the actual performance metric. 

Table C - 1 Correlation between Column and Performance metric 

Column 

Performance Metric 

Area 

Area [m^2] 

Length 

Length of Run [m] 

A/L 

Ratio of Area over Length [-] 

Max. D. 

Maximum Distance Deviation [m] 

Str. Cor. 

Steering Correction [-] 

Acc. Cor. 

Acceleration Correction [-] 

Brk. Cor. 

Brake Correction [-] 

Max. Sp. 

Maximum Speed [m/s] 

Av. Sp. 

Average Speed [m/s] 

A/T 

Area in Function of Time [-] 

Av. M. Sp.  Average Moving speed [m/s] 

SD. M. Sp.  Standard Deviation of Moving Speed [m/s] 

Stops 

Stops [-] 

T. Mov. 

Time Moving [s] 

T. Stp. 

T. Run 

T. Ini. 

Time Stopped [s] 

Time of Run [s] 

Time to Initialize [s] 

T.S/T.M. 

Ratio of Time Stopped over Moving Time [-] 

T.S./T.T. 

Ratio of Time of Stopped over Total Time [-] 

 

161 

 

 

 

 

 

 

Table C-1 Continued 

T.M./T.T. 

Ratio of Time Moving over Total Time [-] 

T. of D. 

Time of Day [h] 

Av. Lag 

Mean Latency [ms] 

S.D. Lag 

Standard Deviation of Latency [ms] 

162 

 

 

Area 

Length 

A/L 

Max. D. 

Str. Cor. 

Acc. Cor  Brk. Cor.  Max. Sp 

Av. Sp. 

A/T 

Av. M. Sp. 

Table C - 2 Path Following Camera Inside 

64.24269 

87.89728 

0.730884 

4.888466 

2.743363 

0.312823 

6372.5 

45.66588 

89.0305 

0.512924 

3.233932 

1.911 

0.308108 

4573.015 

108.6114 

87.21418 

1.245341 

5.087353 

2.318795 

0.445353 

5737.143 

68.83962 

92.39096 

0.74509 

3.98712 

2.404676 

0.561111 

2337.613 

38.35807 

93.79436 

0.408959 

1.794281 

2.434734 

0.730384 

883.2384 

116.7575 

117.3416 

0.995022 

4.43547 

57.87079 

94.81366 

0.610363 

3.93243 

1.95452 

0.410095 

7618.581 

2.318795 

0.468431 

2719.757 

100.3666 

115.2478 

0.870877 

2.649327 

1.636796 

0.233826 

10885.83 

72.5172 

94.3103 

0.768921 

3.557982 

1.583567 

0.223525 

5849.01 

1
6
3

 

141.5441 

97.5162 

1.451493 

5.163758 

2.016038 

0.583666 

3855.086 

76.15319 

88.2038 

0.863378 

4.066671 

2.008028 

0.736712 

2353.94 

73.29974 

95.38715 

0.768445 

3.064837 

11 

2.213395 

0.599549 

3036.747 

58.17601 

86.05521 

0.676031 

4.827348 

1.803507 

0.562838 

2676.755 

158.7171 

107.6479 

1.474409 

6.861242 

100.594 

100.0323 

1.005615 

4.095107 

2.008028 

0.53218 

5779.07 

1.946 

0.762236 

2995.28 

150.0286 

96.74272 

1.5508 

9.828469 

1.872873 

0.577233 

4926.804 

101.224 

100.2605 

1.00961 

4.223937 

15 

2.072114 

0.388724 

8195.909 

129.4814 

93.84011 

1.379808 

4.880369 

2.188525 

0.582049 

5964.13 

114.1539 

93.05264 

1.226767 

5.047022 

2.11716 

0.563614 

5665.708 

120.0226 

105.4863 

1.137803 

8.170613 

62 

36 

1.75553 

0.290591 

7402.716 

9 

8 

5 

6 

4 

22 

11 

13 

14 

6 

5 

3 

6 

7 

7 

7 

5 

25 

35 

17 

29 

21 

55 

39 

43 

36 

21 

10 

35 

31 

21 

21 

29 

52 

21 

39 

71 

 

31 

34 

19 

23 

35 

31 

41 

66 

44 

18 

14 

22 

30 

28 

22 

34 

30 

22 

42 

1.2297 

1.2680 

1.2129 

1.0727 

1.2751 

1.0138 

1.0585 

0.7294 

0.7460 

1.2317 

1.1896 

1.2514 

1.1297 

1.0977 

1.3447 

1.0710 

0.9653 

1.0831 

1.0819 

0.9607 

SD. M.Sp.  Stops 

T. Mov. 

T. Stp. 

T. Run 

T. Ini. 

T.S./T.M. 

T.S./T.T. 

T.M./T.T. 

T. of D.  

Av. Lag 

S.D. Lag 

1
6
4

 

4 

8 

5 

4 

4 

12 

8 

11 

13 

5 

3 

7 

5 

4 

5 

9 

8 

8 

0.4860 

0.5686 

0.4750 

0.5025 

0.4757 

0.4932 

0.5047 

0.3677 

0.4290 

0.4634 

0.4539 

0.5229 

0.4351 

0.3754 

0.5174 

0.4416 

0.4505 

0.4939 

 

 

 

 

101.58 

179.24 

280.81 

265.80 

102.55 

186.35 

288.91 

92.80 

102.70 

195.50 

130.63 

87.70 

33.91 

40.57 

164.54 

191.03 

128.27 

163.37 

122.55 

285.93 

122.70 

79.39 

202.08 

215.30 

277.00 

492.31 

190.83 

230.93 

421.76 

100.45 

92.58 

102.93 

92.99 

119.82 

86.98 

112.82 

66.41 

26.93 

55.94 

59.97 

82.21 

44.11 

54.54 

166.86 

119.50 

158.86 

152.96 

202.03 

131.09 

167.37 

111.28 

112.88 

50.02 

51.97 

161.30 

164.85 

Table C – 2 Continued 

80.67 

43.09 

31.99 

21.85 

91.31 

55.89 

66.33 

62.77 

31.87 

35.88 

22.33 

83.58 

34.98 

20.12 

22.73 

65.11 

25.17 

70.87 

1.765 

1.817 

1.107 

0.260 

0.463 

0.750 

0.647 

1.287 

1.210 

0.661 

0.291 

0.543 

0.645 

0.686 

0.507 

0.483 

0.787 

0.450 

0.460 

1.248 

 

0.4892 

12 

144.38 

113.67 

258.05 

0.4792 

14 

161.28 

201.35 

362.62 

0.638 

0.645 

0.525 

0.206 

0.316 

0.429 

0.393 

0.563 

0.548 

0.398 

0.225 

0.352 

0.392 

0.407 

0.336 

0.326 

0.440 

0.310 

0.315 

0.555 

0.362 

0.355 

0.475 

0.794 

0.684 

0.571 

0.607 

0.437 

0.452 

0.602 

0.775 

0.648 

0.608 

0.593 

0.664 

0.674 

0.560 

0.690 

0.685 

0.445 

20.583 

561.645 

667.223 

18.983 

1421.468 

1759.177 

19.850 

274.249 

273.897 

16.067 

647.287 

546.877 

16.950 

77.918 

41.543 

17.200 

2031.308 

2371.076 

18.400 

484.535 

617.045 

19.033 

116.714 

799.627 

20.067 

102.593 

25.187 

19.133 

98.428 

70.814 

19.700 

83.357 

41.703 

19.167 

111.127 

113.575 

19.633 

119.418 

117.838 

17.867 

749.084 

1028.128 

20.617 

194.292 

256.477 

15.450 

688.998 

1454.423 

19.700 

405.460 

664.224 

19.100 

94.561 

49.834 

18.917 

697.153 

1072.517 

16.033 

636.138 

640.590 

 

 

 

 

 

Table C - 3 Path Following Camera Outside 

Area 

Length 

A/L 

Max. D. 

Str. Cor.  Acc. Cor  Brk. Cor.  Max. Sp  Av. Sp. 

A/T 

Av. M. Sp. 

68.45724  87.77871  0.779884  3.42637 

68.45724  87.77871  0.779884  3.42637 

35 

35 

1.498298  0.174432  9869.227 

0.816942 

1.498298  0.174432  9869.227 

0.816942 

70.99353  83.42185  0.851018  3.570715  14 

2.188525  0.374159  6751.261 

1.044348 

60.4654 

93.61937  0.645864  4.465372  31 

1.882234  0.474995  3690.491 

1.101347 

42.09235  91.61888  0.459429  1.529097  36 

2.188525  0.556318  1429.141 

1.199922 

151.5726  109.7326  1.381291  5.160174  37 

2.021583  0.413227  10133.65 

1.297457 

49.95465  87.41656  0.571455  2.518123  39 

2.375351  0.448195  2732.5 

0.942824 

103.4208  106.6938  0.969323  5.047023  42 

1.803507  0.289198  12301.09 

0.985687 

67.62875  87.00289  0.777316  3.453852  53 

1.837535  0.253258  10657.52 

0.88841 

107.8661  96.76128  1.114765  4.106113  31 

2.072114  0.359783  5912.987 

1.021842 

73.05215  83.05803  0.879531  2.471936  25 

2.164208  0.620616  1761.434 

1.223552 

1
6
5

 

56.43072  87.31979  0.646254  2.674804  44 

12 

2.264869  0.422452  2367.802 

1.13179 

45.66943  78.40899  0.582451  2.556567  24 

1.909596  0.488608  1945.259 

1.190567 

81.39098  101.1931  0.804313  4.895231  38 

2.015 

0.328305  8252.434 

0.992921 

73.56432  87.03871  0.845191  3.651997  27 

2.188525  0.652873  2816.252 

1.304662 

216.424 

123.6354  1.750503  7.373601  42 

1.969 

0.406444  11388.32 

1.039356 

43.45946  92.06667  0.472043  1.659728  20 

1.872873  0.494719  2325.875 

0.994877 

219.897 

105.1172  2.091923  14.25785  27 

2.050303  0.594864  10364.05 

1.177853 

180.2926  120.6917  1.493828  9.205496  51 

1.773 

0.458369  10103.75 

1.189642 

138.3527  112.1302  1.233858  5.931503  62 

2.188525  0.259612  18936.27 

0.863392 

49 

49 

25 

30 

27 

45 

41 

43 

52 

21 

17 

35 

23 

41 

17 

45 

33 

29 

63 

65 

11 

11 

3 

15 

6 

23 

10 

13 

30 

1 

8 

3 

7 

6 

5 

3 

14 

23 

37 

 

SD. M.Sp. 

Stops 

T. Mov. 

T. Stp. 

T. Run 

T. Ini. 

T.S./T.M. 

T.S./T.T. 

T.M./T.T. 

T. of D.  

Av. Lag 

S.D. Lag 

Table C - 3 Continued 

162.119 

340.372 

502.491 

34.265 

2.09952 

0.67737 

0.32263 

162.119 

340.372 

502.491 

34.265 

2.09952 

0.67737 

0.32263 

111.631 

111.176 

222.807 

43.87 

0.99592 

0.49898 

0.50102 

19.750 

175.147 

364.176 

17.750 

175.147 

364.176 

19.250 

117.423 

92.934 

117.572 

79.259 

196.831 

20.135 

0.67413 

0.40268 

0.59732 

15.600 

1051.341 

1471.814 

100.459 

64.448 

164.907 

58.297 

0.64154 

0.39081 

0.60919 

16.783 

98.479 

58.014 

104.973 

160.874 

265.847 

49.389 

1.53253 

0.60514 

0.39486 

121.268 

73.426 

194.694 

24.366 

0.60549 

0.37714 

0.62286 

135.639 

232.773 

368.412 

48.876 

1.71612 

0.63183 

0.36817 

0.459033 

10 

143.761 

200.023 

343.784 

72.499 

1.39136 

0.58183 

0.41817 

1
6
6

 

132.627 

135.897 

268.524 

90.494 

1.02466 

0.50609 

0.49391 

94.254 

39.445 

133.699 

44.325 

0.41850 

0.29503 

0.70497 

106.054 

100.043 

206.097 

52.903 

0.94332 

0.48542 

0.51458 

93.841 

66.811 

160.652 

42.84 

0.71196 

0.41587 

0.58413 

0.690795 

12 

148.739 

159.176 

307.915 

48.48 

1.07017 

0.51695 

0.48305 

0.488319 

6 

82.662 

50.398 

133.06 

28.708 

0.60969 

0.37876 

0.62124 

173.114 

131.195 

304.309 

75.394 

0.75785 

0.43112 

0.56888 

124.777 

61.057 

185.834 

23.093 

0.48933 

0.32856 

0.67144 

0.490247 

7 

123.787 

52.7 

176.487 

37.736 

0.42573 

0.29861 

0.70139 

132.358 

130.679 

263.037 

49.202 

0.98731 

0.49681 

0.50319 

180.177 

251.227 

431.404 

33.418 

1.39433 

0.58235 

0.41765 

16.917 

2113.302 

2023.450 

18.183 

186.021 

231.124 

18.617 

75.788 

74.805 

19.667 

79.879 

29.134 

18.867 

168.691 

269.360 

19.533 

89.395 

47.341 

18.950 

146.837 

183.077 

19.450 

136.645 

131.884 

16.983 

1378.763 

1824.191 

20.233 

416.506 

471.858 

15.200 

2098.850 

2238.089 

19.517 

467.916 

641.928 

18.883 

79.793 

34.355 

18.667 

1454.403 

2145.347 

15.850 

1359.191 

1477.937 

 

 

 

0.396063 

0.396063 

0.464036 

0.475196 

0.502625 

0.508241 

0.457685 

0.421152 

0.475939 

0.503962 

0.501256 

0.506775 

9 

9 

7 

6 

5 

9 

9 

7 

8 

4 

9 

7 

0.541888 

0.465829 

0.790078 

0.441323 

12 

10 

10 

16 

 

 

 

 

 

 

Area 

Length 

A/L 

Max. D. 

Str. Cor.  Acc. Cor  Brk. Cor.  Max. Sp  Av. Sp. 

A/T 

Av. M. Sp. 

Table C - 4 Reverse Trajectory Camera Inside 

41.22564  38.6811 

1.065782  2.05757 

16 

11 

41.57257  39.02607  1.065251  5.131931  20 

34.09267  39.38154  0.865702  1.711552  11 

21.77823  40.74479  0.534504  1.181725  11 

71.36786  58.16074  1.22708 

4.193533  24 

8.556563  39.40585  0.217139  0.828077  12 

14.85317  38.83397  0.382479  1.077039  18 

20.10935  40.82914  0.492524  1.328511  16 

1
6
7

 

32.32845  40.05045  0.807193  2.185732  11 

20.47729  39.82613  0.514167  1.294146  17 

30.99754  41.1906 

0.752539  2.503987  14 

25.00731  40.46769  0.617957  2.09053 

16 

19.00355  38.51615  0.493392  1.276861  10 

29.17572  42.71937  0.682962  2.565041  33 

41.12605  41.02753  1.002401  2.369771  12 

24.15113  39.62031  0.609564  1.88548 

11 

12.57602  41.56643  0.302552  0.748812  7 

16.68347  60.90549  0.273924  0.792468  25 

15.18236  39.45102  0.384841  1.05701 

35 

24.18531  42.15122  0.573775  1.705979  53 

23 

7 

7 

25 

7 

26 

18 

21 

21 

7 

5 

21 

9 

35 

12 

13 

19 

29 

31 

77 

1.724 

1.694 

1.443 

2.630 

1.873 

2.008 

1.820 

0.989 

1.353 

1.257 

1.584 

2.140 

1.558 

2.362 

2.050 

2.008 

1.610 

1.498 

1.353 

1.838 

0.138 

0.355 

0.313 

0.413 

0.708 

0.355 

0.354 

0.195 

0.310 

0.417 

0.498 

0.508 

0.450 

0.118 

0.637 

0.362 

0.482 

0.323 

0.353 

0.136 

3899.350 

0.646 

1958.823 

0.869 

1223.812 

0.683 

3842.050 

0.992 

237.028 

1.003 

737.378 

0.672 

926.799 

0.738 

3408.318 

0.537 

2071.289 

0.672 

1334.014 

0.747 

1156.246 

0.797 

1108.326 

0.808 

721.429 

0.792 

5531.610 

0.651 

1315.706 

1.062 

1240.467 

0.747 

396.521 

0.744 

1158.052 

0.677 

792.955 

0.644 

2678.019 

0.516 

8 

11 

5 

7 

4 

7 

5 

7 

7 

3 

5 

3 

5 

3 

2 

3 

16 

4 

14 

 

 

 

 

 

 

SD. M.Sp.  Stops 

T. Mov. 

T. Stp. 

T. Run 

T. Ini. 

T.S./T.M. 

T.S./T.T. 

T.M./T.T. 

T. of D.  

Av. Lag 

S.D. Lag 

Table C - 4 Continued 

70.734 

57.51 

128.244 

112.829 

0.813 

0.298195 

0.357441 

0.263432 

0.722609 

0.291757 

0.357935 

0.359343 

0.228521 

0.307556 

0.256591 

0.347589 

0.366805 

0.317606 

0.381299 

0.339201 

0.274096 

4 

4 

4 

9 

2 

5 

7 

7 

5 

4 

3 

7 

2 

2 

3 

3 

71.802 

208.639 

280.441 

69.092 

52.48 

57.717 

110.197 

48.278 

65.344 

64.27 

129.614 

57.122 

90.582 

50.057 

140.639 

18.841 

41.755 

13.509 

55.264 

31.923 

68.588 

40.093 

108.681 

24.631 

71.447 

42.968 

114.415 

59.197 

79.064 

117.313 

196.377 

41.168 

62.039 

32.744 

94.783 

65.732 

62.797 

19.34 

82.137 

39.834 

58.315 

20.986 

79.301 

51.793 

58.228 

27.043 

85.271 

41.063 

46.186 

17.717 

63.903 

61.756 

60.88 

47.88 

108.76 

20.202 

60.981 

24.704 

85.685 

22.423 

0.550851 

13 

94.408 

266.317 

360.725 

27.272 

0.312815 

10 

107.447 

80.064 

187.511 

69.759 

0.247516 

7 

67.166 

43.844 

111.01 

21.484 

0.481703 

19 

123.672 

184.476 

308.148 

53.75 

1
6
8

 

0.744 

0.524 

0.496 

0.356 

0.244 

0.369 

0.376 

0.597 

0.448 

0.345 

0.235 

0.265 

0.317 

0.738 

0.277 

0.440 

0.288 

0.427 

0.395 

0.599 

0.256 

0.476 

0.504 

0.644 

0.756 

0.631 

0.624 

0.403 

0.552 

0.655 

0.765 

0.735 

0.683 

0.262 

0.723 

0.560 

0.712 

0.573 

0.605 

0.401 

20.317 

114.894 

46.737 

18.900 

256.399 

239.691 

19.767 

68.585 

16.754 

15.983 

2439.556 

2424.143 

16.917 

108.046 

73.433 

17.083 

532.169 

587.075 

18.317 

1028.109 

1106.917 

18.933 

70.517 

23.330 

19.867 

89.316 

70.790 

19.067 

106.918 

56.990 

19.650 

91.355 

46.625 

19.100 

154.769 

118.811 

19.583 

141.475 

149.874 

17.733 

816.994 

1194.974 

20.550 

229.298 

279.420 

15.383 

242.814 

114.725 

19.650 

579.102 

521.133 

19.017 

93.142 

39.591 

18.850 

148.279 

115.805 

15.200 

1908.960 

2214.540 

2.906 

1.100 

0.984 

0.553 

0.324 

0.585 

0.601 

1.484 

0.528 

0.308 

0.360 

0.464 

2.821 

0.384 

0.786 

0.405 

0.745 

0.653 

1.492 

 

 

 

 

 

 

Area 

Length 

A/L 

Max. D. 

Str. Cor.  Acc. Cor  Brk. Cor.  Max. Sp  Av. Sp. 

A/T 

Av. M. Sp. 

Table C - 5 Reverse Trajectory Camera Outside 

26.869 

36.699 

0.732 

19.387 

37.459 

0.518 

43.773 

55.353 

0.791 

15.106 

39.205 

0.385 

17.322 

42.692 

0.406 

6.671 

38.526 

0.173 

14.890 

39.337 

0.379 

60.103 

39.878 

1.507 

34.665 

38.009 

0.912 

25.763 

40.647 

0.634 

8.233 

38.436 

0.214 

40.041 

52.891 

0.757 

43.480 

38.644 

1.125 

15.150 

37.656 

0.402 

16.838 

39.543 

0.426 

14.704 

42.215 

0.348 

17.913 

39.101 

0.458 

67.214 

66.321 

1.013 

1
6
9

 

17.293 

37.457 

0.462 

27.974 

46.080 

0.607 

1.824 

1.018 

3.457 

1.172 

1.655 

0.562 

2.201 

2.716 

2.913 

1.762 

1.308 

1.672 

0.701 

3.044 

2.040 

2.236 

1.038 

0.967 

1.020 

4.850 

15 

11 

17 

20 

18 

22 

28 

10 

41 

16 

10 

15 

14 

28 

17 

9 

10 

20 

20 

38 

41 

9 

15 

28 

7 

22 

41 

17 

59 

21 

3 

30 

11 

25 

18 

9 

15 

25 

31 

50 

0.932 

1.584 

2.029 

1.571 

1.709 

1.584 

1.009 

1.059 

0.812 

1.325 

1.584 

2.164 

1.891 

2.050 

1.534 

1.510 

1.225 

1.454 

1.353 

1.761 

0.174 

0.254 

0.275 

0.185 

0.583 

0.416 

0.281 

0.282 

0.134 

0.305 

0.455 

0.361 

0.436 

0.275 

0.335 

0.397 

0.372 

0.311 

0.294 

0.209 

3939.067 

0.419 

1276.911 

0.744 

5145.723 

0.773 

1530.611 

0.663 

564.388 

0.855 

579.160 

0.861 

1099.984 

0.542 

4479.383 

0.598 

2692.710 

0.373 

1489.571 

0.602 

504.882 

0.801 

1190.374 

0.885 

420.811 

0.828 

4145.696 

0.723 

2152.304 

0.786 

1262.617 

0.728 

957.410 

0.641 

1154.106 

0.687 

1534.863 

0.596 

7114.516 

0.763 

8 

3 

16 

11 

11 

12 

15 

7 

7 

5 

5 

3 

5 

5 

3 

3 

3 

4 

5 

43 

 

SD. M.Sp.  Stops 

T. Mov. 

T. Stp. 

T. Run 

T. Ini. 

T.S./T.M. 

T.S./T.T. 

T.M./T.T. 

T. of D.  

Av. Lag 

S.D. Lag 

Table C - 5 Continued 

98.683 

110.346 

209.029 

27.24 

1.1182 

0.5279 

0.4721 

124.4194 

271.7045 

62.008 

84.366 

146.374 

24.674 

1.3606 

0.5764 

0.4236 

330.3040 

431.5126 

100.109 

100.493 

200.602 

66.208 

1.0038 

0.5010 

0.4990 

466.6873 

734.7643 

67.144 

143.323 

210.467 

31.028 

2.1346 

0.6810 

0.3190 

716.2281 

896.8088 

57.792 

14.987 

72.779 

79.582 

0.2593 

0.2059 

0.7941 

578.2803 

716.7904 

59.609 

32.674 

92.283 

18.182 

0.5481 

0.3541 

0.6459 

75.4875 

29.6278 

79.78 

59.69 

139.47 

48.829 

0.7482 

0.4280 

0.5720 

807.7530 

858.6846 

79.438 

60.918 

140.356 

57.837 

0.7669 

0.4340 

0.5660 

0.2118 

11 

121.407 

160.199 

281.606 

72.425 

1.3195 

0.5689 

0.4311 

70.3410 

36.0162 

66.5191 

29.4766 

1
7
0

 

83.52 

48.742 

132.262 

78.394 

0.5836 

0.3685 

0.6315 

179.5048 

180.4405 

58.118 

23.66 

81.778 

39.811 

0.4071 

0.2893 

0.7107 

94.0154 

48.8507 

59.209 

68.294 

127.503 

69.4 

1.1534 

0.5356 

0.4644 

401.6120 

607.4483 

56.106 

31.503 

87.609 

32.088 

0.5615 

0.3596 

0.6404 

145.8415 

150.4573 

0.3894 

11 

90.018 

101.882 

191.9 

64.242 

1.1318 

0.5309 

0.4691 

1316.1312  1696.3897 

58.745 

55.945 

114.69 

54.179 

0.9523 

0.4878 

0.5122 

513.4148 

591.0102 

56.509 

37.784 

94.293 

28.843 

0.6686 

0.4007 

0.5993 

764.3874 

833.8427 

64.219 

41.426 

105.645 

21.735 

0.6451 

0.3921 

0.6079 

249.8973 

333.0546 

76.46 

58.407 

134.867 

61.018 

0.7639 

0.4331 

0.5669 

350.5963 

611.3708 

73.975 

59.218 

133.193 

46.234 

0.8005 

0.4446 

0.5554 

350.1714 

399.2239 

131.706 

184.059 

315.765 

78.638 

1.3975 

0.5829 

0.4171 

2380.7132  2826.0838 

19.65 

17.98 

19.15 

15.48 

16.72 

16.85 

18.12 

18.55 

19.55 

18.78 

19.48 

18.88 

19.38 

16.88 

20.17 

14.23 

19.45 

18.80 

18.58 

15.70 

8 

3 

6 

7 

2 

4 

9 

4 

8 

3 

9 

3 

4 

4 

6 

7 

10 

11 

0.2055 

0.3155 

0.4363 

0.2997 

0.3219 

0.3943 

0.2317 

0.2424 

0.3271 

0.3358 

0.4211 

0.3677 

0.3361 

0.2478 

0.2185 

0.3696 

0.2937 

0.4785 

 

 

 

 

 

 

 

 

 

 

 

Area 

Length 

A/L 

Max. D. 

Str. Cor.  Acc. Cor  Brk. Cor.  Max. Sp  Av. Sp. 

A/T 

Av. M. Sp. 

10.562 

34.955 

0.302 

10 

Table C - 6 Straight Trajectory Camera Inside 

13 

11 

14.981 

35.104 

0.427 

12 

17.452 

33.183 

0.526 

2.604 

7.674 

5.829 

35.964 

0.072 

35.096 

0.219 

34.292 

0.170 

16.643 

34.504 

0.482 

7.416 

34.750 

0.213 

14.565 

35.945 

0.405 

23.525 

36.543 

0.644 

13.064 

35.761 

0.365 

5.078 

34.349 

0.148 

10.801 

35.179 

0.307 

7.916 

5.603 

36.908 

0.214 

35.546 

0.158 

25.390 

34.530 

0.735 

10.122 

35.487 

0.285 

22.471 

37.141 

0.605 

12.841 

35.155 

0.365 

6.471 

34.004 

0.190 

5 

2 

6 

9 

8 

9 

4 

4 

5 

9 

6 

5 

6 

3 

8 

0.479 

0.893 

0.212 

0.781 

0.464 

0.928 

0.301 

0.937 

0.846 

1.271 

0.582 

0.561 

0.523 

0.643 

0.355 

1.023 

0.483 

0.938 

0.860 

0.506 

1
7
1

 

3 

1 

3 

9 

1 

3 

9 

9 

1 

1 

3 

3 

9 

1 

7 

3 

1 

7 

21 

6 

11 

2.117 

2.008 

1.584 

1.755 

2.189 

2.563 

2.239 

1.487 

1.498 

1.724 

1.838 

2.668 

1.771 

2.375 

3.142 

1.771 

2.951 

1.929 

1.820 

1.787 

1.363 

1.318 

1.039 

1.357 

1.563 

0.761 

1.459 

0.512 

0.726 

1.185 

1.409 

1.466 

1.372 

1.038 

1.403 

1.294 

1.299 

1.349 

1.151 

0.852 

165.451 

1.544 

250.908 

1.474 

46.879 

1.164 

150.164 

1.431 

100.197 

1.629 

387.773 

1.279 

94.232 

1.549 

480.167 

0.885 

453.963 

0.880 

394.522 

1.291 

171.467 

1.505 

91.387 

1.578 

162.760 

1.419 

153.994 

1.232 

75.206 

1.476 

364.067 

1.459 

137.113 

1.426 

300.278 

1.476 

259.959 

1.209 

138.917 

0.955 

0 

2 

1 

1 

1 

1 

1 

7 

2 

1 

2 

1 

2 

2 

2 

1 

2 

1 

2 

4 

 

1
7
2

 

0.284 

0.292 

0.305 

0.255 

0.255 

0.417 

0.289 

0.348 

0.287 

0.293 

0.251 

0.290 

0.232 

0.356 

0.260 

1.264 

0.301 

0.275 

0.247 

0.310 

 

 

 

 

 

SD. M.Sp. 

Stops 

T. Mov. 

T. Stp. 

T. Run 

T. Ini. 

T.S./T.M.  T.S./T.T. 

T.M./T.T.  T. of D.  

Av. Lag 

S.D. Lag 

Table C - 6 Continued 

2 

1 

1 

1 

1 

2 

1 

3 

2 

1 

1 

1 

1 

1 

1 

1 

1 

1 

1 

1 

23.6 

25.1 

34.7 

25.0 

21.9 

30.4 

23.8 

53.4 

46.0 

30.7 

25.3 

23.4 

25.7 

35.5 

25.3 

26.6 

27.3 

27.4 

30.5 

40.0 

2.0 

0.0 

0.0 

0.0 

0.0 

14.9 

0.0 

16.6 

2.4 

0.0 

0.0 

0.0 

0.0 

0.0 

0.0 

0.0 

0.0 

0.0 

0.0 

0.0 

25.6 

25.1 

34.7 

25.0 

21.9 

45.3 

23.8 

69.9 

48.3 

30.7 

25.3 

23.4 

25.7 

35.5 

25.3 

26.6 

27.3 

27.4 

30.5 

40.0 

107.4 

115.0 

36.8 

69.8 

31.6 

74.7 

20.2 

66.9 

72.0 

77.4 

40.9 

76.8 

26.8 

42.3 

34.0 

29.2 

22.8 

75.9 

55.1 

44.4 

0.1 

0.0 

0.0 

0.0 

0.0 

0.3 

0.0 

0.2 

0.0 

0.0 

0.0 

0.0 

0.0 

0.0 

0.0 

0.0 

0.0 

0.0 

0.0 

0.0 

0.9 

1.0 

1.0 

1.0 

1.0 

0.7 

1.0 

0.8 

1.0 

1.0 

1.0 

1.0 

1.0 

1.0 

1.0 

1.0 

1.0 

1.0 

1.0 

1.0 

20.0 

18.9 

19.7 

15.5 

16.9 

17.2 

18.3 

18.8 

19.8 

19.0 

19.6 

19.1 

19.6 

17.7 

20.5 

15.3 

19.6 

19.0 

18.8 

15.2 

291.1 

276.8 

121.7 

115.2 

60.5 

57.3 

73.2 

91.1 

52.2 

73.7 

108.7 

98.7 

88.8 

62.8 

48.3 

39.2 

16.7 

13.3 

51.5 

63.2 

33.7 

46.3 

130.9 

103.0 

76.8 

24.3 

150.1 

149.3 

68.7 

17.3 

632.2 

566.9 

90.3 

86.6 

54.6 

64.3 

125.9 

114.5 

85.1 

63.1 

0.1 

0.0 

0.0 

0.0 

0.0 

0.5 

0.0 

0.3 

0.1 

0.0 

0.0 

0.0 

0.0 

0.0 

0.0 

0.0 

0.0 

0.0 

0.0 

0.0 

 

 

 

 

 

 

Area 

Length 

A/L 

Max. D. 

Str. Cor.  Acc. Cor  Brk. Cor.  Max. Sp  Av. Sp. 

A/T 

Av. M. Sp. 

Table C - 7 Straight Trajectory Camera Outside 

17 

1.5836 

0.6079 

88.6422 

1.0850 

1
7
3

 

78.450 

44.800 

1.751 

4.974 

3.011 

33.940 

0.147 

35.399 

0.085 

14.493 

35.096 

0.413 

7.498 

9.529 

34.911 

0.215 

35.921 

0.265 

14.299 

39.073 

0.366 

24.805 

34.457 

0.720 

19.422 

33.215 

0.585 

7.233 

9.265 

3.098 

6.600 

35.759 

0.202 

34.040 

0.272 

33.076 

0.094 

33.773 

0.195 

26.710 

34.565 

0.773 

13.704 

35.134 

0.390 

11.664 

34.494 

0.338 

6.071 

6.605 

6.993 

34.751 

0.175 

36.761 

0.180 

34.050 

0.205 

36.699 

37.150 

0.988 

7.391 

0.705 

0.339 

0.603 

0.697 

0.698 

2.589 

1.090 

0.867 

0.806 

0.980 

0.254 

0.345 

1.184 

0.496 

0.570 

0.289 

0.514 

0.364 

2.043 

11 

9 

4 

3 

6 

6 

9 

6 

1 

5 

8 

8 

5 

5 

5 

11 

10 

10 

16 

11 

7 

1 

9 

1 

3 

8 

9 

2 

1 

8 

3 

3 

1 

1 

3 

15 

7 

13 

1.5337 

0.5997 

935.7476 

0.9956 

11 

1.7086 

1.3667 

102.9803 

1.4420 

1.8375 

0.7124 

2827.9729 

1.2586 

1.8204 

1.3206 

128.6993 

1.4172 

1.7548 

1.3572 

204.5286 

1.4305 

2.4047 

1.6190 

119.5781 

1.7079 

2.0080 

1.5734 

157.1150 

1.6539 

2.8229 

1.3131 

372.7158 

1.4875 

1.7548 

1.0853 

369.3549 

1.2622 

2.3284 

1.2376 

143.0942 

1.4379 

1.9096 

0.8195 

164.2946 

1.4831 

2.4656 

1.4437 

56.3346 

1.7031 

1.6368 

1.0196 

475.0846 

1.1200 

2.9966 

0.8948 

274.0523 

1.5348 

2.2134 

1.4321 

161.3960 

1.4947 

2.0080 

1.3144 

91.9362 

1.3944 

2.0721 

1.3696 

109.9626 

1.4747 

1.7086 

0.7718 

175.2564 

0.8527 

2.1404 

1.3237 

613.2183 

1.4377 

3 

1 

3 

1 

2 

1 

3 

3 

1 

1 

1 

3 

2 

2 

1 

2 

2 

1 

1 

3 

 

1
7
4

 

0.4426 

0.2568 

0.2725 

0.2549 

0.2650 

0.2305 

0.3921 

0.3454 

0.3232 

0.4604 

0.2997 

0.2904 

0.2397 

0.2823 

0.3441 

0.2454 

0.2633 

0.3054 

0.2376 

0.2889 

 

 

 

SD. M.Sp. 

Stops 

T. Mov. 

T. Stp. 

T. Run 

T. Ini. 

T.S./T.M.  T.S./T.T. 

T.M./T.T.  T. of D.  

Av. Lag 

S.D. Lag 

Table C - 7 Continued 

2 

1 

2 

1 

1 

1 

1 

2 

2 

1 

2 

2 

1 

1 

2 

1 

1 

1 

1 

1 

47.2 

25.7 

36.3 

25.0 

21.5 

22.8 

29.7 

40.9 

28.3 

28.8 

24.2 

20.5 

24.7 

33.8 

24.3 

24.2 

26.4 

26.7 

43.9 

28.0 

15.4 

0.0 

21.7 

0.0 

0.0 

0.0 

0.0 

16.3 

2.2 

0.0 

17.4 

2.4 

0.0 

0.0 

14.9 

0.0 

0.0 

0.0 

0.0 

0.0 

62.6 

25.7 

58.0 

25.0 

21.5 

22.8 

29.7 

57.2 

30.5 

28.8 

41.6 

22.9 

24.7 

33.8 

39.2 

24.2 

26.4 

26.7 

43.9 

28.0 

120.6 

49.6 

28.8 

41.6 

31.6 

70.6 

22.0 

43.0 

67.4 

55.0 

17.4 

75.7 

38.0 

52.7 

22.9 

19.5 

21.5 

45.9 

35.9 

30.9 

0.2 

0.0 

0.4 

0.0 

0.0 

0.0 

0.0 

0.3 

0.1 

0.0 

0.4 

0.1 

0.0 

0.0 

0.4 

0.0 

0.0 

0.0 

0.0 

0.0 

0.8 

1.0 

0.6 

1.0 

1.0 

1.0 

1.0 

0.7 

0.9 

1.0 

0.6 

0.9 

1.0 

1.0 

0.6 

1.0 

1.0 

1.0 

1.0 

1.0 

20.0 

18.9 

19.7 

15.5 

16.9 

17.2 

18.3 

18.8 

19.8 

19.0 

19.6 

19.1 

19.6 

17.7 

20.5 

15.3 

19.6 

19.0 

18.8 

15.2 

135.6 

159.2 

72.4 

65.4 

57.3 

44.3 

18.7 

13.3 

168.0 

157.8 

80.9 

15.8 

147.7 

141.5 

64.8 

77.8 

166.5 

158.2 

85.0 

67.0 

71.3 

122.9 

75.0 

82.9 

142.0 

48.3 

77.8 

153.7 

225.8 

125.5 

19.1 

23.3 

22.9 

40.9 

41.3 

53.3 

184.3 

238.5 

215.9 

213.2 

0.3 

0.0 

0.6 

0.0 

0.0 

0.0 

0.0 

0.4 

0.1 

0.0 

0.7 

0.1 

0.0 

0.0 

0.6 

0.0 

0.0 

0.0 

0.0 

0.0 

 

 

 

 

APPENDIX D

  

RESULTS – STATISTICAL ANALYSIS 

This Appendix details the calculated values of the statistical analysis completed 

for each task. Each row in the main table represents a different statistical test and the 

columns represent the performance metric value to the corresponding test. The first row 

corresponds to the Kolmogorov-Smirnov Goodness of Fit. The second row, is the output 

of the F-test if the first row accepts the test or a Levene test if the first row rejects the 

hypothesis. Lastly, the third row is a two-sample T-test, if the KS-test accepts the 

hypothesis, or a Kruskal-Wallis test if the first rejects the hypothesis. 

For each run, all p-values are detailed and the rejection or non-rejections are 

shown. An H-value of 1 indicates that the test rejects the null hypothesis. 

Table D-1 correlates the column identification label with the actual performance 

metric. 

The two main hypothesis tests are shown in this appendix. The main hypothesis 

“A vehicle can be controlled over a 4G LTE network streaming HD video Feedback” and 

the secondary hypothesis “the camera positions have a significant effect on performance 

when teleoperating a vehicle”.   

Table D - 1 Correlation between Column and Performance metric 

Column 

Performance Metric 

Area 

Area 

Length 

Length of Run 

175 

 

 

 

 

 

Table D – 1 Continued 

Column 

Performance Metric 

A/L 

Ratio of Area over Length 

Max. D. 

Maximum Distance Deviation 

Str. Cor. 

Steering Correction 

Acc. Cor. 

Acceleration Correction 

Brk. Cor. 

Brake Correction 

Max. Sp. 

Maximum Speed 

Av. Sp. 

Average Speed 

A/T 

Area in Function of Time 

Av. M. Sp.  Average Moving speed 

SD. M. Sp.  Standard Deviation of Moving Speed 

Stops 

Stops 

T. Mov. 

Time Moving 

T. Stp. 

T. Run 

T. Ini. 

Time Stopped 

Time of Run 

Time to Initialize 

T.S/T.M. 

Ratio of Time Stopped over Moving Time 

T.S./T.T. 

Ratio of Time of Stopped over Total Time 

T.M./T.T. 

Ratio of Time Moving over Total Time 

176 

 

1 

1 

1 

 

1 

0 

1 

 

 

 

Table D - 2 Main Hypothesis Statistical Tests for Straight Trajectory 

Straight Trajectory Statistical test H 

Area 

Length 

A/L 

Max. D. 

Str.Cor. 

Acc. Cor. 

Brk. Cor. 

Max. Sp. 

Av. Sp. 

A/T 

Straight Trajectory Statistical test H 

0 

1 

1 

 

1 

0 

1 

0 

1 

1 

 

1 

1 

0 

1 

1 

1 

 

0 

1 

1 

0 

0 

0 

 

1 

1 

0 

1 

1 

0 

 

1 

1 

1 

1 

0 

1 

 

0 

1 

1 

0 

0 

1 

 

1 

1 

0 

1 

1 

1 

 

1 

1 

0 

Av. M. Sp.  SD. M. Sp. 

Stops 

T. Mov. 

T. Stp 

T. Run 

T. Ini. 

T.S./T.M. 

T.S/T.T. 

T.M/T.T. 

1 

1 

1 

 

1 

1 

0 

 

1
7
7

 

Straight Trajectory Statistical test P 

Area 

Length 

A/L 

Max. D. 

Str.Cor. 

Acc. Cor. 

Brk. Cor. 

Max. Sp. 

Av. Sp. 

A/T 

4.40E-02 

5.97E-02 

9.95E-02 

5.65E-04 

1.48E-01 

6.46E-03 

1.52E-02 

2.19E-01 

2.81E-02 

2.11E-03 

2.02E-03 

3.89E-04 

3.55E-03 

2.95E-04 

3.22E-01 

9.69E-04 

6.13E-01 

1.68E-01 

1.71E-02 

6.39E-06 

1.68E-03 

1.44E-02 

5.32E-06 

1.01E-03 

9.36E-01 

5.57E-01 

2.51E-03 

1.63E-07 

3.04E-04 

3.50E-04 

 

 

 

 

 

 

 

 

 

Straight Trajectory Statistical test P 

Av. M. Sp.  SD. M. Sp. 

Stops 

T. Mov. 

T. Stp 

T. Run 

T. Ini. 

T.S./T.M. 

T.S/T.T. 

T.M/T.T. 

3.57E-02 

1.84E-03 

1.38E-07 

9.23E-02 

1.11E-06 

1.54E-02 

3.77E-01  1.44E-06 

6.80E-07 

6.80E-07 

5.03E-02 

7.53E-01 

8.83E-04 

2.26E-05 

1.79E-02 

1.26E-02 

0.00E+00 

2.76E-02 

1.62E-02 

1.62E-02 

3.04E-04 

6.01E-04 

1.84E-01 

2.43E-16 

1.88E-01 

3.04E-04 

1.14E-14 

1.88E-01 

1.88E-01 

1.88E-01 

 

 

 

 

 

 

 

 

 

 

 

 

0 

1 

1 

0 

0 

1 

 

 

Table D - 3 Main Hypothesis Statistical Test for Reverse Trajectory 

Reverse Trajectory Statistical test H 

Area 

Length 

A/L 

Max. D. 

Str.Cor. 

Acc. Cor. 

Brk. Cor. 

Max. Sp. 

Av. Sp. 

A/T 

Reverse Trajectory Statistical test H 

1 

0 

1 

0 

0 

0 

0 

1 

1 

0 

1 

1 

0 

1 

1 

0 

1 

1 

0 

1 

1 

1 

1 

1 

0 

1 

1 

0 

1 

1 

1 

0 

0 

0 

1 

1 

0 

1 

0 

0 

1 

1 

0 

1 

1 

0 

1 

1 

1 

1 

1 

0 

1 

1 

Av. M. Sp.  SD. M. Sp. 

Stops 

T. Mov. 

T. Stp 

T. Run 

T. Ini. 

T.S./T.M. 

T.S/T.T. 

T.M/T.T. 

1
7
8

 

Reverse Trajectory Statistical test P 

Area 

Length 

A/L 

Max. D. 

Str.Cor. 

Acc. Cor. 

Brk. Cor. 

Max. Sp. 

Av. Sp. 

A/T 

3.86E-01 

3.74E-04 

5.74E-01 

4.81E-01 

6.90E-02 

4.30E-01 

2.04E-02 

8.76E-01 

8.08E-01 

8.19E-03 

2.52E-03 

7.63E-02 

4.14E-03 

1.30E-03 

4.31E-03 

3.00E-04 

1.52E-01 

4.56E-03 

2.82E-02 

9.91E-03 

7.88E-06 

1.15E-02 

9.01E-07 

1.20E-07 

2.94E-02 

6.30E-04 

9.85E-01 

9.21E-01 

2.59E-14 

7.83E-04 

Reverse Trajectory Statistical test P 

Av. M. Sp.  SD. M. Sp. 

Stops 

T. Mov. 

T. Stp 

T. Run 

T. Ini. 

T.S./T.M. 

T.S/T.T. 

T.M/T.T. 

8.98E-01 

3.06E-01 

1.24E-01 

2.24E-01 

2.42E-02 

6.80E-02 

5.35E-01 

9.02E-02 

7.97E-01 

7.97E-01 

1.27E-01 

1.29E-01 

0.00E+00 

6.67E-04 

1.89E-02 

6.70E-06 

0.00E+00 

2.12E-04 

1.46E-02 

1.46E-02 

1.01E-06 

1.58E-01 

6.22E-09 

9.80E-13 

3.04E-04 

7.54E-11 

7.80E-17 

2.75E-08 

8.21E-10 

8.21E-10 

 

 

0 

1 

1 

0 

1 

1 

 

 

Table D - 4 Main Hypothesis Statistical Tests for Path Following 

Path Following Statistical test H 

Area 

Length 

A/L 

Max. D. 

Str.Cor. 

Acc. Cor. 

Brk. Cor. 

Max. Sp. 

Av. Sp. 

A/T 

Path Following Statistical test H 

0 

1 

0 

1 

0 

1 

0 

1 

1 

0 

1 

1 

1 

0 

1 

0 

1 

1 

0 

0 

1 

0 

1 

1 

0 

1 

1 

0 

1 

1 

0 

1 

1 

1 

0 

1 

0 

1 

1 

0 

1 

1 

0 

0 

1 

0 

1 

1 

0 

1 

1 

0 

1 

1 

Av. M. Sp.  SD. M. Sp. 

Stops 

T. Mov. 

T. Stp 

T. Run 

T. Ini. 

T.S./T.M. 

T.S/T.T. 

T.M/T.T. 

1
7
9

 

Path Following Statistical test P 

Area 

Length 

A/L 

Max. D. 

Str.Cor. 

Acc. Cor. 

Brk. Cor. 

Max. Sp. 

Av. Sp. 

A/T 

1.07E-01 

3.82E-01 

2.17E-01 

1.77E-02 

8.28E-01 

8.98E-01 

1.48E-01 

9.87E-01 

8.05E-01 

4.33E-01 

5.53E-03 

5.13E-06 

1.22E-02 

2.64E-01 

5.78E-02 

4.16E-03 

1.08E-03 

9.58E-03 

8.02E-02 

1.34E-04 

4.18E-10 

6.42E-01 

1.81E-10 

1.01E-03 

8.57E-03 

3.88E-06 

2.28E-04 

2.96E-12 

9.67E-11 

5.01E-11 

Path Following Statistical test P 

Av. M. Sp.  SD. M. Sp. 

Stops 

T. Mov. 

T. Stp 

T. Run 

T. Ini. 

T.S./T.M. 

T.S/T.T. 

T.M/T.T. 

7.11E-01 

2.79E-02 

6.87E-01 

4.98E-01 

1.39E-01 

8.87E-02 

3.92E-02 

1.40E-01 

7.64E-01 

7.64E-01 

2.29E-03 

4.84E-01 

0.00E+00 

8.75E-06 

1.35E-05 

1.23E-05 

1.03E-01 

4.67E-04 

1.90E-02 

1.90E-02 

4.65E-18 

1.15E-03 

1.48E-12 

1.51E-14 

1.25E-09 

9.40E-12 

3.01E-04 

2.25E-10 

5.58E-10 

5.58E-10 

 

 

1 

0 

0 

1 

0 

0 

 

 

Table D - 5 Camera Comparison, Statistical Tests for Straight Trajectory 

Straight Trajectory Camera Comparison Statistical test H 

Area 

Length 

A/L 

Max. D. 

Str.Cor. 

Acc. Cor. 

Brk. Cor. 

Max. Sp. 

Av. Sp. 

A/T 

Av. M. Sp. 

SD. M. Sp.  Stops 

T. Mov. 

T. Stp 

T. Run 

T. Ini. 

T.S./T.M. 

T.S/T.T. 

T.M/T.T. 

Straight Trajectory Camera Comparison Statistical test H 

0 

1 

0 

1 

0 

0 

0 

1 

0 

1 

0 

0 

1 

1 

0 

0 

0 

0 

0 

0 

0 

1 

1 

0 

1
8
0

 

Straight Trajectory Camera Comparison Statistical test P 

1 

0 

0 

0 

0 

0 

0 

0 

0 

1 

1 

0 

1 

0 

0 

1 

1 

0 

1 

0 

0 

1 

1 

0 

Area 

Length 

A/L 

Max. D. 

Str.Cor. 

Acc. Cor. 

Brk. Cor. 

Max. Sp. 

Av. Sp. 

A/T 

4.40E-02 

5.97E-02 

9.95E-02 

5.65E-04 

1.48E-01 

6.46E-03 

1.52E-02 

2.19E-01 

2.81E-02 

2.11E-03 

7.41E-02 

9.06E-05 

1.39E-03 

3.96E-02 

3.86E-01 

1.74E-01 

6.21E-01 

5.12E-01 

3.56E-01 

6.43E-02 

8.92E-01 

6.36E-01 

4.42E-01 

6.65E-01 

9.36E-01 

5.43E-01 

4.26E-01 

8.56E-01 

7.35E-01 

7.87E-01 

Straight Trajectory Camera Comparison Statistical test P 

Av. M. Sp. 

SD. M. Sp.  Stops 

T. Mov. 

T. Stp 

T. Run 

T. Ini. 

T.S./T.M. 

T.S/T.T. 

T.M/T.T. 

3.57E-02 

1.84E-03 

1.38E-07 

9.23E-02 

1.11E-06 

1.54E-02 

3.77E-01 

1.44E-06 

6.80E-07 

6.80E-07 

7.75E-01 

2.47E-01 

5.37E-01 

6.94E-01 

8.48E-03 

4.56E-01 

6.76E-01 

3.75E-03 

6.49E-03 

6.49E-03 

6.95E-01 

7.97E-01 

3.56E-01 

7.09E-01 

2.29E-01 

8.18E-01 

1.74E-01 

2.03E-01 

2.03E-01 

2.03E-01 

1 

0 

0 

1 

0 

0 

 

 

0 

0 

0 

0 

0 

0 

 

 

Table D - 6 Camera Comparison, Statistical Tests for Reverse Trajectory 

Reverse Trajectory Camera Comparison Statistical test H 

Area 

Length 

A/L 

Max. D. 

Str.Cor. 

Acc. Cor. 

Brk. Cor. 

Max. Sp. 

Av. Sp. 

A/T 

Av. M. Sp. 

SD. M. Sp.  Stops 

T. Mov. 

T. Stp 

T. Run 

T. Ini. 

T.S./T.M. 

T.S/T.T. 

T.M/T.T. 

Reverse Trajectory Camera Comparison Statistical test H 

1 

0 

0 

0 

0 

0 

0 

0 

0 

0 

0 

0 

0 

0 

0 

0 

0 

0 

0 

0 

0 

1 

0 

0 

1
8
1

 

Reverse Trajectory Camera Comparison Statistical test P 

1 

0 

0 

0 

0 

0 

0 

0 

0 

0 

1 

0 

0 

0 

0 

0 

0 

0 

1 

0 

0 

0 

0 

0 

Area 

Length 

A/L 

Max. D. 

Str.Cor. 

Acc. Cor. 

Brk. Cor. 

Max. Sp. 

Av. Sp. 

A/T 

3.86E-01 

3.74E-04 

5.74E-01 

4.81E-01 

6.90E-02 

4.30E-01 

2.04E-02 

8.76E-01 

8.08E-01 

8.19E-03 

4.91E-01 

3.18E-01 

5.37E-01 

8.59E-01 

3.59E-01 

7.43E-01 

1.19E-01 

8.44E-01 

1.18E-01 

2.36E-01 

9.11E-01 

1.68E-01 

7.55E-01 

9.80E-01 

9.13E-01 

5.16E-01 

6.22E-01 

6.31E-02 

2.04E-01 

5.16E-01 

Reverse Trajectory Camera Comparison Statistical test P 

Av. M. Sp. 

SD. M. Sp.  Stops 

T. Mov. 

T. Stp 

T. Run 

T. Ini. 

T.S./T.M. 

T.S/T.T. 

T.M/T.T. 

8.98E-01 

3.06E-01 

1.24E-01 

2.24E-01 

2.42E-02 

6.80E-02 

5.35E-01 

9.02E-02 

7.97E-01 

7.97E-01 

9.14E-01 

1.07E-01 

1.50E-01 

6.86E-01 

2.74E-01 

9.48E-01 

6.46E-01 

1.96E-02 

1.99E-01 

1.99E-01 

2.18E-01 

3.32E-01 

6.70E-01 

3.71E-01 

2.67E-01 

3.55E-01 

6.57E-01 

9.94E-01 

4.68E-01 

4.68E-01 

0 

0 

0 

0 

0 

0 

 

 

0 

0 

0 

0 

0 

0 

 

Table D - 7 Camera Comparison, Statistical Tests for Path Following 

Path Following Camera Comparison Statistical test H 

Area 

Length 

A/L 

Max. D. 

Str.Cor. 

Acc. Cor. 

Brk. Cor. 

Max. Sp. 

Av. Sp. 

A/T 

Av. M. Sp. 

SD. M. Sp.  Stops 

T. Mov. 

T. Stp 

T. Run 

T. Ini. 

T.S./T.M. 

T.S/T.T. 

T.M/T.T. 

Path Following Camera Comparison Statistical test H 

0 

0 

0 

1 

0 

0 

0 

0 

0 

0 

0 

0 

1 

0 

0 

0 

0 

0 

0 

0 

0 

0 

0 

0 

1
8
2

 

Path Following Camera Comparison Statistical test P 

0 

0 

0 

1 

1 

0 

0 

0 

0 

0 

0 

0 

0 

0 

0 

0 

0 

0 

0 

1 

0 

0 

0 

0 

Area 

Length 

A/L 

Max. D. 

Str.Cor. 

Acc. Cor. 

Brk. Cor. 

Max. Sp. 

Av. Sp. 

A/T 

1.07E-01 

3.82E-01 

2.17E-01 

1.77E-02 

8.28E-01 

8.98E-01 

1.48E-01 

9.87E-01 

8.05E-01 

4.33E-01 

5.03E-02 

1.00E-01 

2.55E-01 

1.99E-01 

5.04E-01 

8.76E-01 

3.39E-01 

3.93E-01 

4.76E-01 

5.92E-03 

9.39E-01 

8.45E-01 

9.03E-01 

3.58E-01 

4.20E-01 

2.84E-01 

4.59E-01 

3.56E-01 

9.74E-02 

7.68E-02 

Path Following Camera Comparison Statistical test P 

Av. M. Sp. 

SD. M. Sp.  Stops 

T. Mov. 

T. Stp 

T. Run 

T. Ini. 

T.S./T.M. 

T.S/T.T. 

T.M/T.T. 

7.11E-01 

2.79E-02 

6.87E-01 

4.98E-01 

1.39E-01 

8.87E-02 

3.92E-02 

1.40E-01 

7.64E-01 

7.64E-01 

7.30E-01 

2.58E-01 

3.40E-01 

2.72E-01 

3.35E-01 

6.61E-01 

2.45E-02 

5.58E-01 

8.05E-01 

8.05E-01 

4.33E-01 

5.16E-01 

2.49E-01 

6.02E-01 

1.77E-01 

2.34E-01 

6.07E-01 

1.51E-01 

1.14E-01 

1.14E-01 

0 

0 

0 

0 

0 

0 

 

 

 

REFERENCES 

Alshazly, H. A., & Hassaballah, M. (2013). An Embedded System for a Bluetooth Controlled 

Mobile Robot Based on the ATmega8535 Microcontroller. Egyptian Computer Science 
Journal, 61-72. 

Araque, C., & Guerrero, F. (2010). Wireless Robot Teleoperation via Internet Using IPv6 over a 

Bluetooth Personal Area Network. Revista Facultad Ingenieria Universidad Antioquia, 
172-184. 

Baker, C. (2005). Cave Crawlwe. Retrieved from The Robotics Institute Carnegie Mellon: 

https://www.cs.cmu.edu/~groundhog/robots_cc.html 

Cohen, J. (1992). A Power Primer. Quantitative Methods in Psychology, 155-159. 

Cui, J., Tosunoglu, S., Roberts, R., Moore, C., & Repperger, D. W. (2003). A Review of 

Teleoperation System Control. Florida Conference on Recent Advances in Robotics. 
Boca Raton: FCRAR. 

Dutton, S. (2013, November 4). WebRTC in the real world: STUN, TURN and signaling. 

Retrieved from html5rocks: http://www.html5rocks.com/en/tutorials/webrtc/infrastructure/ 

Endsley, M. R., & Garland, D. J. (2000). Direct Measurement of Situation Awarness: Validity 

and Use of Sagat. Mahwah. 

Ericsson. (2015, November 4). Industrial Remote Operation: 5G Rises to the Chalenge. 

Retrieved from 
https://www.ericsson.com/res/thecompany/docs/publications/ericsson_review/2015/etr-
5g-remote-control.pdf 

Georgira DDS. (2015, May 5). Tests and Exams. Retrieved from Georgia Department of Driver 

Services: http://www.dds.ga.gov/drivers/dldata.aspx?con=1744407270&ty=dl 

Gnatzig, S., Chucholowski, F., Tang, T., & Lienkamp, M. (2013). A System Design for 

Teleoperated Road Vehicles. 10th International Conference on Informatics in Control, 
Automation and Robotics (pp. 231-238). Munchen: Science and Technology 
Publications. 

Halme, A., Suomela, J., & Savela, M. (1999). Applying Telepresence and Augmented Reality to 

Teleoperate Field Robots. Robotics and Autonomous Systems, 117-125. 

Harding, J., Powell, G. R., Yoon, R., Fikentscher, J., Doyle, C., Sade, D., . . . Wang, J. (2014). 

Vehicle to Vehicle Communications: Readiness of V2V Technology for Applications. 
Washington, DC: National Highway Traffic Safety Administration. 

183 

 

 

Hokayem, P. F., & Spong, M. W. (2006). Bilateral Teleoperation: A Historical Survey. 

Automatica, 2035-2057. 

IEEE. (2009). IEEE Std 802.11n-2009. New York: IEEE. 

International Organization for Standardization. (1996). ISO/IEC 7498-1 - Information Technology 

- Open Systems Interconnection - Basic Reference Model: The Basic Model. Geneva: 
ISO. 

Jazar, R. N. (2014). Vehicle Dynamics. New York: Springer. 

Korte, C., Nair, S. S., Nistor, V., Low, T. P., Doarn, C. R., & Schaffner, G. (2013). Determining 

the Threshold of Time-Delay for Teleoperation Accuracy and Efficieny in Relation to 
Telesurgery. Telemedicine and e-Health, 1078/1086. 

Liciardopol, S. (2007). A Survey on Teleoperation. Eindhoven: DCT. 

Lombard, M., Ditton, T. B., & Weinstein, L. (2009). Measuring Presence: The Temple Presence 

Inventory. Proceedings of the 12th International Workshop on Presence. Los angeles, 
San francisco. 

Marin, R., Sanz, P. J., & Sanches, J. S. (2002). A Very High Level Interface to Teleoperate a 
Robot Via Web Including Augmented Reality. International Conference on Robotics & 
Automation (pp. 2725-2730). Washinton DC.: IEEE. 

Meier, A. (2005). 5.9GHz Dedicated Short Range Communication - Design of the Vehicular 

Safety Communications Architecture. Zurich: Daimler Chrysler. 

Microchip Techonology Inc. (2016, June). TCP vs. UDP. Retrieved from 

http://microchip.wikidot.com/tcpip:tcp-vs-udp 

Mills, D. L. (2014, February 21). ntp.org: home of the network time protocol. Retrieved from 

www.ntp.org 

Morris, A. (2005, March). Groundhog. Retrieved from The Robots Institute Carnegie Mellon: 

https://www.cs.cmu.edu/~groundhog/robots_ghog.html 

Munoz, N. D., Eusse, J. F., & Cruz, E. J. (2007). Robot Teleoperation System Based on GPRS. 
Fourth Congress of electronics, Robotics and Automotive Mechanics (pp. 74-79). IEEE 
Computer Society. 

Northrup, T. (2016, June). Firewalls. Retrieved from TechNet: https://technet.microsoft.com/en-

us/library/cc700820.aspx 

Preusche, C., & Hirzinger, G. (2007). Haptics in Telerobotics. The Visual Computer, 273-284. 

Rysavy Research. (2013, August). 4G Americas - Mobile Broadband Explosion. Retrieved from 

4G Americas: 

184 

 

 

 

http://www.4gamericas.org/files/7214/0759/2052/4G_Americas_Mobile_Broadband_Expl
osion_August_2013_9_5_13_R1.pdf 

Saakes, D., Choudhary, V., Sakamoto, D., Inami, M., & Igarashi, T. (2013). A Teleoperating 

Interface for Ground Vehicles using Autonomos Flying Cameras. 2013 23rd International 
Conference on Artificial Reality and Telexistence (ICAT) (pp. 13-19). Tokyo: IEEE. 

Sharma, N. (2014, January 2). Kinematics of a robot car (Bicycle Model). Retrieved from 

https://nabinsharma.wordpress.com/2014/01/02/kinematics-of-a-robot-bicycle-model/ 

Shen, X., Jie Chong, Z., Pendleton, S., Ming, G., Fu, J., Qin, B., . . . Ang, M. H. (2016). 

Teleoperation of On-Road Vehilces via Immersive Telepresence Using Off-the-shelf 
Components. Inteligent Autonomous Systems, Springer International Publishing. 

Sheridan, T. B. (1995). Teleoperation, Telerobotics and Telepresence: a Progress Report. 

Control Eng. Practice, 205-214. 

Son, K. (2011, October). Autonomous Networks Reasearch Group. Retrieved from 

http://anrg.usc.edu/ 

Swanson, K. D. (2013). Identification of Stabilility Thresholds in Time-Delayed Vehicle 

Teleoperation. Pennsylvania State University. 

Tanner, N. A., & Niemeyer, G. (2005). Improving Perception in Time-Delayed Telerobotics. The 

International Journal of Robotics Research, 631-644. 

Vasilijevic, A., Nad, D., Miskovic, N., & Vukic, Z. (2014). Auditory Interface for Teleoperation - 

Path Following Experimental results. The International Federation of Automatic Control, 
19th World Congress (pp. 4234-4239). Cape Town: Elsevier. 

Vozar, S., & Tilbury, D. M. (2014). Driver Modeling for Teleoperation with Time Delay. The 

International Federation of Automatic Contol, 3551-3556. 

Welch, G. F. (2016, Februrary 10). The Kalman Filter. Retrieved from 

http://www.cs.unc.edu/~welch/kalman/ 

Zanchi, M. G. (2014, February). Bleutooth Low Energy White Paper. Retrieved from Litepoint: 

http://www.litepoint.com/wp-content/uploads/2014/02/Bluetooth-Low-
Energy_WhitePaper.pdf 

 

185 

